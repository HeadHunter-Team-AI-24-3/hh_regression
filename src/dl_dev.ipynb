{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gIU6ZtYBjmdh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, mean_absolute_error\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from pytorch_tabnet.metrics import Metric\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, InputLayer\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"'pin_memory' argument is set as true but not supported on MPS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vudGTFnkj-FA",
        "outputId": "52d45624-603e-4858-bbbd-a2ddb7d26514"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/7m/n6pdmsh950scyftx2z0wsv3w0000gn/T/ipykernel_25448/990545542.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df.salary_gross.fillna(False, inplace=True)\n",
            "/var/folders/7m/n6pdmsh950scyftx2z0wsv3w0000gn/T/ipykernel_25448/990545542.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.salary_gross.fillna(False, inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(709524, 43)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('final_data.csv', low_memory=False)\n",
        "df.salary_gross.fillna(False, inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jy2XuTrnkVdR"
      },
      "outputs": [],
      "source": [
        "def culc_metrics(y_test, y_pred):\n",
        "    test_mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = test_mse**0.5\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
        "        y_true = np.array(y_true)\n",
        "        y_pred = np.array(y_pred)\n",
        "        smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "        return smape\n",
        "\n",
        "    smape = symmetric_mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "\n",
        "    print(f'Корень из среднеквадратичной ошибки (RMSE): {rmse}')\n",
        "    print(f\"R² Score: {r2}\")\n",
        "    print(f\"Средняя абсолютная ошибка (MAE): {mae}\")\n",
        "    print(f\"Средняя абсолютная процентная ошибка (SMAPE): {smape:.2f}%\")\n",
        "    print(f\"Медианная абсолютная ошибка (MedAE): {medae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8vPRpbXHkXM7"
      },
      "outputs": [],
      "source": [
        "cat_columns = ['premium', 'has_test', 'response_letter_required', 'area_name', 'salary_currency', 'salary_gross', 'type_name', 'address_city', 'address_metro_station_name', 'address_metro_line_name', 'address_metro_stations_0_line_name', 'archived', 'employer_name', 'employer_accredited_it_employer', 'employer_trusted', 'schedule_name', 'accept_temporary', 'professional_roles_0_name', 'accept_incomplete_resumes', 'experience_name', 'employment_name', 'address_metro_stations_3_station_name', 'address_metro_stations_3_line_name', 'working_time_intervals_0_name', 'working_time_modes_0_name', 'working_days_0_name', 'branding_type', 'branding_tariff', 'department_name', 'insider_interview_id', 'brand_snippet_logo', 'brand_snippet_picture', 'brand_snippet_background_color', 'brand_snippet_background_gradient_angle', 'brand_snippet_background_gradient_color_list_0_position', 'brand_snippet_background_gradient_color_list_1_position', 'category']\n",
        "text_columns = ['name', 'snippet_requirement', 'snippet_responsibility']\n",
        "num_columns = ['name_length', 'length']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3U6w5RxskZn_"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "num_df = pd.DataFrame(scaler.fit_transform(df[num_columns]), columns=num_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NSXTq4AEka5S"
      },
      "outputs": [],
      "source": [
        "label_columns = []\n",
        "ohe_columns = []\n",
        "\n",
        "for column in cat_columns:\n",
        "    if df[column].nunique() > 10:\n",
        "        label_columns.append(column)\n",
        "    else:\n",
        "        ohe_columns.append(column)\n",
        "\n",
        "to_bool = list(df[cat_columns].select_dtypes(include=['bool']).columns)\n",
        "df[['salary_gross', 'employer_accredited_it_employer']] = df[['salary_gross', 'employer_accredited_it_employer']].astype(bool).astype(int)\n",
        "df[to_bool] = df[to_bool].astype(int)\n",
        "\n",
        "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
        "ohe_encoded = ohe.fit_transform(df[ohe_columns])\n",
        "ohe_feature_names = ohe.get_feature_names_out(ohe_columns).tolist()\n",
        "encoded_ohe_data = pd.DataFrame(ohe_encoded, columns=ohe_feature_names)\n",
        "\n",
        "embedding_dim = 5\n",
        "embeddings = {}\n",
        "\n",
        "for col in label_columns:\n",
        "    unique_values = df[col].unique()\n",
        "    value_to_idx = {v: i for i, v in enumerate(unique_values)}\n",
        "    df[col+'_idx'] = df[col].map(value_to_idx)\n",
        "\n",
        "    num_embeddings = len(unique_values)\n",
        "    embedding_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "\n",
        "    embeddings[col] = {\n",
        "        'value_to_idx': value_to_idx,\n",
        "        'embedding': embedding_layer,\n",
        "        'num_embeddings': num_embeddings\n",
        "    }\n",
        "\n",
        "embedded_data = []\n",
        "for col in label_columns:\n",
        "    indices = torch.tensor(df[col+'_idx'].values, dtype=torch.long)\n",
        "    embedded = embeddings[col]['embedding'](indices).detach().numpy()\n",
        "    embedded_cols = [f\"{col}_embed_{i}\" for i in range(embedding_dim)]\n",
        "    embedded_df = pd.DataFrame(embedded, columns=embedded_cols)\n",
        "    embedded_data.append(embedded_df)\n",
        "\n",
        "embedded_data = pd.concat(embedded_data, axis=1)\n",
        "final_data = pd.concat([encoded_ohe_data, embedded_data], axis=1)\n",
        "\n",
        "for col in label_columns:\n",
        "    df.drop(col+'_idx', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUGN7e04l_Ot",
        "outputId": "3a87e0fb-27cb-40a4-9d78-72d38ab5046e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(709524, 111)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "Wh-ASMHMmCSi",
        "outputId": "ff8bd846-86e4-4e81-8452-0101eed79961"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "premium_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "has_test_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "response_letter_required_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_BYR",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_EUR",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_GEL",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_KGS",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_KZT",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_RUR",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_USD",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_currency_UZS",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "salary_gross_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "type_name_Закрытая",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "type_name_Открытая",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "type_name_Рекламная",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "archived_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "employer_trusted_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "schedule_name_Гибкий график",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "schedule_name_Полный день",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "schedule_name_Сменный график",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "schedule_name_Удаленная работа",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "accept_temporary_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "accept_incomplete_resumes_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "experience_name_Нет опыта",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "experience_name_От 1 года до 3 лет",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "experience_name_От 3 до 6 лет",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "employment_name_Полная занятость",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "employment_name_Проектная работа",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "employment_name_Стажировка",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "employment_name_Частичная занятость",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "working_time_intervals_0_name_Можно сменами по 4-6 часов в день",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "working_time_modes_0_name_С началом дня после 16:00",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "working_days_0_name_По субботам и воскресеньям",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "branding_type_MAKEUP",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "branding_type_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "branding_tariff_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "insider_interview_id_1",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_logo_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_picture_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_color_#EF3124",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_color_#FF5B29",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_color_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_angle_134.0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_angle_200.0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_angle_206.43",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_angle_67.0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_angle_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_0_position_0.0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_0_position_0.52",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_0_position_6.96",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_0_position_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_1_position_40.0",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_1_position_88.86",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_1_position_90.95",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_1_position_94.48",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "brand_snippet_background_gradient_color_list_1_position_Unknown",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "area_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "area_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "area_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "area_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "area_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_city_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_city_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_city_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_city_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_city_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_station_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_station_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_station_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_station_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_station_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_line_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_line_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_line_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_line_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_line_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_0_line_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_0_line_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_0_line_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_0_line_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_0_line_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "employer_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "employer_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "employer_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "employer_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "employer_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "professional_roles_0_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "professional_roles_0_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "professional_roles_0_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "professional_roles_0_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "professional_roles_0_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_station_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_station_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_station_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_station_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_station_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_line_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_line_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_line_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_line_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "address_metro_stations_3_line_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "department_name_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "department_name_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "department_name_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "department_name_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "department_name_embed_4",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "category_embed_0",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "category_embed_1",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "category_embed_2",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "category_embed_3",
                  "rawType": "float32",
                  "type": "float"
                },
                {
                  "name": "category_embed_4",
                  "rawType": "float32",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "4a73e1e6-17a3-4fd7-9ac3-970d3b625bf6",
              "rows": [
                [
                  "0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.4560292",
                  "-1.9213027",
                  "1.1276885",
                  "-0.017080141",
                  "0.7704254",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "0.33136937",
                  "0.16628349",
                  "-0.12126223",
                  "-0.81512755",
                  "0.14509052",
                  "-1.1610785",
                  "1.0318935",
                  "1.35559",
                  "0.39901254",
                  "-0.39681038",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "1",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.12560137",
                  "0.8683519",
                  "-0.49411798",
                  "-0.454782",
                  "0.6346824",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "0.29198343",
                  "-0.2645786",
                  "0.16426899",
                  "1.1978916",
                  "-0.031115683",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.7911934",
                  "-1.1045358",
                  "0.06856971",
                  "0.14240515",
                  "0.71400344"
                ],
                [
                  "2",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.0041281",
                  "1.144209",
                  "0.621498",
                  "1.6989455",
                  "1.5426066",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.6908963",
                  "-0.88329774",
                  "-1.1220036",
                  "0.04391833",
                  "0.58982724",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.7649316",
                  "1.048306",
                  "-0.17370057",
                  "-0.27079174",
                  "-0.81872696"
                ],
                [
                  "3",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "-0.07629777",
                  "1.4663755",
                  "-0.7650111",
                  "-0.23158886",
                  "0.15897465",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.67728895",
                  "-0.48271325",
                  "1.4456735",
                  "-0.6249574",
                  "1.5062504",
                  "0.5468655",
                  "0.16070747",
                  "1.1001048",
                  "-0.8189404",
                  "2.2235937",
                  "0.879781",
                  "-1.1166483",
                  "-1.5719247",
                  "0.9439411",
                  "-0.53561217",
                  "1.5453658",
                  "0.09484746",
                  "0.02163158",
                  "-2.0820355",
                  "0.756443",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "0.120367944",
                  "-0.61120176",
                  "-0.4604012",
                  "-1.3320998",
                  "0.59230214",
                  "-0.23459715",
                  "0.18854895",
                  "1.2811385",
                  "0.40528443",
                  "-0.07085834",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "4",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "-0.3142041",
                  "-0.015903937",
                  "-0.41546375",
                  "1.4782733",
                  "-0.5760592",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.4801135",
                  "0.3922",
                  "0.63566655",
                  "0.61069196",
                  "0.78268516",
                  "-0.3480379",
                  "-0.51862764",
                  "-0.12898086",
                  "0.4182826",
                  "-0.61708635",
                  "-1.4533231",
                  "2.1795764",
                  "0.31788477",
                  "0.22337401",
                  "0.640807",
                  "-0.51149905",
                  "1.253941",
                  "0.580151",
                  "-1.178894",
                  "-1.3275756",
                  "0.6185741",
                  "2.2447963",
                  "1.2243528",
                  "-0.06612169",
                  "-1.0387212",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.0143528",
                  "-1.5953436",
                  "1.7357459",
                  "-0.23289715",
                  "1.1592432"
                ],
                [
                  "5",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.5082178",
                  "-0.039192412",
                  "-1.0428782",
                  "0.8062964",
                  "0.72159266",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.94034314",
                  "-0.70855886",
                  "-0.12793735",
                  "0.17557696",
                  "0.0017063351",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "-1.1863075",
                  "0.9393159",
                  "-0.3101343",
                  "0.8735047",
                  "-1.0469604",
                  "-0.012116741",
                  "-0.11928398",
                  "0.29770294",
                  "0.9957401",
                  "0.82112277",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "6",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.4801135",
                  "0.3922",
                  "0.63566655",
                  "0.61069196",
                  "0.78268516",
                  "-0.3480379",
                  "-0.51862764",
                  "-0.12898086",
                  "0.4182826",
                  "-0.61708635",
                  "-1.4533231",
                  "2.1795764",
                  "0.31788477",
                  "0.22337401",
                  "0.640807",
                  "-0.7620412",
                  "0.26181766",
                  "1.8445324",
                  "0.060366943",
                  "0.11594443",
                  "-0.37431216",
                  "-0.7509284",
                  "-1.3918697",
                  "0.042270675",
                  "-0.54654753",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.7649316",
                  "1.048306",
                  "-0.17370057",
                  "-0.27079174",
                  "-0.81872696"
                ],
                [
                  "7",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8621686",
                  "-0.02971062",
                  "-0.5339472",
                  "0.3391863",
                  "-3.0023491",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "-1.854904",
                  "0.24199939",
                  "-1.6128074",
                  "1.4270859",
                  "-0.5434856",
                  "-0.37431216",
                  "-0.7509284",
                  "-1.3918697",
                  "0.042270675",
                  "-0.54654753",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.803299",
                  "0.835655",
                  "-0.82073903",
                  "0.33604833",
                  "-2.2077029"
                ],
                [
                  "8",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3631476",
                  "-1.322606",
                  "-0.7118264",
                  "-0.32131633",
                  "-1.7835069",
                  "0.62161076",
                  "-0.5417869",
                  "-1.559007",
                  "0.13982813",
                  "-0.027036011",
                  "-0.32971838",
                  "-0.83195144",
                  "0.4859843",
                  "1.673322",
                  "-1.9595768",
                  "-0.7160923",
                  "0.002223952",
                  "-2.0822575",
                  "-1.8041874",
                  "-0.19091716",
                  "-1.5557634",
                  "-0.86149174",
                  "0.2748319",
                  "-2.0654056",
                  "0.5886844",
                  "0.25034285",
                  "0.96640325",
                  "0.7350404",
                  "0.044535063",
                  "-0.7654275",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "9",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.67350334",
                  "-0.4229947",
                  "-0.26620573",
                  "2.3567584",
                  "-1.5362374",
                  "-1.0411855",
                  "0.6535503",
                  "-0.18781698",
                  "0.87737525",
                  "0.79181343",
                  "0.7721298",
                  "1.5770702",
                  "-0.4311321",
                  "1.3110727",
                  "0.045153864",
                  "-0.65520084",
                  "0.50078267",
                  "-0.26781037",
                  "1.0873568",
                  "-1.4477701",
                  "0.25034285",
                  "0.96640325",
                  "0.7350404",
                  "0.044535063",
                  "-0.7654275",
                  "0.9363394",
                  "0.08333516",
                  "-0.95635283",
                  "1.0240172",
                  "1.4240801",
                  "0.5559783",
                  "0.3608624",
                  "0.727326",
                  "0.97708625",
                  "0.5749386",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "10",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8621686",
                  "-0.02971062",
                  "-0.5339472",
                  "0.3391863",
                  "-3.0023491",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "-1.0375913",
                  "0.4650453",
                  "-0.6911215",
                  "-0.010252569",
                  "-1.0173532",
                  "-1.2987758",
                  "-2.0961068",
                  "0.7575517",
                  "-0.15491422",
                  "0.36678004",
                  "0.8471562",
                  "-0.22640869",
                  "-1.0281857",
                  "-0.2013989",
                  "-0.97631365",
                  "0.9762678",
                  "1.2307385",
                  "0.025653282",
                  "-0.47692302",
                  "0.8976497",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "11",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.62161076",
                  "-0.5417869",
                  "-1.559007",
                  "0.13982813",
                  "-0.027036011",
                  "-0.32971838",
                  "-0.83195144",
                  "0.4859843",
                  "1.673322",
                  "-1.9595768",
                  "-0.7160923",
                  "0.002223952",
                  "-2.0822575",
                  "-1.8041874",
                  "-0.19091716",
                  "0.39244157",
                  "-0.06461502",
                  "2.3379838",
                  "-1.1114616",
                  "0.96888024",
                  "-1.3767995",
                  "0.5227108",
                  "-0.3054979",
                  "0.34191832",
                  "-0.45012423",
                  "-1.4680157",
                  "0.33473456",
                  "-2.439473",
                  "-1.9125773",
                  "1.9990573",
                  "-0.04842216",
                  "0.5840409",
                  "0.91406685",
                  "-1.4383537",
                  "-0.07760572",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "12",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8074226",
                  "0.020809408",
                  "-0.60499",
                  "0.20870987",
                  "-1.0931203",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "-1.191898",
                  "-1.0056819",
                  "0.58101976",
                  "0.99598616",
                  "0.501516",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "0.9363394",
                  "0.08333516",
                  "-0.95635283",
                  "1.0240172",
                  "1.4240801",
                  "0.5559783",
                  "0.3608624",
                  "0.727326",
                  "0.97708625",
                  "0.5749386",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.7649316",
                  "1.048306",
                  "-0.17370057",
                  "-0.27079174",
                  "-0.81872696"
                ],
                [
                  "13",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "-1.5146675",
                  "-0.102226906",
                  "0.0646503",
                  "-1.0330036",
                  "1.728782",
                  "0.8641637",
                  "-0.31981897",
                  "-0.6022704",
                  "1.2417827",
                  "-1.3373579",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.53227717",
                  "0.85672134",
                  "-2.1153808",
                  "0.17525682",
                  "0.24891923",
                  "-0.25733393",
                  "0.92299145",
                  "-0.8030803",
                  "-0.5906896",
                  "0.31581876",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-2.3090336",
                  "0.3842769",
                  "-0.41184157",
                  "-0.7225233",
                  "-0.7328943"
                ],
                [
                  "14",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-1.981017",
                  "-0.2839515",
                  "-1.0636168",
                  "-0.3577364",
                  "-0.34893942",
                  "-0.32971838",
                  "-0.83195144",
                  "0.4859843",
                  "1.673322",
                  "-1.9595768",
                  "-0.7160923",
                  "0.002223952",
                  "-2.0822575",
                  "-1.8041874",
                  "-0.19091716",
                  "0.96309704",
                  "0.2114741",
                  "-1.5821218",
                  "-0.43009135",
                  "-0.22090419",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "15",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8621686",
                  "-0.02971062",
                  "-0.5339472",
                  "0.3391863",
                  "-3.0023491",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "1.1242582",
                  "-1.7776779",
                  "0.7689911",
                  "1.5866265",
                  "-1.0166156",
                  "-1.2714323",
                  "0.62200904",
                  "-1.2341589",
                  "-0.926676",
                  "-0.30212328",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "16",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.6863976",
                  "1.272348",
                  "1.4176192",
                  "0.18541855",
                  "0.49268445",
                  "0.7386498",
                  "0.5351573",
                  "-0.0034452768",
                  "1.4355456",
                  "0.20614842",
                  "-0.5314326",
                  "-1.1999893",
                  "0.5184074",
                  "1.3559722",
                  "2.0889072",
                  "0.20584184",
                  "0.62873095",
                  "0.47812858",
                  "-1.4118307",
                  "-0.23412877",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.40932652",
                  "-0.3466189",
                  "-0.8739438",
                  "0.7487059",
                  "1.675863",
                  "0.34618765",
                  "-1.3375515",
                  "1.0547208",
                  "-0.72099996",
                  "0.5333426",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.009331",
                  "-1.0059348",
                  "-1.6478721",
                  "2.0912604",
                  "-0.49846855"
                ],
                [
                  "17",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.12223936",
                  "0.25245735",
                  "1.4062592",
                  "1.5299654",
                  "-1.2050074",
                  "0.64697564",
                  "-0.9320586",
                  "-0.6925827",
                  "0.62975514",
                  "-0.4136547",
                  "-0.24144103",
                  "0.78672",
                  "-0.92728096",
                  "1.1302377",
                  "1.1887208",
                  "-0.4605006",
                  "0.8317561",
                  "0.7505897",
                  "-2.0670218",
                  "-1.4574236",
                  "-1.1610785",
                  "1.0318935",
                  "1.35559",
                  "0.39901254",
                  "-0.39681038",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "18",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.8216668",
                  "0.19546053",
                  "-1.606356",
                  "-1.4889596",
                  "2.0300846",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "0.40254012",
                  "1.0665964",
                  "-0.5197734",
                  "-1.6753591",
                  "-0.7577482",
                  "-1.6547492",
                  "1.0953491",
                  "-0.83354646",
                  "0.10941607",
                  "1.1765428",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.7911934",
                  "-1.1045358",
                  "0.06856971",
                  "0.14240515",
                  "0.71400344"
                ],
                [
                  "19",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.28313327",
                  "0.00053745793",
                  "0.38783368",
                  "0.16414796",
                  "-0.1206488",
                  "0.64697564",
                  "-0.9320586",
                  "-0.6925827",
                  "0.62975514",
                  "-0.4136547",
                  "-0.24144103",
                  "0.78672",
                  "-0.92728096",
                  "1.1302377",
                  "1.1887208",
                  "1.9141214",
                  "0.2588248",
                  "0.07765322",
                  "-0.07782279",
                  "-0.55935764",
                  "-0.10619571",
                  "0.9891233",
                  "0.46695793",
                  "-0.6358473",
                  "-1.4397662",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.0143528",
                  "-1.5953436",
                  "1.7357459",
                  "-0.23289715",
                  "1.1592432"
                ],
                [
                  "20",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-1.0498329",
                  "-0.30828083",
                  "2.721992",
                  "-2.3243282",
                  "0.12154024",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "-0.8647142",
                  "1.03075",
                  "-0.79522777",
                  "0.31884083",
                  "-0.33940187",
                  "-0.10079699",
                  "0.44546226",
                  "0.69869995",
                  "-1.4581162",
                  "-1.1475319",
                  "-0.8049475",
                  "0.41729793",
                  "-0.15399148",
                  "0.99123174",
                  "-0.5197171",
                  "1.0299238",
                  "0.1306455",
                  "-0.23480614",
                  "-0.28800333",
                  "-0.8237052",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "21",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.8216668",
                  "0.19546053",
                  "-1.606356",
                  "-1.4889596",
                  "2.0300846",
                  "-1.0411855",
                  "0.6535503",
                  "-0.18781698",
                  "0.87737525",
                  "0.79181343",
                  "0.7721298",
                  "1.5770702",
                  "-0.4311321",
                  "1.3110727",
                  "0.045153864",
                  "-1.4495671",
                  "-0.3710211",
                  "0.31766075",
                  "0.31284374",
                  "0.08555387",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.6708077",
                  "-0.6244744",
                  "-0.37416694",
                  "1.4610153",
                  "-0.843855",
                  "1.0299238",
                  "0.1306455",
                  "-0.23480614",
                  "-0.28800333",
                  "-0.8237052",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "22",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-1.0498329",
                  "-0.30828083",
                  "2.721992",
                  "-2.3243282",
                  "0.12154024",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "-1.0614173",
                  "2.1531832",
                  "-0.87523353",
                  "-0.071477704",
                  "0.119623095",
                  "-0.929068",
                  "-0.94980735",
                  "0.14458922",
                  "1.6436461",
                  "-0.2454346",
                  "-0.8049475",
                  "0.41729793",
                  "-0.15399148",
                  "0.99123174",
                  "-0.5197171",
                  "1.0299238",
                  "0.1306455",
                  "-0.23480614",
                  "-0.28800333",
                  "-0.8237052",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.803299",
                  "0.835655",
                  "-0.82073903",
                  "0.33604833",
                  "-2.2077029"
                ],
                [
                  "23",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.22410443",
                  "-1.0930452",
                  "0.10285489",
                  "0.696368",
                  "-0.1371678",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.22895604",
                  "-0.441809",
                  "-1.5473949",
                  "-1.495267",
                  "0.5785833",
                  "-1.5441028",
                  "0.30252302",
                  "-0.001112256",
                  "-0.8779211",
                  "0.19365649",
                  "1.1620215",
                  "-0.29874533",
                  "-0.6888078",
                  "0.20514151",
                  "-0.102459334",
                  "0.5559783",
                  "0.3608624",
                  "0.727326",
                  "0.97708625",
                  "0.5749386",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "24",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.28965405",
                  "1.0894903",
                  "-0.7813667",
                  "0.22740997",
                  "-0.28995317",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "0.5580404",
                  "-0.43206838",
                  "-1.7877387",
                  "-0.37550735",
                  "0.2393171",
                  "0.6185741",
                  "2.2447963",
                  "1.2243528",
                  "-0.06612169",
                  "-1.0387212",
                  "-0.26428524",
                  "0.70252216",
                  "1.3099465",
                  "-0.77399665",
                  "-0.71556044",
                  "-1.562562",
                  "-1.2744322",
                  "0.036009766",
                  "-0.39191473",
                  "-0.33264703",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.0143528",
                  "-1.5953436",
                  "1.7357459",
                  "-0.23289715",
                  "1.1592432"
                ],
                [
                  "25",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.3022947",
                  "0.5583532",
                  "0.71204334",
                  "-0.45586514",
                  "1.4429663",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "0.2465701",
                  "0.11168926",
                  "-0.0044923066",
                  "-2.2208383",
                  "1.2140527",
                  "-1.3495352",
                  "-0.96996576",
                  "-0.8355657",
                  "1.0303193",
                  "0.1310996",
                  "-0.51046777",
                  "-0.26332",
                  "0.87919617",
                  "1.6637495",
                  "1.9859147",
                  "1.0299238",
                  "0.1306455",
                  "-0.23480614",
                  "-0.28800333",
                  "-0.8237052",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.80593526",
                  "-0.1596749",
                  "1.3301666",
                  "-0.6353694",
                  "0.22315367"
                ],
                [
                  "26",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.28965405",
                  "1.0894903",
                  "-0.7813667",
                  "0.22740997",
                  "-0.28995317",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "-1.1265385",
                  "-0.59965664",
                  "-0.21603198",
                  "0.6217691",
                  "-0.17939502",
                  "1.5343525",
                  "-1.593748",
                  "-0.809641",
                  "0.14957567",
                  "-0.10126255",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.29581368",
                  "-1.214801",
                  "0.05362274",
                  "-0.5665001",
                  "0.3902468"
                ],
                [
                  "27",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.4801135",
                  "0.3922",
                  "0.63566655",
                  "0.61069196",
                  "0.78268516",
                  "-0.3480379",
                  "-0.51862764",
                  "-0.12898086",
                  "0.4182826",
                  "-0.61708635",
                  "-1.4533231",
                  "2.1795764",
                  "0.31788477",
                  "0.22337401",
                  "0.640807",
                  "-1.384838",
                  "-1.7217028",
                  "-1.8423383",
                  "1.2541871",
                  "-2.3691947",
                  "-0.5001503",
                  "0.5403024",
                  "-0.53841865",
                  "1.4729617",
                  "1.1388452",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.0143528",
                  "-1.5953436",
                  "1.7357459",
                  "-0.23289715",
                  "1.1592432"
                ],
                [
                  "28",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.6733192",
                  "-1.0399727",
                  "0.09724655",
                  "1.3997269",
                  "-0.94581556",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "-0.017555922",
                  "0.6597707",
                  "-0.72038317",
                  "-0.7870708",
                  "0.30273038",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.6668553",
                  "-0.3767639",
                  "0.72121084",
                  "0.6029032",
                  "-0.31633893",
                  "0.07543729",
                  "-0.67626137",
                  "1.2701132",
                  "1.5515535",
                  "-0.5889714",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "29",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "-1.5146675",
                  "-0.102226906",
                  "0.0646503",
                  "-1.0330036",
                  "1.728782",
                  "0.8641637",
                  "-0.31981897",
                  "-0.6022704",
                  "1.2417827",
                  "-1.3373579",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.53227717",
                  "0.85672134",
                  "-2.1153808",
                  "0.17525682",
                  "0.24891923",
                  "-0.12350254",
                  "-0.74073744",
                  "0.14234465",
                  "0.7471232",
                  "-0.29727477",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-2.3090336",
                  "0.3842769",
                  "-0.41184157",
                  "-0.7225233",
                  "-0.7328943"
                ],
                [
                  "30",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.28965405",
                  "1.0894903",
                  "-0.7813667",
                  "0.22740997",
                  "-0.28995317",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "-1.1265385",
                  "-0.59965664",
                  "-0.21603198",
                  "0.6217691",
                  "-0.17939502",
                  "-0.41996446",
                  "-1.5986398",
                  "0.2154695",
                  "-1.0623878",
                  "0.5063548",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "31",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.6863976",
                  "1.272348",
                  "1.4176192",
                  "0.18541855",
                  "0.49268445",
                  "0.7386498",
                  "0.5351573",
                  "-0.0034452768",
                  "1.4355456",
                  "0.20614842",
                  "-0.5314326",
                  "-1.1999893",
                  "0.5184074",
                  "1.3559722",
                  "2.0889072",
                  "-2.5742335",
                  "1.2806842",
                  "1.2175751",
                  "0.3115672",
                  "-0.018004544",
                  "-0.16662516",
                  "-1.0133978",
                  "-0.8212263",
                  "-0.64200747",
                  "0.805787",
                  "-0.40932652",
                  "-0.3466189",
                  "-0.8739438",
                  "0.7487059",
                  "1.675863",
                  "0.58371294",
                  "1.2497057",
                  "0.14717287",
                  "-0.03718086",
                  "0.20114517",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "32",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "-0.32285184",
                  "0.2887457",
                  "-0.04778509",
                  "-1.903002",
                  "-1.9034809",
                  "1.0042876",
                  "1.4791024",
                  "-0.07492499",
                  "-1.2259135",
                  "0.3091432",
                  "0.4427483",
                  "1.1041353",
                  "-0.8767837",
                  "1.6540749",
                  "-0.984517",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "-2.0933974",
                  "-0.61529833",
                  "-2.2539093",
                  "0.15979975",
                  "1.4353474",
                  "0.25034285",
                  "0.96640325",
                  "0.7350404",
                  "0.044535063",
                  "-0.7654275",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-2.3090336",
                  "0.3842769",
                  "-0.41184157",
                  "-0.7225233",
                  "-0.7328943"
                ],
                [
                  "33",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.7299685",
                  "0.463948",
                  "0.9146976",
                  "1.6693895",
                  "0.06499418",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.0921497",
                  "-0.32425702",
                  "-0.9274807",
                  "1.2759781",
                  "0.7410347",
                  "0.64697564",
                  "-0.9320586",
                  "-0.6925827",
                  "0.62975514",
                  "-0.4136547",
                  "-0.24144103",
                  "0.78672",
                  "-0.92728096",
                  "1.1302377",
                  "1.1887208",
                  "-1.6067847",
                  "-1.4747599",
                  "-0.61600465",
                  "-0.37743118",
                  "1.0856019",
                  "-1.1610785",
                  "1.0318935",
                  "1.35559",
                  "0.39901254",
                  "-0.39681038",
                  "0.9363394",
                  "0.08333516",
                  "-0.95635283",
                  "1.0240172",
                  "1.4240801",
                  "0.5559783",
                  "0.3608624",
                  "0.727326",
                  "0.97708625",
                  "0.5749386",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "34",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.4803916",
                  "-0.675448",
                  "0.13434926",
                  "-0.43455815",
                  "-0.61596346",
                  "0.85257643",
                  "-0.3994951",
                  "0.6588897",
                  "0.6863992",
                  "-0.6921362",
                  "0.23176214",
                  "-0.4036152",
                  "-0.102667294",
                  "-0.428479",
                  "-0.430578",
                  "-0.9228051",
                  "0.049095295",
                  "-0.18991596",
                  "-1.1333987",
                  "-1.1705476",
                  "0.49280804",
                  "-1.8188627",
                  "-0.31594986",
                  "-0.5291092",
                  "1.2812452",
                  "-0.8209097",
                  "-0.41715658",
                  "-1.8566222",
                  "0.5131293",
                  "-0.47235018",
                  "0.34618765",
                  "-1.3375515",
                  "1.0547208",
                  "-0.72099996",
                  "0.5333426",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.29581368",
                  "-1.214801",
                  "0.05362274",
                  "-0.5665001",
                  "0.3902468"
                ],
                [
                  "35",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-1.7955811",
                  "-1.4972374",
                  "0.048024092",
                  "-0.32143328",
                  "-0.8672499",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "-1.5094812",
                  "-0.5228337",
                  "-1.0800148",
                  "-1.5836523",
                  "0.0906581",
                  "0.25034285",
                  "0.96640325",
                  "0.7350404",
                  "0.044535063",
                  "-0.7654275",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "36",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8621686",
                  "-0.02971062",
                  "-0.5339472",
                  "0.3391863",
                  "-3.0023491",
                  "-0.016991122",
                  "0.03910132",
                  "-0.28934234",
                  "0.75408345",
                  "0.5818078",
                  "0.8102237",
                  "0.7170392",
                  "0.311768",
                  "-0.4229948",
                  "-0.41307303",
                  "1.1242582",
                  "-1.7776779",
                  "0.7689911",
                  "1.5866265",
                  "-1.0166156",
                  "0.6185741",
                  "2.2447963",
                  "1.2243528",
                  "-0.06612169",
                  "-1.0387212",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.0143528",
                  "-1.5953436",
                  "1.7357459",
                  "-0.23289715",
                  "1.1592432"
                ],
                [
                  "37",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.2868558",
                  "-0.08093567",
                  "0.24674802",
                  "1.6134342",
                  "-0.47974426",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "0.56211805",
                  "0.48054436",
                  "-1.1498923",
                  "1.291244",
                  "0.39932618",
                  "1.3689286",
                  "0.89076966",
                  "-0.18267211",
                  "-0.9403066",
                  "-0.841482",
                  "-0.51046777",
                  "-0.26332",
                  "0.87919617",
                  "1.6637495",
                  "1.9859147",
                  "-0.04842216",
                  "0.5840409",
                  "0.91406685",
                  "-1.4383537",
                  "-0.07760572",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.14073342",
                  "0.23482044",
                  "-0.37219393",
                  "0.4169873",
                  "0.17568092"
                ],
                [
                  "38",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.12223936",
                  "0.25245735",
                  "1.4062592",
                  "1.5299654",
                  "-1.2050074",
                  "0.64697564",
                  "-0.9320586",
                  "-0.6925827",
                  "0.62975514",
                  "-0.4136547",
                  "-0.24144103",
                  "0.78672",
                  "-0.92728096",
                  "1.1302377",
                  "1.1887208",
                  "-1.3595828",
                  "-0.7060707",
                  "1.4539253",
                  "0.5439949",
                  "0.44801363",
                  "-0.89713883",
                  "0.55076647",
                  "0.52445185",
                  "-0.43242994",
                  "-0.8812097",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "39",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.6863976",
                  "1.272348",
                  "1.4176192",
                  "0.18541855",
                  "0.49268445",
                  "0.7386498",
                  "0.5351573",
                  "-0.0034452768",
                  "1.4355456",
                  "0.20614842",
                  "-0.5314326",
                  "-1.1999893",
                  "0.5184074",
                  "1.3559722",
                  "2.0889072",
                  "-0.34163365",
                  "0.396383",
                  "0.72511256",
                  "-0.32971716",
                  "-2.3081682",
                  "-1.1610785",
                  "1.0318935",
                  "1.35559",
                  "0.39901254",
                  "-0.39681038",
                  "-0.40932652",
                  "-0.3466189",
                  "-0.8739438",
                  "0.7487059",
                  "1.675863",
                  "0.34618765",
                  "-1.3375515",
                  "1.0547208",
                  "-0.72099996",
                  "0.5333426",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.0023288354",
                  "-1.1179168",
                  "0.38640526",
                  "0.27895528",
                  "-0.008146935"
                ],
                [
                  "40",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.4801135",
                  "0.3922",
                  "0.63566655",
                  "0.61069196",
                  "0.78268516",
                  "-0.3480379",
                  "-0.51862764",
                  "-0.12898086",
                  "0.4182826",
                  "-0.61708635",
                  "-1.4533231",
                  "2.1795764",
                  "0.31788477",
                  "0.22337401",
                  "0.640807",
                  "-0.4935274",
                  "-0.5849425",
                  "-0.79101557",
                  "2.1783073",
                  "0.48738545",
                  "0.39734444",
                  "-1.2148163",
                  "-0.9314555",
                  "-0.33484524",
                  "1.3838135",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.38533005",
                  "-0.9361409",
                  "2.4827633",
                  "-0.25272068",
                  "1.2772778"
                ],
                [
                  "41",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.8641637",
                  "-0.31981897",
                  "-0.6022704",
                  "1.2417827",
                  "-1.3373579",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.8081691",
                  "-1.1657513",
                  "0.3586996",
                  "0.66356117",
                  "1.186352",
                  "-1.5753856",
                  "0.97449803",
                  "-1.73175",
                  "-0.6006423",
                  "-0.7831747",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "42",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.12223936",
                  "0.25245735",
                  "1.4062592",
                  "1.5299654",
                  "-1.2050074",
                  "0.64697564",
                  "-0.9320586",
                  "-0.6925827",
                  "0.62975514",
                  "-0.4136547",
                  "-0.24144103",
                  "0.78672",
                  "-0.92728096",
                  "1.1302377",
                  "1.1887208",
                  "-0.066275805",
                  "0.52905375",
                  "-0.25085267",
                  "1.8168725",
                  "-0.65939415",
                  "-1.395693",
                  "-0.9725334",
                  "0.061614737",
                  "-0.31536824",
                  "-0.27773902",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.7911934",
                  "-1.1045358",
                  "0.06856971",
                  "0.14240515",
                  "0.71400344"
                ],
                [
                  "43",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.3022947",
                  "0.5583532",
                  "0.71204334",
                  "-0.45586514",
                  "1.4429663",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "2.154965",
                  "-0.025880512",
                  "-0.28028244",
                  "-0.28279895",
                  "0.17388532",
                  "-1.028253",
                  "-0.40187484",
                  "0.25050598",
                  "0.5674019",
                  "0.499511",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-1.7649316",
                  "1.048306",
                  "-0.17370057",
                  "-0.27079174",
                  "-0.81872696"
                ],
                [
                  "44",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.14144406",
                  "-0.85097164",
                  "-1.1230956",
                  "1.0207562",
                  "1.0517533",
                  "0.45635557",
                  "1.1903087",
                  "-0.8672293",
                  "0.81366575",
                  "-0.13232276",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "-0.16559786",
                  "-0.8943692",
                  "-0.6646602",
                  "-0.53015053",
                  "-0.054651737",
                  "0.49280804",
                  "-1.8188627",
                  "-0.31594986",
                  "-0.5291092",
                  "1.2812452",
                  "-1.109314",
                  "-0.018371858",
                  "1.0126805",
                  "2.2025688",
                  "-0.55911666",
                  "-0.04842216",
                  "0.5840409",
                  "0.91406685",
                  "-1.4383537",
                  "-0.07760572",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ],
                [
                  "45",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "1.0476934",
                  "-0.23354465",
                  "-1.2550951",
                  "1.3803984",
                  "-1.5638484",
                  "0.62161076",
                  "-0.5417869",
                  "-1.559007",
                  "0.13982813",
                  "-0.027036011",
                  "-0.32971838",
                  "-0.83195144",
                  "0.4859843",
                  "1.673322",
                  "-1.9595768",
                  "-0.7160923",
                  "0.002223952",
                  "-2.0822575",
                  "-1.8041874",
                  "-0.19091716",
                  "-1.5776372",
                  "1.2732985",
                  "-0.5117399",
                  "1.5952765",
                  "-2.4998474",
                  "-0.37431216",
                  "-0.7509284",
                  "-1.3918697",
                  "0.042270675",
                  "-0.54654753",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.7911934",
                  "-1.1045358",
                  "0.06856971",
                  "0.14240515",
                  "0.71400344"
                ],
                [
                  "46",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "1.6733192",
                  "-1.0399727",
                  "0.09724655",
                  "1.3997269",
                  "-0.94581556",
                  "-0.29728645",
                  "-0.24914202",
                  "0.84869474",
                  "0.40909067",
                  "-1.0743815",
                  "1.2018075",
                  "-1.0764947",
                  "-0.6477631",
                  "1.1386791",
                  "-0.46752867",
                  "0.56211805",
                  "0.48054436",
                  "-1.1498923",
                  "1.291244",
                  "0.39932618",
                  "1.3689286",
                  "0.89076966",
                  "-0.18267211",
                  "-0.9403066",
                  "-0.841482",
                  "0.35233268",
                  "-0.33906084",
                  "0.33151582",
                  "-0.53072184",
                  "-0.9430303",
                  "0.34618765",
                  "-1.3375515",
                  "1.0547208",
                  "-0.72099996",
                  "0.5333426",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.14073342",
                  "0.23482044",
                  "-0.37219393",
                  "0.4169873",
                  "0.17568092"
                ],
                [
                  "47",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.6224307",
                  "0.6163781",
                  "-0.8885599",
                  "-0.5472227",
                  "-0.8827124",
                  "-0.3480379",
                  "-0.51862764",
                  "-0.12898086",
                  "0.4182826",
                  "-0.61708635",
                  "-1.4533231",
                  "2.1795764",
                  "0.31788477",
                  "0.22337401",
                  "0.640807",
                  "0.01837243",
                  "-0.2794654",
                  "2.3334064",
                  "-0.45461532",
                  "-0.7424541",
                  "1.3689286",
                  "0.89076966",
                  "-0.18267211",
                  "-0.9403066",
                  "-0.841482",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "0.14073342",
                  "0.23482044",
                  "-0.37219393",
                  "0.4169873",
                  "0.17568092"
                ],
                [
                  "48",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "0.28965405",
                  "1.0894903",
                  "-0.7813667",
                  "0.22740997",
                  "-0.28995317",
                  "0.7005446",
                  "-0.45004365",
                  "-0.5710515",
                  "0.49136224",
                  "1.0031796",
                  "1.1011664",
                  "1.2188874",
                  "-0.22393577",
                  "0.053248502",
                  "0.7817305",
                  "-1.1265385",
                  "-0.59965664",
                  "-0.21603198",
                  "0.6217691",
                  "-0.17939502",
                  "0.1191607",
                  "0.11627443",
                  "-0.34910977",
                  "1.9359108",
                  "-0.09837752",
                  "-0.9923979",
                  "0.6433607",
                  "0.4373805",
                  "-0.38188612",
                  "0.80816376",
                  "0.5721176",
                  "0.968845",
                  "-0.1805319",
                  "-1.3295491",
                  "1.193094",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "1.7911934",
                  "-1.1045358",
                  "0.06856971",
                  "0.14240515",
                  "0.71400344"
                ],
                [
                  "49",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.2052009",
                  "-1.3757603",
                  "-2.0249548",
                  "2.0489652",
                  "-0.7094232",
                  "0.3744834",
                  "-0.41695046",
                  "-1.000886",
                  "0.39910662",
                  "0.078708604",
                  "-0.22410443",
                  "-1.0930452",
                  "0.10285489",
                  "0.696368",
                  "-0.1371678",
                  "1.9125526",
                  "0.26287392",
                  "0.6829854",
                  "-0.22240521",
                  "0.09643467",
                  "0.8576872",
                  "2.2831466",
                  "0.5007871",
                  "1.9106332",
                  "-1.0262378",
                  "0.84291536",
                  "0.33748603",
                  "-0.18981329",
                  "1.0915185",
                  "-1.1748203",
                  "-0.41996446",
                  "-1.5986398",
                  "0.2154695",
                  "-1.0623878",
                  "0.5063548",
                  "-0.7780126",
                  "0.7166478",
                  "-2.019715",
                  "-0.5125619",
                  "1.826665",
                  "-0.04842216",
                  "0.5840409",
                  "0.91406685",
                  "-1.4383537",
                  "-0.07760572",
                  "1.4297845",
                  "-0.12720993",
                  "-0.09578714",
                  "-1.2804302",
                  "0.5230676",
                  "-0.19185168",
                  "-1.6061792",
                  "-1.2491078",
                  "-0.30472484",
                  "0.08800757"
                ]
              ],
              "shape": {
                "columns": 111,
                "rows": 709524
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premium_1</th>\n",
              "      <th>has_test_1</th>\n",
              "      <th>response_letter_required_1</th>\n",
              "      <th>salary_currency_BYR</th>\n",
              "      <th>salary_currency_EUR</th>\n",
              "      <th>salary_currency_GEL</th>\n",
              "      <th>salary_currency_KGS</th>\n",
              "      <th>salary_currency_KZT</th>\n",
              "      <th>salary_currency_RUR</th>\n",
              "      <th>salary_currency_USD</th>\n",
              "      <th>salary_currency_UZS</th>\n",
              "      <th>salary_gross_1</th>\n",
              "      <th>type_name_Закрытая</th>\n",
              "      <th>type_name_Открытая</th>\n",
              "      <th>type_name_Рекламная</th>\n",
              "      <th>archived_1</th>\n",
              "      <th>employer_trusted_1</th>\n",
              "      <th>schedule_name_Гибкий график</th>\n",
              "      <th>schedule_name_Полный день</th>\n",
              "      <th>schedule_name_Сменный график</th>\n",
              "      <th>schedule_name_Удаленная работа</th>\n",
              "      <th>accept_temporary_1</th>\n",
              "      <th>accept_incomplete_resumes_1</th>\n",
              "      <th>experience_name_Нет опыта</th>\n",
              "      <th>experience_name_От 1 года до 3 лет</th>\n",
              "      <th>experience_name_От 3 до 6 лет</th>\n",
              "      <th>employment_name_Полная занятость</th>\n",
              "      <th>employment_name_Проектная работа</th>\n",
              "      <th>employment_name_Стажировка</th>\n",
              "      <th>employment_name_Частичная занятость</th>\n",
              "      <th>working_time_intervals_0_name_Можно сменами по 4-6 часов в день</th>\n",
              "      <th>working_time_modes_0_name_С началом дня после 16:00</th>\n",
              "      <th>working_days_0_name_По субботам и воскресеньям</th>\n",
              "      <th>branding_type_MAKEUP</th>\n",
              "      <th>branding_type_Unknown</th>\n",
              "      <th>branding_tariff_Unknown</th>\n",
              "      <th>insider_interview_id_1</th>\n",
              "      <th>brand_snippet_logo_Unknown</th>\n",
              "      <th>brand_snippet_picture_Unknown</th>\n",
              "      <th>brand_snippet_background_color_#EF3124</th>\n",
              "      <th>brand_snippet_background_color_#FF5B29</th>\n",
              "      <th>brand_snippet_background_color_Unknown</th>\n",
              "      <th>brand_snippet_background_gradient_angle_134.0</th>\n",
              "      <th>brand_snippet_background_gradient_angle_200.0</th>\n",
              "      <th>brand_snippet_background_gradient_angle_206.43</th>\n",
              "      <th>brand_snippet_background_gradient_angle_67.0</th>\n",
              "      <th>brand_snippet_background_gradient_angle_Unknown</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_0_position_0.0</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_0_position_0.52</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_0_position_6.96</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_0_position_Unknown</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_1_position_40.0</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_1_position_88.86</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_1_position_90.95</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_1_position_94.48</th>\n",
              "      <th>brand_snippet_background_gradient_color_list_1_position_Unknown</th>\n",
              "      <th>area_name_embed_0</th>\n",
              "      <th>area_name_embed_1</th>\n",
              "      <th>area_name_embed_2</th>\n",
              "      <th>area_name_embed_3</th>\n",
              "      <th>area_name_embed_4</th>\n",
              "      <th>address_city_embed_0</th>\n",
              "      <th>address_city_embed_1</th>\n",
              "      <th>address_city_embed_2</th>\n",
              "      <th>address_city_embed_3</th>\n",
              "      <th>address_city_embed_4</th>\n",
              "      <th>address_metro_station_name_embed_0</th>\n",
              "      <th>address_metro_station_name_embed_1</th>\n",
              "      <th>address_metro_station_name_embed_2</th>\n",
              "      <th>address_metro_station_name_embed_3</th>\n",
              "      <th>address_metro_station_name_embed_4</th>\n",
              "      <th>address_metro_line_name_embed_0</th>\n",
              "      <th>address_metro_line_name_embed_1</th>\n",
              "      <th>address_metro_line_name_embed_2</th>\n",
              "      <th>address_metro_line_name_embed_3</th>\n",
              "      <th>address_metro_line_name_embed_4</th>\n",
              "      <th>address_metro_stations_0_line_name_embed_0</th>\n",
              "      <th>address_metro_stations_0_line_name_embed_1</th>\n",
              "      <th>address_metro_stations_0_line_name_embed_2</th>\n",
              "      <th>address_metro_stations_0_line_name_embed_3</th>\n",
              "      <th>address_metro_stations_0_line_name_embed_4</th>\n",
              "      <th>employer_name_embed_0</th>\n",
              "      <th>employer_name_embed_1</th>\n",
              "      <th>employer_name_embed_2</th>\n",
              "      <th>employer_name_embed_3</th>\n",
              "      <th>employer_name_embed_4</th>\n",
              "      <th>professional_roles_0_name_embed_0</th>\n",
              "      <th>professional_roles_0_name_embed_1</th>\n",
              "      <th>professional_roles_0_name_embed_2</th>\n",
              "      <th>professional_roles_0_name_embed_3</th>\n",
              "      <th>professional_roles_0_name_embed_4</th>\n",
              "      <th>address_metro_stations_3_station_name_embed_0</th>\n",
              "      <th>address_metro_stations_3_station_name_embed_1</th>\n",
              "      <th>address_metro_stations_3_station_name_embed_2</th>\n",
              "      <th>address_metro_stations_3_station_name_embed_3</th>\n",
              "      <th>address_metro_stations_3_station_name_embed_4</th>\n",
              "      <th>address_metro_stations_3_line_name_embed_0</th>\n",
              "      <th>address_metro_stations_3_line_name_embed_1</th>\n",
              "      <th>address_metro_stations_3_line_name_embed_2</th>\n",
              "      <th>address_metro_stations_3_line_name_embed_3</th>\n",
              "      <th>address_metro_stations_3_line_name_embed_4</th>\n",
              "      <th>department_name_embed_0</th>\n",
              "      <th>department_name_embed_1</th>\n",
              "      <th>department_name_embed_2</th>\n",
              "      <th>department_name_embed_3</th>\n",
              "      <th>department_name_embed_4</th>\n",
              "      <th>category_embed_0</th>\n",
              "      <th>category_embed_1</th>\n",
              "      <th>category_embed_2</th>\n",
              "      <th>category_embed_3</th>\n",
              "      <th>category_embed_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.205201</td>\n",
              "      <td>-1.375760</td>\n",
              "      <td>-2.024955</td>\n",
              "      <td>2.048965</td>\n",
              "      <td>-0.709423</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>1.456029</td>\n",
              "      <td>-1.921303</td>\n",
              "      <td>1.127689</td>\n",
              "      <td>-0.017080</td>\n",
              "      <td>0.770425</td>\n",
              "      <td>-0.016991</td>\n",
              "      <td>0.039101</td>\n",
              "      <td>-0.289342</td>\n",
              "      <td>0.754083</td>\n",
              "      <td>0.581808</td>\n",
              "      <td>0.810224</td>\n",
              "      <td>0.717039</td>\n",
              "      <td>0.311768</td>\n",
              "      <td>-0.422995</td>\n",
              "      <td>-0.413073</td>\n",
              "      <td>0.331369</td>\n",
              "      <td>0.166283</td>\n",
              "      <td>-0.121262</td>\n",
              "      <td>-0.815128</td>\n",
              "      <td>0.145091</td>\n",
              "      <td>-1.161078</td>\n",
              "      <td>1.031893</td>\n",
              "      <td>1.355590</td>\n",
              "      <td>0.399013</td>\n",
              "      <td>-0.396810</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>0.002329</td>\n",
              "      <td>-1.117917</td>\n",
              "      <td>0.386405</td>\n",
              "      <td>0.278955</td>\n",
              "      <td>-0.008147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.205201</td>\n",
              "      <td>-1.375760</td>\n",
              "      <td>-2.024955</td>\n",
              "      <td>2.048965</td>\n",
              "      <td>-0.709423</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>-0.125601</td>\n",
              "      <td>0.868352</td>\n",
              "      <td>-0.494118</td>\n",
              "      <td>-0.454782</td>\n",
              "      <td>0.634682</td>\n",
              "      <td>0.700545</td>\n",
              "      <td>-0.450044</td>\n",
              "      <td>-0.571051</td>\n",
              "      <td>0.491362</td>\n",
              "      <td>1.003180</td>\n",
              "      <td>1.101166</td>\n",
              "      <td>1.218887</td>\n",
              "      <td>-0.223936</td>\n",
              "      <td>0.053249</td>\n",
              "      <td>0.781730</td>\n",
              "      <td>0.291983</td>\n",
              "      <td>-0.264579</td>\n",
              "      <td>0.164269</td>\n",
              "      <td>1.197892</td>\n",
              "      <td>-0.031116</td>\n",
              "      <td>-0.123503</td>\n",
              "      <td>-0.740737</td>\n",
              "      <td>0.142345</td>\n",
              "      <td>0.747123</td>\n",
              "      <td>-0.297275</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>1.791193</td>\n",
              "      <td>-1.104536</td>\n",
              "      <td>0.068570</td>\n",
              "      <td>0.142405</td>\n",
              "      <td>0.714003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.205201</td>\n",
              "      <td>-1.375760</td>\n",
              "      <td>-2.024955</td>\n",
              "      <td>2.048965</td>\n",
              "      <td>-0.709423</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>1.004128</td>\n",
              "      <td>1.144209</td>\n",
              "      <td>0.621498</td>\n",
              "      <td>1.698946</td>\n",
              "      <td>1.542607</td>\n",
              "      <td>1.912553</td>\n",
              "      <td>0.262874</td>\n",
              "      <td>0.682985</td>\n",
              "      <td>-0.222405</td>\n",
              "      <td>0.096435</td>\n",
              "      <td>0.857687</td>\n",
              "      <td>2.283147</td>\n",
              "      <td>0.500787</td>\n",
              "      <td>1.910633</td>\n",
              "      <td>-1.026238</td>\n",
              "      <td>0.690896</td>\n",
              "      <td>-0.883298</td>\n",
              "      <td>-1.122004</td>\n",
              "      <td>0.043918</td>\n",
              "      <td>0.589827</td>\n",
              "      <td>-0.123503</td>\n",
              "      <td>-0.740737</td>\n",
              "      <td>0.142345</td>\n",
              "      <td>0.747123</td>\n",
              "      <td>-0.297275</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>-1.764932</td>\n",
              "      <td>1.048306</td>\n",
              "      <td>-0.173701</td>\n",
              "      <td>-0.270792</td>\n",
              "      <td>-0.818727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.076298</td>\n",
              "      <td>1.466375</td>\n",
              "      <td>-0.765011</td>\n",
              "      <td>-0.231589</td>\n",
              "      <td>0.158975</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.677289</td>\n",
              "      <td>-0.482713</td>\n",
              "      <td>1.445673</td>\n",
              "      <td>-0.624957</td>\n",
              "      <td>1.506250</td>\n",
              "      <td>0.546866</td>\n",
              "      <td>0.160707</td>\n",
              "      <td>1.100105</td>\n",
              "      <td>-0.818940</td>\n",
              "      <td>2.223594</td>\n",
              "      <td>0.879781</td>\n",
              "      <td>-1.116648</td>\n",
              "      <td>-1.571925</td>\n",
              "      <td>0.943941</td>\n",
              "      <td>-0.535612</td>\n",
              "      <td>1.545366</td>\n",
              "      <td>0.094847</td>\n",
              "      <td>0.021632</td>\n",
              "      <td>-2.082036</td>\n",
              "      <td>0.756443</td>\n",
              "      <td>-0.123503</td>\n",
              "      <td>-0.740737</td>\n",
              "      <td>0.142345</td>\n",
              "      <td>0.747123</td>\n",
              "      <td>-0.297275</td>\n",
              "      <td>0.120368</td>\n",
              "      <td>-0.611202</td>\n",
              "      <td>-0.460401</td>\n",
              "      <td>-1.332100</td>\n",
              "      <td>0.592302</td>\n",
              "      <td>-0.234597</td>\n",
              "      <td>0.188549</td>\n",
              "      <td>1.281139</td>\n",
              "      <td>0.405284</td>\n",
              "      <td>-0.070858</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>0.002329</td>\n",
              "      <td>-1.117917</td>\n",
              "      <td>0.386405</td>\n",
              "      <td>0.278955</td>\n",
              "      <td>-0.008147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.314204</td>\n",
              "      <td>-0.015904</td>\n",
              "      <td>-0.415464</td>\n",
              "      <td>1.478273</td>\n",
              "      <td>-0.576059</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.480114</td>\n",
              "      <td>0.392200</td>\n",
              "      <td>0.635667</td>\n",
              "      <td>0.610692</td>\n",
              "      <td>0.782685</td>\n",
              "      <td>-0.348038</td>\n",
              "      <td>-0.518628</td>\n",
              "      <td>-0.128981</td>\n",
              "      <td>0.418283</td>\n",
              "      <td>-0.617086</td>\n",
              "      <td>-1.453323</td>\n",
              "      <td>2.179576</td>\n",
              "      <td>0.317885</td>\n",
              "      <td>0.223374</td>\n",
              "      <td>0.640807</td>\n",
              "      <td>-0.511499</td>\n",
              "      <td>1.253941</td>\n",
              "      <td>0.580151</td>\n",
              "      <td>-1.178894</td>\n",
              "      <td>-1.327576</td>\n",
              "      <td>0.618574</td>\n",
              "      <td>2.244796</td>\n",
              "      <td>1.224353</td>\n",
              "      <td>-0.066122</td>\n",
              "      <td>-1.038721</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>-1.014353</td>\n",
              "      <td>-1.595344</td>\n",
              "      <td>1.735746</td>\n",
              "      <td>-0.232897</td>\n",
              "      <td>1.159243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709519</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.094439</td>\n",
              "      <td>0.556053</td>\n",
              "      <td>-0.147310</td>\n",
              "      <td>0.668464</td>\n",
              "      <td>-0.019185</td>\n",
              "      <td>-0.089407</td>\n",
              "      <td>-0.479558</td>\n",
              "      <td>0.717473</td>\n",
              "      <td>-0.418876</td>\n",
              "      <td>-1.045492</td>\n",
              "      <td>0.410558</td>\n",
              "      <td>0.081635</td>\n",
              "      <td>0.110028</td>\n",
              "      <td>-0.526280</td>\n",
              "      <td>1.652590</td>\n",
              "      <td>-0.168085</td>\n",
              "      <td>-2.549698</td>\n",
              "      <td>-1.356583</td>\n",
              "      <td>-0.726098</td>\n",
              "      <td>0.369500</td>\n",
              "      <td>0.587124</td>\n",
              "      <td>-0.813821</td>\n",
              "      <td>1.021916</td>\n",
              "      <td>1.691159</td>\n",
              "      <td>1.534646</td>\n",
              "      <td>0.865447</td>\n",
              "      <td>1.244169</td>\n",
              "      <td>1.467285</td>\n",
              "      <td>0.063808</td>\n",
              "      <td>-1.063296</td>\n",
              "      <td>1.368929</td>\n",
              "      <td>0.890770</td>\n",
              "      <td>-0.182672</td>\n",
              "      <td>-0.940307</td>\n",
              "      <td>-0.841482</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>0.917495</td>\n",
              "      <td>-0.12210</td>\n",
              "      <td>-0.628140</td>\n",
              "      <td>1.085993</td>\n",
              "      <td>0.416683</td>\n",
              "      <td>0.140733</td>\n",
              "      <td>0.234820</td>\n",
              "      <td>-0.372194</td>\n",
              "      <td>0.416987</td>\n",
              "      <td>0.175681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709520</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.094439</td>\n",
              "      <td>0.556053</td>\n",
              "      <td>-0.147310</td>\n",
              "      <td>0.668464</td>\n",
              "      <td>-0.019185</td>\n",
              "      <td>-0.089407</td>\n",
              "      <td>-0.479558</td>\n",
              "      <td>0.717473</td>\n",
              "      <td>-0.418876</td>\n",
              "      <td>-1.045492</td>\n",
              "      <td>1.618188</td>\n",
              "      <td>-2.324020</td>\n",
              "      <td>-0.723260</td>\n",
              "      <td>-0.047075</td>\n",
              "      <td>-0.129131</td>\n",
              "      <td>1.336465</td>\n",
              "      <td>1.228576</td>\n",
              "      <td>0.195029</td>\n",
              "      <td>1.610126</td>\n",
              "      <td>-0.613384</td>\n",
              "      <td>-2.319588</td>\n",
              "      <td>-0.750993</td>\n",
              "      <td>-0.825062</td>\n",
              "      <td>0.280801</td>\n",
              "      <td>0.143363</td>\n",
              "      <td>0.338411</td>\n",
              "      <td>-0.533607</td>\n",
              "      <td>-0.735669</td>\n",
              "      <td>-0.969695</td>\n",
              "      <td>0.436879</td>\n",
              "      <td>0.397344</td>\n",
              "      <td>-1.214816</td>\n",
              "      <td>-0.931455</td>\n",
              "      <td>-0.334845</td>\n",
              "      <td>1.383814</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>-0.385330</td>\n",
              "      <td>-0.936141</td>\n",
              "      <td>2.482763</td>\n",
              "      <td>-0.252721</td>\n",
              "      <td>1.277278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709521</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.205201</td>\n",
              "      <td>-1.375760</td>\n",
              "      <td>-2.024955</td>\n",
              "      <td>2.048965</td>\n",
              "      <td>-0.709423</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.410558</td>\n",
              "      <td>0.081635</td>\n",
              "      <td>0.110028</td>\n",
              "      <td>-0.526280</td>\n",
              "      <td>1.652590</td>\n",
              "      <td>-0.168085</td>\n",
              "      <td>-2.549698</td>\n",
              "      <td>-1.356583</td>\n",
              "      <td>-0.726098</td>\n",
              "      <td>0.369500</td>\n",
              "      <td>0.587124</td>\n",
              "      <td>-0.813821</td>\n",
              "      <td>1.021916</td>\n",
              "      <td>1.691159</td>\n",
              "      <td>1.534646</td>\n",
              "      <td>0.878010</td>\n",
              "      <td>0.289776</td>\n",
              "      <td>0.853992</td>\n",
              "      <td>0.804243</td>\n",
              "      <td>0.484368</td>\n",
              "      <td>1.368929</td>\n",
              "      <td>0.890770</td>\n",
              "      <td>-0.182672</td>\n",
              "      <td>-0.940307</td>\n",
              "      <td>-0.841482</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>0.140733</td>\n",
              "      <td>0.234820</td>\n",
              "      <td>-0.372194</td>\n",
              "      <td>0.416987</td>\n",
              "      <td>0.175681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709522</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.008302</td>\n",
              "      <td>0.563011</td>\n",
              "      <td>0.594524</td>\n",
              "      <td>-0.224431</td>\n",
              "      <td>-1.871617</td>\n",
              "      <td>-0.136895</td>\n",
              "      <td>-2.544892</td>\n",
              "      <td>1.548013</td>\n",
              "      <td>0.406414</td>\n",
              "      <td>0.943872</td>\n",
              "      <td>-0.228299</td>\n",
              "      <td>-1.137940</td>\n",
              "      <td>1.040894</td>\n",
              "      <td>0.155791</td>\n",
              "      <td>-0.614703</td>\n",
              "      <td>1.491590</td>\n",
              "      <td>-1.318055</td>\n",
              "      <td>1.086710</td>\n",
              "      <td>-1.061597</td>\n",
              "      <td>-0.481346</td>\n",
              "      <td>-0.242944</td>\n",
              "      <td>-0.406439</td>\n",
              "      <td>0.594328</td>\n",
              "      <td>0.064523</td>\n",
              "      <td>-1.332344</td>\n",
              "      <td>-1.229636</td>\n",
              "      <td>0.227100</td>\n",
              "      <td>0.150392</td>\n",
              "      <td>0.617529</td>\n",
              "      <td>0.994449</td>\n",
              "      <td>-1.161078</td>\n",
              "      <td>1.031893</td>\n",
              "      <td>1.355590</td>\n",
              "      <td>0.399013</td>\n",
              "      <td>-0.396810</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>0.002329</td>\n",
              "      <td>-1.117917</td>\n",
              "      <td>0.386405</td>\n",
              "      <td>0.278955</td>\n",
              "      <td>-0.008147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709523</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.205201</td>\n",
              "      <td>-1.375760</td>\n",
              "      <td>-2.024955</td>\n",
              "      <td>2.048965</td>\n",
              "      <td>-0.709423</td>\n",
              "      <td>0.374483</td>\n",
              "      <td>-0.416950</td>\n",
              "      <td>-1.000886</td>\n",
              "      <td>0.399107</td>\n",
              "      <td>0.078709</td>\n",
              "      <td>0.410558</td>\n",
              "      <td>0.081635</td>\n",
              "      <td>0.110028</td>\n",
              "      <td>-0.526280</td>\n",
              "      <td>1.652590</td>\n",
              "      <td>-0.168085</td>\n",
              "      <td>-2.549698</td>\n",
              "      <td>-1.356583</td>\n",
              "      <td>-0.726098</td>\n",
              "      <td>0.369500</td>\n",
              "      <td>0.587124</td>\n",
              "      <td>-0.813821</td>\n",
              "      <td>1.021916</td>\n",
              "      <td>1.691159</td>\n",
              "      <td>1.534646</td>\n",
              "      <td>0.367046</td>\n",
              "      <td>1.303645</td>\n",
              "      <td>0.312184</td>\n",
              "      <td>-1.121137</td>\n",
              "      <td>0.218202</td>\n",
              "      <td>0.879174</td>\n",
              "      <td>1.134611</td>\n",
              "      <td>0.768043</td>\n",
              "      <td>0.587090</td>\n",
              "      <td>0.892701</td>\n",
              "      <td>-0.992398</td>\n",
              "      <td>0.643361</td>\n",
              "      <td>0.437380</td>\n",
              "      <td>-0.381886</td>\n",
              "      <td>0.808164</td>\n",
              "      <td>0.572118</td>\n",
              "      <td>0.968845</td>\n",
              "      <td>-0.180532</td>\n",
              "      <td>-1.329549</td>\n",
              "      <td>1.193094</td>\n",
              "      <td>1.429785</td>\n",
              "      <td>-0.12721</td>\n",
              "      <td>-0.095787</td>\n",
              "      <td>-1.280430</td>\n",
              "      <td>0.523068</td>\n",
              "      <td>1.009331</td>\n",
              "      <td>-1.005935</td>\n",
              "      <td>-1.647872</td>\n",
              "      <td>2.091260</td>\n",
              "      <td>-0.498469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>709524 rows × 111 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        premium_1  has_test_1  response_letter_required_1  \\\n",
              "0             0.0         0.0                         0.0   \n",
              "1             0.0         0.0                         0.0   \n",
              "2             0.0         0.0                         1.0   \n",
              "3             0.0         0.0                         0.0   \n",
              "4             0.0         0.0                         0.0   \n",
              "...           ...         ...                         ...   \n",
              "709519        0.0         0.0                         0.0   \n",
              "709520        0.0         0.0                         0.0   \n",
              "709521        0.0         0.0                         0.0   \n",
              "709522        0.0         0.0                         0.0   \n",
              "709523        0.0         0.0                         0.0   \n",
              "\n",
              "        salary_currency_BYR  salary_currency_EUR  salary_currency_GEL  \\\n",
              "0                       0.0                  0.0                  0.0   \n",
              "1                       0.0                  0.0                  0.0   \n",
              "2                       0.0                  0.0                  0.0   \n",
              "3                       0.0                  0.0                  0.0   \n",
              "4                       0.0                  0.0                  0.0   \n",
              "...                     ...                  ...                  ...   \n",
              "709519                  0.0                  0.0                  0.0   \n",
              "709520                  0.0                  0.0                  0.0   \n",
              "709521                  0.0                  0.0                  0.0   \n",
              "709522                  0.0                  0.0                  0.0   \n",
              "709523                  0.0                  0.0                  0.0   \n",
              "\n",
              "        salary_currency_KGS  salary_currency_KZT  salary_currency_RUR  \\\n",
              "0                       0.0                  0.0                  1.0   \n",
              "1                       0.0                  0.0                  1.0   \n",
              "2                       0.0                  0.0                  1.0   \n",
              "3                       0.0                  0.0                  1.0   \n",
              "4                       0.0                  0.0                  1.0   \n",
              "...                     ...                  ...                  ...   \n",
              "709519                  0.0                  0.0                  1.0   \n",
              "709520                  0.0                  0.0                  1.0   \n",
              "709521                  0.0                  0.0                  1.0   \n",
              "709522                  0.0                  0.0                  1.0   \n",
              "709523                  0.0                  0.0                  1.0   \n",
              "\n",
              "        salary_currency_USD  salary_currency_UZS  salary_gross_1  \\\n",
              "0                       0.0                  0.0             1.0   \n",
              "1                       0.0                  0.0             0.0   \n",
              "2                       0.0                  0.0             0.0   \n",
              "3                       0.0                  0.0             0.0   \n",
              "4                       0.0                  0.0             1.0   \n",
              "...                     ...                  ...             ...   \n",
              "709519                  0.0                  0.0             1.0   \n",
              "709520                  0.0                  0.0             1.0   \n",
              "709521                  0.0                  0.0             0.0   \n",
              "709522                  0.0                  0.0             0.0   \n",
              "709523                  0.0                  0.0             0.0   \n",
              "\n",
              "        type_name_Закрытая  type_name_Открытая  type_name_Рекламная  \\\n",
              "0                      0.0                 1.0                  0.0   \n",
              "1                      0.0                 1.0                  0.0   \n",
              "2                      0.0                 1.0                  0.0   \n",
              "3                      0.0                 1.0                  0.0   \n",
              "4                      0.0                 1.0                  0.0   \n",
              "...                    ...                 ...                  ...   \n",
              "709519                 0.0                 1.0                  0.0   \n",
              "709520                 0.0                 1.0                  0.0   \n",
              "709521                 0.0                 1.0                  0.0   \n",
              "709522                 0.0                 1.0                  0.0   \n",
              "709523                 0.0                 1.0                  0.0   \n",
              "\n",
              "        archived_1  employer_trusted_1  schedule_name_Гибкий график  \\\n",
              "0              1.0                 1.0                          0.0   \n",
              "1              1.0                 1.0                          0.0   \n",
              "2              1.0                 1.0                          0.0   \n",
              "3              0.0                 1.0                          0.0   \n",
              "4              0.0                 1.0                          0.0   \n",
              "...            ...                 ...                          ...   \n",
              "709519         0.0                 1.0                          0.0   \n",
              "709520         0.0                 1.0                          0.0   \n",
              "709521         0.0                 1.0                          0.0   \n",
              "709522         0.0                 1.0                          0.0   \n",
              "709523         0.0                 1.0                          0.0   \n",
              "\n",
              "        schedule_name_Полный день  schedule_name_Сменный график  \\\n",
              "0                             1.0                           0.0   \n",
              "1                             0.0                           1.0   \n",
              "2                             0.0                           1.0   \n",
              "3                             0.0                           0.0   \n",
              "4                             1.0                           0.0   \n",
              "...                           ...                           ...   \n",
              "709519                        0.0                           1.0   \n",
              "709520                        0.0                           1.0   \n",
              "709521                        0.0                           1.0   \n",
              "709522                        1.0                           0.0   \n",
              "709523                        0.0                           0.0   \n",
              "\n",
              "        schedule_name_Удаленная работа  accept_temporary_1  \\\n",
              "0                                  0.0                 0.0   \n",
              "1                                  0.0                 0.0   \n",
              "2                                  0.0                 1.0   \n",
              "3                                  1.0                 1.0   \n",
              "4                                  0.0                 0.0   \n",
              "...                                ...                 ...   \n",
              "709519                             0.0                 0.0   \n",
              "709520                             0.0                 0.0   \n",
              "709521                             0.0                 0.0   \n",
              "709522                             0.0                 1.0   \n",
              "709523                             1.0                 0.0   \n",
              "\n",
              "        accept_incomplete_resumes_1  experience_name_Нет опыта  \\\n",
              "0                               1.0                        0.0   \n",
              "1                               1.0                        1.0   \n",
              "2                               1.0                        1.0   \n",
              "3                               1.0                        0.0   \n",
              "4                               0.0                        0.0   \n",
              "...                             ...                        ...   \n",
              "709519                          1.0                        1.0   \n",
              "709520                          0.0                        0.0   \n",
              "709521                          1.0                        1.0   \n",
              "709522                          0.0                        1.0   \n",
              "709523                          0.0                        1.0   \n",
              "\n",
              "        experience_name_От 1 года до 3 лет  experience_name_От 3 до 6 лет  \\\n",
              "0                                      1.0                            0.0   \n",
              "1                                      0.0                            0.0   \n",
              "2                                      0.0                            0.0   \n",
              "3                                      1.0                            0.0   \n",
              "4                                      0.0                            1.0   \n",
              "...                                    ...                            ...   \n",
              "709519                                 0.0                            0.0   \n",
              "709520                                 0.0                            1.0   \n",
              "709521                                 0.0                            0.0   \n",
              "709522                                 0.0                            0.0   \n",
              "709523                                 0.0                            0.0   \n",
              "\n",
              "        employment_name_Полная занятость  employment_name_Проектная работа  \\\n",
              "0                                    1.0                               0.0   \n",
              "1                                    1.0                               0.0   \n",
              "2                                    1.0                               0.0   \n",
              "3                                    1.0                               0.0   \n",
              "4                                    1.0                               0.0   \n",
              "...                                  ...                               ...   \n",
              "709519                               1.0                               0.0   \n",
              "709520                               1.0                               0.0   \n",
              "709521                               1.0                               0.0   \n",
              "709522                               1.0                               0.0   \n",
              "709523                               0.0                               1.0   \n",
              "\n",
              "        employment_name_Стажировка  employment_name_Частичная занятость  \\\n",
              "0                              0.0                                  0.0   \n",
              "1                              0.0                                  0.0   \n",
              "2                              0.0                                  0.0   \n",
              "3                              0.0                                  0.0   \n",
              "4                              0.0                                  0.0   \n",
              "...                            ...                                  ...   \n",
              "709519                         0.0                                  0.0   \n",
              "709520                         0.0                                  0.0   \n",
              "709521                         0.0                                  0.0   \n",
              "709522                         0.0                                  0.0   \n",
              "709523                         0.0                                  0.0   \n",
              "\n",
              "        working_time_intervals_0_name_Можно сменами по 4-6 часов в день  \\\n",
              "0                                                     0.0                 \n",
              "1                                                     0.0                 \n",
              "2                                                     0.0                 \n",
              "3                                                     0.0                 \n",
              "4                                                     0.0                 \n",
              "...                                                   ...                 \n",
              "709519                                                0.0                 \n",
              "709520                                                0.0                 \n",
              "709521                                                0.0                 \n",
              "709522                                                0.0                 \n",
              "709523                                                0.0                 \n",
              "\n",
              "        working_time_modes_0_name_С началом дня после 16:00  \\\n",
              "0                                                     0.0     \n",
              "1                                                     0.0     \n",
              "2                                                     0.0     \n",
              "3                                                     0.0     \n",
              "4                                                     0.0     \n",
              "...                                                   ...     \n",
              "709519                                                0.0     \n",
              "709520                                                0.0     \n",
              "709521                                                0.0     \n",
              "709522                                                0.0     \n",
              "709523                                                0.0     \n",
              "\n",
              "        working_days_0_name_По субботам и воскресеньям  branding_type_MAKEUP  \\\n",
              "0                                                  0.0                   0.0   \n",
              "1                                                  0.0                   0.0   \n",
              "2                                                  0.0                   0.0   \n",
              "3                                                  0.0                   0.0   \n",
              "4                                                  0.0                   0.0   \n",
              "...                                                ...                   ...   \n",
              "709519                                             0.0                   1.0   \n",
              "709520                                             0.0                   1.0   \n",
              "709521                                             0.0                   1.0   \n",
              "709522                                             0.0                   0.0   \n",
              "709523                                             0.0                   0.0   \n",
              "\n",
              "        branding_type_Unknown  branding_tariff_Unknown  \\\n",
              "0                         1.0                      1.0   \n",
              "1                         1.0                      1.0   \n",
              "2                         1.0                      1.0   \n",
              "3                         1.0                      1.0   \n",
              "4                         1.0                      1.0   \n",
              "...                       ...                      ...   \n",
              "709519                    0.0                      1.0   \n",
              "709520                    0.0                      1.0   \n",
              "709521                    0.0                      1.0   \n",
              "709522                    1.0                      1.0   \n",
              "709523                    1.0                      1.0   \n",
              "\n",
              "        insider_interview_id_1  brand_snippet_logo_Unknown  \\\n",
              "0                          0.0                         1.0   \n",
              "1                          0.0                         1.0   \n",
              "2                          0.0                         1.0   \n",
              "3                          0.0                         1.0   \n",
              "4                          0.0                         1.0   \n",
              "...                        ...                         ...   \n",
              "709519                     1.0                         1.0   \n",
              "709520                     0.0                         1.0   \n",
              "709521                     0.0                         1.0   \n",
              "709522                     0.0                         1.0   \n",
              "709523                     0.0                         1.0   \n",
              "\n",
              "        brand_snippet_picture_Unknown  brand_snippet_background_color_#EF3124  \\\n",
              "0                                 1.0                                     0.0   \n",
              "1                                 1.0                                     0.0   \n",
              "2                                 1.0                                     0.0   \n",
              "3                                 1.0                                     0.0   \n",
              "4                                 1.0                                     0.0   \n",
              "...                               ...                                     ...   \n",
              "709519                            1.0                                     0.0   \n",
              "709520                            1.0                                     0.0   \n",
              "709521                            1.0                                     0.0   \n",
              "709522                            1.0                                     0.0   \n",
              "709523                            1.0                                     0.0   \n",
              "\n",
              "        brand_snippet_background_color_#FF5B29  \\\n",
              "0                                          0.0   \n",
              "1                                          0.0   \n",
              "2                                          0.0   \n",
              "3                                          0.0   \n",
              "4                                          0.0   \n",
              "...                                        ...   \n",
              "709519                                     0.0   \n",
              "709520                                     0.0   \n",
              "709521                                     0.0   \n",
              "709522                                     0.0   \n",
              "709523                                     0.0   \n",
              "\n",
              "        brand_snippet_background_color_Unknown  \\\n",
              "0                                          1.0   \n",
              "1                                          1.0   \n",
              "2                                          1.0   \n",
              "3                                          1.0   \n",
              "4                                          1.0   \n",
              "...                                        ...   \n",
              "709519                                     1.0   \n",
              "709520                                     1.0   \n",
              "709521                                     1.0   \n",
              "709522                                     1.0   \n",
              "709523                                     1.0   \n",
              "\n",
              "        brand_snippet_background_gradient_angle_134.0  \\\n",
              "0                                                 0.0   \n",
              "1                                                 0.0   \n",
              "2                                                 0.0   \n",
              "3                                                 0.0   \n",
              "4                                                 0.0   \n",
              "...                                               ...   \n",
              "709519                                            0.0   \n",
              "709520                                            0.0   \n",
              "709521                                            0.0   \n",
              "709522                                            0.0   \n",
              "709523                                            0.0   \n",
              "\n",
              "        brand_snippet_background_gradient_angle_200.0  \\\n",
              "0                                                 0.0   \n",
              "1                                                 0.0   \n",
              "2                                                 0.0   \n",
              "3                                                 0.0   \n",
              "4                                                 0.0   \n",
              "...                                               ...   \n",
              "709519                                            0.0   \n",
              "709520                                            0.0   \n",
              "709521                                            0.0   \n",
              "709522                                            0.0   \n",
              "709523                                            0.0   \n",
              "\n",
              "        brand_snippet_background_gradient_angle_206.43  \\\n",
              "0                                                  0.0   \n",
              "1                                                  0.0   \n",
              "2                                                  0.0   \n",
              "3                                                  0.0   \n",
              "4                                                  0.0   \n",
              "...                                                ...   \n",
              "709519                                             0.0   \n",
              "709520                                             0.0   \n",
              "709521                                             0.0   \n",
              "709522                                             0.0   \n",
              "709523                                             0.0   \n",
              "\n",
              "        brand_snippet_background_gradient_angle_67.0  \\\n",
              "0                                                0.0   \n",
              "1                                                0.0   \n",
              "2                                                0.0   \n",
              "3                                                0.0   \n",
              "4                                                0.0   \n",
              "...                                              ...   \n",
              "709519                                           0.0   \n",
              "709520                                           0.0   \n",
              "709521                                           0.0   \n",
              "709522                                           0.0   \n",
              "709523                                           0.0   \n",
              "\n",
              "        brand_snippet_background_gradient_angle_Unknown  \\\n",
              "0                                                   1.0   \n",
              "1                                                   1.0   \n",
              "2                                                   1.0   \n",
              "3                                                   1.0   \n",
              "4                                                   1.0   \n",
              "...                                                 ...   \n",
              "709519                                              1.0   \n",
              "709520                                              1.0   \n",
              "709521                                              1.0   \n",
              "709522                                              1.0   \n",
              "709523                                              1.0   \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_0_position_0.0  \\\n",
              "0                                                     0.0             \n",
              "1                                                     0.0             \n",
              "2                                                     0.0             \n",
              "3                                                     0.0             \n",
              "4                                                     0.0             \n",
              "...                                                   ...             \n",
              "709519                                                0.0             \n",
              "709520                                                0.0             \n",
              "709521                                                0.0             \n",
              "709522                                                0.0             \n",
              "709523                                                0.0             \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_0_position_0.52  \\\n",
              "0                                                     0.0              \n",
              "1                                                     0.0              \n",
              "2                                                     0.0              \n",
              "3                                                     0.0              \n",
              "4                                                     0.0              \n",
              "...                                                   ...              \n",
              "709519                                                0.0              \n",
              "709520                                                0.0              \n",
              "709521                                                0.0              \n",
              "709522                                                0.0              \n",
              "709523                                                0.0              \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_0_position_6.96  \\\n",
              "0                                                     0.0              \n",
              "1                                                     0.0              \n",
              "2                                                     0.0              \n",
              "3                                                     0.0              \n",
              "4                                                     0.0              \n",
              "...                                                   ...              \n",
              "709519                                                0.0              \n",
              "709520                                                0.0              \n",
              "709521                                                0.0              \n",
              "709522                                                0.0              \n",
              "709523                                                0.0              \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_0_position_Unknown  \\\n",
              "0                                                     1.0                 \n",
              "1                                                     1.0                 \n",
              "2                                                     1.0                 \n",
              "3                                                     1.0                 \n",
              "4                                                     1.0                 \n",
              "...                                                   ...                 \n",
              "709519                                                1.0                 \n",
              "709520                                                1.0                 \n",
              "709521                                                1.0                 \n",
              "709522                                                1.0                 \n",
              "709523                                                1.0                 \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_1_position_40.0  \\\n",
              "0                                                     0.0              \n",
              "1                                                     0.0              \n",
              "2                                                     0.0              \n",
              "3                                                     0.0              \n",
              "4                                                     0.0              \n",
              "...                                                   ...              \n",
              "709519                                                0.0              \n",
              "709520                                                0.0              \n",
              "709521                                                0.0              \n",
              "709522                                                0.0              \n",
              "709523                                                0.0              \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_1_position_88.86  \\\n",
              "0                                                     0.0               \n",
              "1                                                     0.0               \n",
              "2                                                     0.0               \n",
              "3                                                     0.0               \n",
              "4                                                     0.0               \n",
              "...                                                   ...               \n",
              "709519                                                0.0               \n",
              "709520                                                0.0               \n",
              "709521                                                0.0               \n",
              "709522                                                0.0               \n",
              "709523                                                0.0               \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_1_position_90.95  \\\n",
              "0                                                     0.0               \n",
              "1                                                     0.0               \n",
              "2                                                     0.0               \n",
              "3                                                     0.0               \n",
              "4                                                     0.0               \n",
              "...                                                   ...               \n",
              "709519                                                0.0               \n",
              "709520                                                0.0               \n",
              "709521                                                0.0               \n",
              "709522                                                0.0               \n",
              "709523                                                0.0               \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_1_position_94.48  \\\n",
              "0                                                     0.0               \n",
              "1                                                     0.0               \n",
              "2                                                     0.0               \n",
              "3                                                     0.0               \n",
              "4                                                     0.0               \n",
              "...                                                   ...               \n",
              "709519                                                0.0               \n",
              "709520                                                0.0               \n",
              "709521                                                0.0               \n",
              "709522                                                0.0               \n",
              "709523                                                0.0               \n",
              "\n",
              "        brand_snippet_background_gradient_color_list_1_position_Unknown  \\\n",
              "0                                                     1.0                 \n",
              "1                                                     1.0                 \n",
              "2                                                     1.0                 \n",
              "3                                                     1.0                 \n",
              "4                                                     1.0                 \n",
              "...                                                   ...                 \n",
              "709519                                                1.0                 \n",
              "709520                                                1.0                 \n",
              "709521                                                1.0                 \n",
              "709522                                                1.0                 \n",
              "709523                                                1.0                 \n",
              "\n",
              "        area_name_embed_0  area_name_embed_1  area_name_embed_2  \\\n",
              "0                0.205201          -1.375760          -2.024955   \n",
              "1                0.205201          -1.375760          -2.024955   \n",
              "2                0.205201          -1.375760          -2.024955   \n",
              "3               -0.076298           1.466375          -0.765011   \n",
              "4               -0.314204          -0.015904          -0.415464   \n",
              "...                   ...                ...                ...   \n",
              "709519           1.094439           0.556053          -0.147310   \n",
              "709520           1.094439           0.556053          -0.147310   \n",
              "709521           0.205201          -1.375760          -2.024955   \n",
              "709522          -0.008302           0.563011           0.594524   \n",
              "709523           0.205201          -1.375760          -2.024955   \n",
              "\n",
              "        area_name_embed_3  area_name_embed_4  address_city_embed_0  \\\n",
              "0                2.048965          -0.709423              0.374483   \n",
              "1                2.048965          -0.709423              0.374483   \n",
              "2                2.048965          -0.709423              0.374483   \n",
              "3               -0.231589           0.158975              0.374483   \n",
              "4                1.478273          -0.576059              0.374483   \n",
              "...                   ...                ...                   ...   \n",
              "709519           0.668464          -0.019185             -0.089407   \n",
              "709520           0.668464          -0.019185             -0.089407   \n",
              "709521           2.048965          -0.709423              0.374483   \n",
              "709522          -0.224431          -1.871617             -0.136895   \n",
              "709523           2.048965          -0.709423              0.374483   \n",
              "\n",
              "        address_city_embed_1  address_city_embed_2  address_city_embed_3  \\\n",
              "0                  -0.416950             -1.000886              0.399107   \n",
              "1                  -0.416950             -1.000886              0.399107   \n",
              "2                  -0.416950             -1.000886              0.399107   \n",
              "3                  -0.416950             -1.000886              0.399107   \n",
              "4                  -0.416950             -1.000886              0.399107   \n",
              "...                      ...                   ...                   ...   \n",
              "709519             -0.479558              0.717473             -0.418876   \n",
              "709520             -0.479558              0.717473             -0.418876   \n",
              "709521             -0.416950             -1.000886              0.399107   \n",
              "709522             -2.544892              1.548013              0.406414   \n",
              "709523             -0.416950             -1.000886              0.399107   \n",
              "\n",
              "        address_city_embed_4  address_metro_station_name_embed_0  \\\n",
              "0                   0.078709                            1.456029   \n",
              "1                   0.078709                           -0.125601   \n",
              "2                   0.078709                            1.004128   \n",
              "3                   0.078709                            0.677289   \n",
              "4                   0.078709                            0.480114   \n",
              "...                      ...                                 ...   \n",
              "709519             -1.045492                            0.410558   \n",
              "709520             -1.045492                            1.618188   \n",
              "709521              0.078709                            0.410558   \n",
              "709522              0.943872                           -0.228299   \n",
              "709523              0.078709                            0.410558   \n",
              "\n",
              "        address_metro_station_name_embed_1  \\\n",
              "0                                -1.921303   \n",
              "1                                 0.868352   \n",
              "2                                 1.144209   \n",
              "3                                -0.482713   \n",
              "4                                 0.392200   \n",
              "...                                    ...   \n",
              "709519                            0.081635   \n",
              "709520                           -2.324020   \n",
              "709521                            0.081635   \n",
              "709522                           -1.137940   \n",
              "709523                            0.081635   \n",
              "\n",
              "        address_metro_station_name_embed_2  \\\n",
              "0                                 1.127689   \n",
              "1                                -0.494118   \n",
              "2                                 0.621498   \n",
              "3                                 1.445673   \n",
              "4                                 0.635667   \n",
              "...                                    ...   \n",
              "709519                            0.110028   \n",
              "709520                           -0.723260   \n",
              "709521                            0.110028   \n",
              "709522                            1.040894   \n",
              "709523                            0.110028   \n",
              "\n",
              "        address_metro_station_name_embed_3  \\\n",
              "0                                -0.017080   \n",
              "1                                -0.454782   \n",
              "2                                 1.698946   \n",
              "3                                -0.624957   \n",
              "4                                 0.610692   \n",
              "...                                    ...   \n",
              "709519                           -0.526280   \n",
              "709520                           -0.047075   \n",
              "709521                           -0.526280   \n",
              "709522                            0.155791   \n",
              "709523                           -0.526280   \n",
              "\n",
              "        address_metro_station_name_embed_4  address_metro_line_name_embed_0  \\\n",
              "0                                 0.770425                        -0.016991   \n",
              "1                                 0.634682                         0.700545   \n",
              "2                                 1.542607                         1.912553   \n",
              "3                                 1.506250                         0.546866   \n",
              "4                                 0.782685                        -0.348038   \n",
              "...                                    ...                              ...   \n",
              "709519                            1.652590                        -0.168085   \n",
              "709520                           -0.129131                         1.336465   \n",
              "709521                            1.652590                        -0.168085   \n",
              "709522                           -0.614703                         1.491590   \n",
              "709523                            1.652590                        -0.168085   \n",
              "\n",
              "        address_metro_line_name_embed_1  address_metro_line_name_embed_2  \\\n",
              "0                              0.039101                        -0.289342   \n",
              "1                             -0.450044                        -0.571051   \n",
              "2                              0.262874                         0.682985   \n",
              "3                              0.160707                         1.100105   \n",
              "4                             -0.518628                        -0.128981   \n",
              "...                                 ...                              ...   \n",
              "709519                        -2.549698                        -1.356583   \n",
              "709520                         1.228576                         0.195029   \n",
              "709521                        -2.549698                        -1.356583   \n",
              "709522                        -1.318055                         1.086710   \n",
              "709523                        -2.549698                        -1.356583   \n",
              "\n",
              "        address_metro_line_name_embed_3  address_metro_line_name_embed_4  \\\n",
              "0                              0.754083                         0.581808   \n",
              "1                              0.491362                         1.003180   \n",
              "2                             -0.222405                         0.096435   \n",
              "3                             -0.818940                         2.223594   \n",
              "4                              0.418283                        -0.617086   \n",
              "...                                 ...                              ...   \n",
              "709519                        -0.726098                         0.369500   \n",
              "709520                         1.610126                        -0.613384   \n",
              "709521                        -0.726098                         0.369500   \n",
              "709522                        -1.061597                        -0.481346   \n",
              "709523                        -0.726098                         0.369500   \n",
              "\n",
              "        address_metro_stations_0_line_name_embed_0  \\\n",
              "0                                         0.810224   \n",
              "1                                         1.101166   \n",
              "2                                         0.857687   \n",
              "3                                         0.879781   \n",
              "4                                        -1.453323   \n",
              "...                                            ...   \n",
              "709519                                    0.587124   \n",
              "709520                                   -2.319588   \n",
              "709521                                    0.587124   \n",
              "709522                                   -0.242944   \n",
              "709523                                    0.587124   \n",
              "\n",
              "        address_metro_stations_0_line_name_embed_1  \\\n",
              "0                                         0.717039   \n",
              "1                                         1.218887   \n",
              "2                                         2.283147   \n",
              "3                                        -1.116648   \n",
              "4                                         2.179576   \n",
              "...                                            ...   \n",
              "709519                                   -0.813821   \n",
              "709520                                   -0.750993   \n",
              "709521                                   -0.813821   \n",
              "709522                                   -0.406439   \n",
              "709523                                   -0.813821   \n",
              "\n",
              "        address_metro_stations_0_line_name_embed_2  \\\n",
              "0                                         0.311768   \n",
              "1                                        -0.223936   \n",
              "2                                         0.500787   \n",
              "3                                        -1.571925   \n",
              "4                                         0.317885   \n",
              "...                                            ...   \n",
              "709519                                    1.021916   \n",
              "709520                                   -0.825062   \n",
              "709521                                    1.021916   \n",
              "709522                                    0.594328   \n",
              "709523                                    1.021916   \n",
              "\n",
              "        address_metro_stations_0_line_name_embed_3  \\\n",
              "0                                        -0.422995   \n",
              "1                                         0.053249   \n",
              "2                                         1.910633   \n",
              "3                                         0.943941   \n",
              "4                                         0.223374   \n",
              "...                                            ...   \n",
              "709519                                    1.691159   \n",
              "709520                                    0.280801   \n",
              "709521                                    1.691159   \n",
              "709522                                    0.064523   \n",
              "709523                                    1.691159   \n",
              "\n",
              "        address_metro_stations_0_line_name_embed_4  employer_name_embed_0  \\\n",
              "0                                        -0.413073               0.331369   \n",
              "1                                         0.781730               0.291983   \n",
              "2                                        -1.026238               0.690896   \n",
              "3                                        -0.535612               1.545366   \n",
              "4                                         0.640807              -0.511499   \n",
              "...                                            ...                    ...   \n",
              "709519                                    1.534646               0.865447   \n",
              "709520                                    0.143363               0.338411   \n",
              "709521                                    1.534646               0.878010   \n",
              "709522                                   -1.332344              -1.229636   \n",
              "709523                                    1.534646               0.367046   \n",
              "\n",
              "        employer_name_embed_1  employer_name_embed_2  employer_name_embed_3  \\\n",
              "0                    0.166283              -0.121262              -0.815128   \n",
              "1                   -0.264579               0.164269               1.197892   \n",
              "2                   -0.883298              -1.122004               0.043918   \n",
              "3                    0.094847               0.021632              -2.082036   \n",
              "4                    1.253941               0.580151              -1.178894   \n",
              "...                       ...                    ...                    ...   \n",
              "709519               1.244169               1.467285               0.063808   \n",
              "709520              -0.533607              -0.735669              -0.969695   \n",
              "709521               0.289776               0.853992               0.804243   \n",
              "709522               0.227100               0.150392               0.617529   \n",
              "709523               1.303645               0.312184              -1.121137   \n",
              "\n",
              "        employer_name_embed_4  professional_roles_0_name_embed_0  \\\n",
              "0                    0.145091                          -1.161078   \n",
              "1                   -0.031116                          -0.123503   \n",
              "2                    0.589827                          -0.123503   \n",
              "3                    0.756443                          -0.123503   \n",
              "4                   -1.327576                           0.618574   \n",
              "...                       ...                                ...   \n",
              "709519              -1.063296                           1.368929   \n",
              "709520               0.436879                           0.397344   \n",
              "709521               0.484368                           1.368929   \n",
              "709522               0.994449                          -1.161078   \n",
              "709523               0.218202                           0.879174   \n",
              "\n",
              "        professional_roles_0_name_embed_1  professional_roles_0_name_embed_2  \\\n",
              "0                                1.031893                           1.355590   \n",
              "1                               -0.740737                           0.142345   \n",
              "2                               -0.740737                           0.142345   \n",
              "3                               -0.740737                           0.142345   \n",
              "4                                2.244796                           1.224353   \n",
              "...                                   ...                                ...   \n",
              "709519                           0.890770                          -0.182672   \n",
              "709520                          -1.214816                          -0.931455   \n",
              "709521                           0.890770                          -0.182672   \n",
              "709522                           1.031893                           1.355590   \n",
              "709523                           1.134611                           0.768043   \n",
              "\n",
              "        professional_roles_0_name_embed_3  professional_roles_0_name_embed_4  \\\n",
              "0                                0.399013                          -0.396810   \n",
              "1                                0.747123                          -0.297275   \n",
              "2                                0.747123                          -0.297275   \n",
              "3                                0.747123                          -0.297275   \n",
              "4                               -0.066122                          -1.038721   \n",
              "...                                   ...                                ...   \n",
              "709519                          -0.940307                          -0.841482   \n",
              "709520                          -0.334845                           1.383814   \n",
              "709521                          -0.940307                          -0.841482   \n",
              "709522                           0.399013                          -0.396810   \n",
              "709523                           0.587090                           0.892701   \n",
              "\n",
              "        address_metro_stations_3_station_name_embed_0  \\\n",
              "0                                           -0.992398   \n",
              "1                                           -0.992398   \n",
              "2                                           -0.992398   \n",
              "3                                            0.120368   \n",
              "4                                           -0.992398   \n",
              "...                                               ...   \n",
              "709519                                      -0.992398   \n",
              "709520                                      -0.992398   \n",
              "709521                                      -0.992398   \n",
              "709522                                      -0.992398   \n",
              "709523                                      -0.992398   \n",
              "\n",
              "        address_metro_stations_3_station_name_embed_1  \\\n",
              "0                                            0.643361   \n",
              "1                                            0.643361   \n",
              "2                                            0.643361   \n",
              "3                                           -0.611202   \n",
              "4                                            0.643361   \n",
              "...                                               ...   \n",
              "709519                                       0.643361   \n",
              "709520                                       0.643361   \n",
              "709521                                       0.643361   \n",
              "709522                                       0.643361   \n",
              "709523                                       0.643361   \n",
              "\n",
              "        address_metro_stations_3_station_name_embed_2  \\\n",
              "0                                            0.437380   \n",
              "1                                            0.437380   \n",
              "2                                            0.437380   \n",
              "3                                           -0.460401   \n",
              "4                                            0.437380   \n",
              "...                                               ...   \n",
              "709519                                       0.437380   \n",
              "709520                                       0.437380   \n",
              "709521                                       0.437380   \n",
              "709522                                       0.437380   \n",
              "709523                                       0.437380   \n",
              "\n",
              "        address_metro_stations_3_station_name_embed_3  \\\n",
              "0                                           -0.381886   \n",
              "1                                           -0.381886   \n",
              "2                                           -0.381886   \n",
              "3                                           -1.332100   \n",
              "4                                           -0.381886   \n",
              "...                                               ...   \n",
              "709519                                      -0.381886   \n",
              "709520                                      -0.381886   \n",
              "709521                                      -0.381886   \n",
              "709522                                      -0.381886   \n",
              "709523                                      -0.381886   \n",
              "\n",
              "        address_metro_stations_3_station_name_embed_4  \\\n",
              "0                                            0.808164   \n",
              "1                                            0.808164   \n",
              "2                                            0.808164   \n",
              "3                                            0.592302   \n",
              "4                                            0.808164   \n",
              "...                                               ...   \n",
              "709519                                       0.808164   \n",
              "709520                                       0.808164   \n",
              "709521                                       0.808164   \n",
              "709522                                       0.808164   \n",
              "709523                                       0.808164   \n",
              "\n",
              "        address_metro_stations_3_line_name_embed_0  \\\n",
              "0                                         0.572118   \n",
              "1                                         0.572118   \n",
              "2                                         0.572118   \n",
              "3                                        -0.234597   \n",
              "4                                         0.572118   \n",
              "...                                            ...   \n",
              "709519                                    0.572118   \n",
              "709520                                    0.572118   \n",
              "709521                                    0.572118   \n",
              "709522                                    0.572118   \n",
              "709523                                    0.572118   \n",
              "\n",
              "        address_metro_stations_3_line_name_embed_1  \\\n",
              "0                                         0.968845   \n",
              "1                                         0.968845   \n",
              "2                                         0.968845   \n",
              "3                                         0.188549   \n",
              "4                                         0.968845   \n",
              "...                                            ...   \n",
              "709519                                    0.968845   \n",
              "709520                                    0.968845   \n",
              "709521                                    0.968845   \n",
              "709522                                    0.968845   \n",
              "709523                                    0.968845   \n",
              "\n",
              "        address_metro_stations_3_line_name_embed_2  \\\n",
              "0                                        -0.180532   \n",
              "1                                        -0.180532   \n",
              "2                                        -0.180532   \n",
              "3                                         1.281139   \n",
              "4                                        -0.180532   \n",
              "...                                            ...   \n",
              "709519                                   -0.180532   \n",
              "709520                                   -0.180532   \n",
              "709521                                   -0.180532   \n",
              "709522                                   -0.180532   \n",
              "709523                                   -0.180532   \n",
              "\n",
              "        address_metro_stations_3_line_name_embed_3  \\\n",
              "0                                        -1.329549   \n",
              "1                                        -1.329549   \n",
              "2                                        -1.329549   \n",
              "3                                         0.405284   \n",
              "4                                        -1.329549   \n",
              "...                                            ...   \n",
              "709519                                   -1.329549   \n",
              "709520                                   -1.329549   \n",
              "709521                                   -1.329549   \n",
              "709522                                   -1.329549   \n",
              "709523                                   -1.329549   \n",
              "\n",
              "        address_metro_stations_3_line_name_embed_4  department_name_embed_0  \\\n",
              "0                                         1.193094                 1.429785   \n",
              "1                                         1.193094                 1.429785   \n",
              "2                                         1.193094                 1.429785   \n",
              "3                                        -0.070858                 1.429785   \n",
              "4                                         1.193094                 1.429785   \n",
              "...                                            ...                      ...   \n",
              "709519                                    1.193094                 0.917495   \n",
              "709520                                    1.193094                 1.429785   \n",
              "709521                                    1.193094                 1.429785   \n",
              "709522                                    1.193094                 1.429785   \n",
              "709523                                    1.193094                 1.429785   \n",
              "\n",
              "        department_name_embed_1  department_name_embed_2  \\\n",
              "0                      -0.12721                -0.095787   \n",
              "1                      -0.12721                -0.095787   \n",
              "2                      -0.12721                -0.095787   \n",
              "3                      -0.12721                -0.095787   \n",
              "4                      -0.12721                -0.095787   \n",
              "...                         ...                      ...   \n",
              "709519                 -0.12210                -0.628140   \n",
              "709520                 -0.12721                -0.095787   \n",
              "709521                 -0.12721                -0.095787   \n",
              "709522                 -0.12721                -0.095787   \n",
              "709523                 -0.12721                -0.095787   \n",
              "\n",
              "        department_name_embed_3  department_name_embed_4  category_embed_0  \\\n",
              "0                     -1.280430                 0.523068          0.002329   \n",
              "1                     -1.280430                 0.523068          1.791193   \n",
              "2                     -1.280430                 0.523068         -1.764932   \n",
              "3                     -1.280430                 0.523068          0.002329   \n",
              "4                     -1.280430                 0.523068         -1.014353   \n",
              "...                         ...                      ...               ...   \n",
              "709519                 1.085993                 0.416683          0.140733   \n",
              "709520                -1.280430                 0.523068         -0.385330   \n",
              "709521                -1.280430                 0.523068          0.140733   \n",
              "709522                -1.280430                 0.523068          0.002329   \n",
              "709523                -1.280430                 0.523068          1.009331   \n",
              "\n",
              "        category_embed_1  category_embed_2  category_embed_3  category_embed_4  \n",
              "0              -1.117917          0.386405          0.278955         -0.008147  \n",
              "1              -1.104536          0.068570          0.142405          0.714003  \n",
              "2               1.048306         -0.173701         -0.270792         -0.818727  \n",
              "3              -1.117917          0.386405          0.278955         -0.008147  \n",
              "4              -1.595344          1.735746         -0.232897          1.159243  \n",
              "...                  ...               ...               ...               ...  \n",
              "709519          0.234820         -0.372194          0.416987          0.175681  \n",
              "709520         -0.936141          2.482763         -0.252721          1.277278  \n",
              "709521          0.234820         -0.372194          0.416987          0.175681  \n",
              "709522         -1.117917          0.386405          0.278955         -0.008147  \n",
              "709523         -1.005935         -1.647872          2.091260         -0.498469  \n",
              "\n",
              "[709524 rows x 111 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GINOvCLmDJV",
        "outputId": "587ea009-39d2-4065-926e-96f5e63835fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размеры выборок: Обучающая (425714, 111), Валидационная (141905, 111), Тестовая (141905, 111)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test_val, y_train, y_test_val, = train_test_split(final_data, df['salary'], test_size=0.4, random_state=12345)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=12345)\n",
        "\n",
        "print(f'Размеры выборок: Обучающая {X_train.shape}, Валидационная {X_test.shape}, Тестовая {X_val.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-IT3HLWw2Hz"
      },
      "source": [
        "### Случайный лес с эмбедингами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "330mXDiRmUn4",
        "outputId": "4f515a2b-d321-429a-afb6-6fcf68f13dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
            "Лучшие параметры: {'regressor__max_depth': 15, 'regressor__min_samples_leaf': 2, 'regressor__min_samples_split': 2}\n",
            "Корень из среднеквадратичной ошибки (RMSE): 48970.264067754295\n",
            "R² Score: 0.5416319993914924\n",
            "Средняя абсолютная ошибка (MAE): 25268.431367611895\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 28.27%\n",
            "Медианная абсолютная ошибка (MedAE): 14970.763403016885\n"
          ]
        }
      ],
      "source": [
        "model_dtr = DecisionTreeRegressor(random_state=12345)\n",
        "\n",
        "regressor = TransformedTargetRegressor(\n",
        "    regressor=model_dtr,\n",
        "    func=np.log,\n",
        "    inverse_func=np.exp\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'regressor__max_depth': [10, 11, 12, 13, 14, 15, 16],\n",
        "    'regressor__min_samples_split': [2, 5],\n",
        "    'regressor__min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=regressor,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Лучшие параметры: {best_params}')\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Zj1-594hvP"
      },
      "source": [
        "Случайному лесу создание эмбедингов не принесло никакой информации и никак не улучшило обобщающую способность. Продолжем использщовать изначальный DF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMGBpnDTcZf_"
      },
      "source": [
        "#Полносвязная нейронная сеть\n",
        "\n",
        "Создадим свою нейронную сеть основаную на **Sequentia**\n",
        "И протестируем на разных вариантах архитектур"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGNM4itHw2H1"
      },
      "source": [
        "### Полносвязная нейронная сеть с эмбедингами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu2fa4Dnmv7E"
      },
      "outputs": [],
      "source": [
        "def build_and_train_model(architecture, X_train, y_train, X_test, y_test, epochs=100, batch_size=32):\n",
        "    \"\"\"\n",
        "    Строит и обучает модель с заданной архитектурой\n",
        "\n",
        "    Параметры:\n",
        "    architecture - список, определяющий архитектуру сети (количество нейронов в каждом слое)\n",
        "    X_train, y_train - обучающие данные\n",
        "    X_test, y_test - тестовые данные\n",
        "    epochs - количество эпох обучения\n",
        "    batch_size - размер батча\n",
        "\n",
        "    Возвращает:\n",
        "    model - обученная модель\n",
        "    history - история обучения\n",
        "    metrics - словарь с метриками на тестовых данных\n",
        "    train_time - время обучения\n",
        "    \"\"\"\n",
        "\n",
        "    input_shape = X_train.shape[1]\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(InputLayer(shape=(input_shape,)))\n",
        "    model.add(Dense(architecture[0], activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    for neurons in architecture[1:]:\n",
        "        model.add(Dense(neurons, activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=0\n",
        "    )\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    return model, history, y_pred, train_time, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVSPO85TRqF",
        "outputId": "ab494d5c-a8ec-446a-8542-5008149f58a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 1012.70s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 50941.297970951884\n",
            "R² Score: 0.5039911649265851\n",
            "Средняя абсолютная ошибка (MAE): 29103.112701003913\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 32.33%\n",
            "Медианная абсолютная ошибка (MedAE): 20343.0625\n",
            "\n",
            "Training medium architecture: [128, 64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 1239.07s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 63997.72743782658\n",
            "R² Score: 0.2171500930664486\n",
            "Средняя абсолютная ошибка (MAE): 29133.000331506486\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 31.22%\n",
            "Медианная абсолютная ошибка (MedAE): 18446.55078125\n",
            "\n",
            "Training large architecture: [256, 128, 64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "Training time: 903.88s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 99553.35289036723\n",
            "R² Score: -0.8943541865990701\n",
            "Средняя абсолютная ошибка (MAE): 62541.92347013849\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 107.80%\n",
            "Медианная абсолютная ошибка (MedAE): 48945.900390625\n",
            "\n",
            "Training wide architecture: [512, 256]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step\n",
            "Training time: 1555.23s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 58451.25684594225\n",
            "R² Score: 0.34696402397744963\n",
            "Средняя абсолютная ошибка (MAE): 29016.7892498606\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 31.54%\n",
            "Медианная абсолютная ошибка (MedAE): 19087.1953125\n",
            "\n",
            "Training deep architecture: [64, 64, 64, 64, 64]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "Training time: 991.13s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 58303.6348769263\n",
            "R² Score: 0.35025841752428777\n",
            "Средняя абсолютная ошибка (MAE): 28460.063851204188\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 31.20%\n",
            "Медианная абсолютная ошибка (MedAE): 18813.2734375\n"
          ]
        }
      ],
      "source": [
        "architectures = {\n",
        "    'small': [64, 32],\n",
        "    'medium': [128, 64, 32],\n",
        "    'large': [256, 128, 64, 32],\n",
        "    'wide': [512, 256],\n",
        "    'deep': [64, 64, 64, 64, 64]\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, arch in architectures.items():\n",
        "    print(f\"\\nTraining {name} architecture: {arch}\")\n",
        "    model, history, y_pred, train_time, metrics = build_and_train_model(\n",
        "        arch, X_train, y_train, X_test, y_test\n",
        "    )\n",
        "\n",
        "    results[name] = {\n",
        "        'architecture': arch,\n",
        "        'train_time': train_time,\n",
        "        'metrics': metrics,\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgSKYWFw5pn"
      },
      "source": [
        "## Попробуем улучшить нейронную сеть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwisvill0HpC"
      },
      "outputs": [],
      "source": [
        "def build_and_train_model(architecture, X_train, y_train, X_test, y_test,\n",
        "                          epochs=50,\n",
        "                          batch_size=32,\n",
        "                          norm='batch',\n",
        "                          optimizer='adam',\n",
        "                          learning_rate=0.001,\n",
        "                          dropout=0.2):\n",
        "\n",
        "    input_shape = X_train.shape[1]\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(InputLayer(shape=(input_shape,)))\n",
        "    model.add(Dense(architecture[0], activation='relu'))\n",
        "\n",
        "    if norm == 'batch':\n",
        "        model.add(BatchNormalization())\n",
        "    elif norm == 'layer':\n",
        "        model.add(LayerNormalization())\n",
        "\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    for neurons in architecture[1:]:\n",
        "        model.add(Dense(neurons, activation='relu'))\n",
        "        if norm == 'batch':\n",
        "            model.add(BatchNormalization())\n",
        "        elif norm == 'layer':\n",
        "            model.add(LayerNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9, clipnorm=1)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    return model, history, y_pred, train_time, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzZ9cxW8yYUG"
      },
      "source": [
        "1. Попробуем нормализацию по батчам и по слоям"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T99jZv1Hb2Tk",
        "outputId": "5416638f-71d3-408c-aa6c-202cfcbc4b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - loss: 14569798656.0000 - mae: 88045.1875 - val_loss: 11746809856.0000 - val_mae: 83408.5000\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 20008044544.0000 - mae: 78276.3984 - val_loss: 8272483328.0000 - val_mae: 64880.9570\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 22606891008.0000 - mae: 59471.1953 - val_loss: 4919746560.0000 - val_mae: 42189.9961\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11112892416.0000 - mae: 38715.8320 - val_loss: 3031486208.0000 - val_mae: 28739.7422\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 11658013696.0000 - mae: 30686.9883 - val_loss: 2912188416.0000 - val_mae: 27899.6777\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7970615296.0000 - mae: 30632.7070 - val_loss: 2688742656.0000 - val_mae: 28104.9512\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 10558289920.0000 - mae: 30847.7910 - val_loss: 3779744256.0000 - val_mae: 28291.4180\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7598462464.0000 - mae: 30879.6699 - val_loss: 3510832896.0000 - val_mae: 28608.0684\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 8130333696.0000 - mae: 30648.5645 - val_loss: 6359897600.0000 - val_mae: 28776.8105\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 7743491072.0000 - mae: 30905.1953 - val_loss: 5011165696.0000 - val_mae: 29246.0078\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 9431328768.0000 - mae: 30873.0430 - val_loss: 10053301248.0000 - val_mae: 28203.1445\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6219184640.0000 - mae: 30535.5117 - val_loss: 64392282112.0000 - val_mae: 32092.3398\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 5803076096.0000 - mae: 30668.2949 - val_loss: 13077980160.0000 - val_mae: 30120.7305\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 11653189632.0000 - mae: 30652.2383 - val_loss: 4353332224.0000 - val_mae: 29193.6289\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 16844128256.0000 - mae: 30972.1582 - val_loss: 6629719552.0000 - val_mae: 29321.5410\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 7769492992.0000 - mae: 30743.6582 - val_loss: 10789031936.0000 - val_mae: 30445.3086\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
            "Training time: 1007.44s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 51853.079279776364\n",
            "R² Score: 0.4860764688675544\n",
            "Средняя абсолютная ошибка (MAE): 28104.98361313245\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 31.24%\n",
            "Медианная абсолютная ошибка (MedAE): 18523.874999999993\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='batch',\n",
        "                          optimizer='adam', learning_rate=0.001)\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRFCd72HVx3T",
        "outputId": "69b0c7ba-90fe-4ded-ac4f-d72a685f0ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - loss: 14577665024.0000 - mae: 87028.7031 - val_loss: 10671672320.0000 - val_mae: 73856.6094\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 23649177600.0000 - mae: 67305.3828 - val_loss: 6778035712.0000 - val_mae: 45056.0742\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 12787627008.0000 - mae: 42728.3906 - val_loss: 5265594880.0000 - val_mae: 40915.8008\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8096053760.0000 - mae: 39109.3477 - val_loss: 4332970496.0000 - val_mae: 32079.2090\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 9174734848.0000 - mae: 32802.5391 - val_loss: 3982244864.0000 - val_mae: 29937.6270\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 8157485568.0000 - mae: 31493.6738 - val_loss: 3813918208.0000 - val_mae: 29201.7363\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 17756825600.0000 - mae: 30939.0625 - val_loss: 3737719552.0000 - val_mae: 29244.3828\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 5423637504.0000 - mae: 30168.7207 - val_loss: 3678513664.0000 - val_mae: 28385.4375\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 8304157184.0000 - mae: 30030.2852 - val_loss: 3639394048.0000 - val_mae: 27917.7012\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11604557824.0000 - mae: 29742.3340 - val_loss: 3621491968.0000 - val_mae: 28606.2500\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 6301154816.0000 - mae: 29405.2031 - val_loss: 3594530560.0000 - val_mae: 27873.7773\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 7746177536.0000 - mae: 29290.7598 - val_loss: 3573779200.0000 - val_mae: 28067.5957\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 17737451520.0000 - mae: 29405.6895 - val_loss: 3558142208.0000 - val_mae: 27607.0254\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 9421441024.0000 - mae: 29154.2246 - val_loss: 3554188800.0000 - val_mae: 27083.3008\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7821973504.0000 - mae: 29114.3828 - val_loss: 3541293568.0000 - val_mae: 27311.5352\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 19130572800.0000 - mae: 29201.5430 - val_loss: 3523095040.0000 - val_mae: 27812.9805\n",
            "Epoch 17/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8357168128.0000 - mae: 28924.0742 - val_loss: 3521331200.0000 - val_mae: 27954.0215\n",
            "Epoch 18/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 13835412480.0000 - mae: 29076.9531 - val_loss: 3533883904.0000 - val_mae: 27028.9805\n",
            "Epoch 19/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 9312473088.0000 - mae: 28892.0078 - val_loss: 3504848128.0000 - val_mae: 27706.8730\n",
            "Epoch 20/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 9656415232.0000 - mae: 28805.4316 - val_loss: 3500858880.0000 - val_mae: 27916.7402\n",
            "Epoch 21/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 8352654336.0000 - mae: 28816.7949 - val_loss: 3480234752.0000 - val_mae: 27062.8789\n",
            "Epoch 22/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 19697471488.0000 - mae: 29172.5078 - val_loss: 3499738624.0000 - val_mae: 28383.9336\n",
            "Epoch 23/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 10397029376.0000 - mae: 28883.3809 - val_loss: 3478781440.0000 - val_mae: 27250.0566\n",
            "Epoch 24/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 9833143296.0000 - mae: 28789.4238 - val_loss: 3474398208.0000 - val_mae: 27128.9102\n",
            "Epoch 25/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 4602299392.0000 - mae: 28648.6074 - val_loss: 3890011136.0000 - val_mae: 34803.2695\n",
            "Epoch 26/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 5345153024.0000 - mae: 28884.4375 - val_loss: 3456864512.0000 - val_mae: 27218.6953\n",
            "Epoch 27/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 6932998144.0000 - mae: 28641.8984 - val_loss: 3454242560.0000 - val_mae: 27640.5000\n",
            "Epoch 28/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 4407492096.0000 - mae: 28504.7383 - val_loss: 3460995328.0000 - val_mae: 27216.9629\n",
            "Epoch 29/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 17658681344.0000 - mae: 29042.5723 - val_loss: 3449594880.0000 - val_mae: 27267.1992\n",
            "Epoch 30/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 10882663424.0000 - mae: 28735.9902 - val_loss: 3429071872.0000 - val_mae: 27246.7988\n",
            "Epoch 31/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9904425984.0000 - mae: 28863.3828 - val_loss: 3445678336.0000 - val_mae: 27642.9082\n",
            "Epoch 32/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 24928954368.0000 - mae: 29133.3086 - val_loss: 3500643072.0000 - val_mae: 27088.4355\n",
            "Epoch 33/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 28475602944.0000 - mae: 29211.9727 - val_loss: 3443047168.0000 - val_mae: 27450.8438\n",
            "Epoch 34/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 12684272640.0000 - mae: 28819.9805 - val_loss: 3422124800.0000 - val_mae: 27123.9121\n",
            "Epoch 35/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6156611584.0000 - mae: 28466.0840 - val_loss: 3435326720.0000 - val_mae: 27448.8184\n",
            "Epoch 36/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8745768960.0000 - mae: 28803.3672 - val_loss: 3441702912.0000 - val_mae: 27460.6465\n",
            "Epoch 37/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 15555674112.0000 - mae: 28897.9355 - val_loss: 3405316352.0000 - val_mae: 27072.3066\n",
            "Epoch 38/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 5571586560.0000 - mae: 28560.5137 - val_loss: 3415515392.0000 - val_mae: 27341.1523\n",
            "Epoch 39/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 9354486784.0000 - mae: 28894.6191 - val_loss: 3401296896.0000 - val_mae: 27227.5020\n",
            "Epoch 40/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6311590400.0000 - mae: 28661.7461 - val_loss: 3413732096.0000 - val_mae: 27462.0312\n",
            "Epoch 41/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 7424967680.0000 - mae: 28738.2070 - val_loss: 3385313024.0000 - val_mae: 27082.4160\n",
            "Epoch 42/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 7582870016.0000 - mae: 28507.4414 - val_loss: 3413749248.0000 - val_mae: 27385.1191\n",
            "Epoch 43/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9150191616.0000 - mae: 28895.7148 - val_loss: 3402494208.0000 - val_mae: 28028.0371\n",
            "Epoch 44/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8020752896.0000 - mae: 28874.8398 - val_loss: 3408754432.0000 - val_mae: 26977.4590\n",
            "Epoch 45/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 4796596224.0000 - mae: 28682.5762 - val_loss: 3386188288.0000 - val_mae: 27195.1680\n",
            "Epoch 46/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 13425160192.0000 - mae: 28512.7910 - val_loss: 3370581248.0000 - val_mae: 27743.5312\n",
            "Epoch 47/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 11251582976.0000 - mae: 28738.0898 - val_loss: 3404254208.0000 - val_mae: 27421.4062\n",
            "Epoch 48/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 7156005376.0000 - mae: 28621.1992 - val_loss: 3396506624.0000 - val_mae: 27321.3867\n",
            "Epoch 49/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 5995734528.0000 - mae: 28639.4648 - val_loss: 3397156864.0000 - val_mae: 27249.4277\n",
            "Epoch 50/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 6277847040.0000 - mae: 28668.8047 - val_loss: 3358828544.0000 - val_mae: 27787.0566\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
            "Training time: 3226.72s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 57955.38897880252\n",
            "R² Score: 0.35799701186262844\n",
            "Средняя абсолютная ошибка (MAE): 27787.083629775952\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 30.88%\n",
            "Медианная абсолютная ошибка (MedAE): 18780.484375\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='layer',\n",
        "                          optimizer='adam', learning_rate=0.001)\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJYM-gWCzUz8"
      },
      "source": [
        "лучше рузультат у batchnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z-nrXRfzbhy"
      },
      "source": [
        "2. Вместо adam оптимизатора попробуем sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6CIssn-n87q",
        "outputId": "92b03738-eac7-47d2-b901-13dc45f93219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 18110072832.0000 - mae: 87330.8906 - val_loss: 9499155456.0000 - val_mae: 71680.7422\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3ms/step - loss: 8890734592.0000 - mae: 61910.0352 - val_loss: 4389327360.0000 - val_mae: 31759.1758\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 12017816576.0000 - mae: 32611.0312 - val_loss: 3899975424.0000 - val_mae: 29252.4141\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 9159672832.0000 - mae: 31949.0430 - val_loss: 3853399808.0000 - val_mae: 28825.4316\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 12084412416.0000 - mae: 31608.4805 - val_loss: 3848325632.0000 - val_mae: 28606.1992\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6973356032.0000 - mae: 31246.0840 - val_loss: 3823539456.0000 - val_mae: 28605.9863\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 12489183232.0000 - mae: 31210.2461 - val_loss: 3772775680.0000 - val_mae: 28125.9961\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 12228338688.0000 - mae: 31170.4375 - val_loss: 3772887040.0000 - val_mae: 28014.4102\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6249400320.0000 - mae: 30771.3750 - val_loss: 3762851840.0000 - val_mae: 28238.3164\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 10524847104.0000 - mae: 30883.0996 - val_loss: 3749775360.0000 - val_mae: 27734.8184\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 10161698816.0000 - mae: 30569.6895 - val_loss: 3705049600.0000 - val_mae: 27893.8145\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 7853149184.0000 - mae: 30562.1211 - val_loss: 3751024640.0000 - val_mae: 27695.5723\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 6737869824.0000 - mae: 30444.9805 - val_loss: 3654107904.0000 - val_mae: 27786.7500\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 18337937408.0000 - mae: 30486.3418 - val_loss: 3667244800.0000 - val_mae: 28417.7012\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 7785605120.0000 - mae: 30446.1465 - val_loss: 3552914944.0000 - val_mae: 27653.8496\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 10870961152.0000 - mae: 30442.0020 - val_loss: 3567841280.0000 - val_mae: 27823.0605\n",
            "Epoch 17/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9427170304.0000 - mae: 30355.2188 - val_loss: 3588383488.0000 - val_mae: 27488.0410\n",
            "Epoch 18/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 5069086208.0000 - mae: 29933.6777 - val_loss: 3422875904.0000 - val_mae: 27428.6328\n",
            "Epoch 19/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 5555473920.0000 - mae: 29939.4727 - val_loss: 3408386816.0000 - val_mae: 27497.1328\n",
            "Epoch 20/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9862804480.0000 - mae: 30050.8691 - val_loss: 3373707776.0000 - val_mae: 27342.4023\n",
            "Epoch 21/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 10373965824.0000 - mae: 30071.5273 - val_loss: 3371621120.0000 - val_mae: 27346.8398\n",
            "Epoch 22/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 10783746048.0000 - mae: 29938.4434 - val_loss: 3297078016.0000 - val_mae: 27267.2891\n",
            "Epoch 23/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 9103992832.0000 - mae: 29957.0254 - val_loss: 3281493760.0000 - val_mae: 27369.7969\n",
            "Epoch 24/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 8106329088.0000 - mae: 30013.3008 - val_loss: 3282649088.0000 - val_mae: 27738.0527\n",
            "Epoch 25/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 11046511616.0000 - mae: 30012.7051 - val_loss: 3278432000.0000 - val_mae: 27350.7148\n",
            "Epoch 26/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 23602501632.0000 - mae: 30060.7559 - val_loss: 3353079808.0000 - val_mae: 27817.4512\n",
            "Epoch 27/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 25445130240.0000 - mae: 30183.9219 - val_loss: 3378285568.0000 - val_mae: 27236.3789\n",
            "Epoch 28/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 20281372672.0000 - mae: 29814.5156 - val_loss: 3301936640.0000 - val_mae: 27374.1680\n",
            "Epoch 29/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 10135640064.0000 - mae: 29831.7578 - val_loss: 3219421440.0000 - val_mae: 27046.4688\n",
            "Epoch 30/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6668112896.0000 - mae: 29623.9746 - val_loss: 3326370560.0000 - val_mae: 27454.0273\n",
            "Epoch 31/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 6245749248.0000 - mae: 29586.1621 - val_loss: 3226210048.0000 - val_mae: 27119.5078\n",
            "Epoch 32/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 15675471872.0000 - mae: 29984.4375 - val_loss: 3343241216.0000 - val_mae: 27651.0195\n",
            "Epoch 33/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 7445922816.0000 - mae: 29655.2305 - val_loss: 3369028352.0000 - val_mae: 27397.3887\n",
            "Epoch 34/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 6230409728.0000 - mae: 29527.1445 - val_loss: 3226214144.0000 - val_mae: 27870.9004\n",
            "Epoch 35/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 13193475072.0000 - mae: 29758.2891 - val_loss: 3276073216.0000 - val_mae: 27124.1426\n",
            "Epoch 36/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 32968988672.0000 - mae: 30014.3125 - val_loss: 3338366208.0000 - val_mae: 27527.1582\n",
            "Epoch 37/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 16842598400.0000 - mae: 29918.0762 - val_loss: 3293873152.0000 - val_mae: 27648.2715\n",
            "Epoch 38/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 11215696896.0000 - mae: 29594.0898 - val_loss: 3467099392.0000 - val_mae: 27689.5469\n",
            "Epoch 39/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3ms/step - loss: 6583868928.0000 - mae: 29594.4434 - val_loss: 3234982400.0000 - val_mae: 27664.3438\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 2338.59s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 56739.933067225895\n",
            "R² Score: 0.3846431524412033\n",
            "Средняя абсолютная ошибка (MAE): 27046.46066225257\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 29.85%\n",
            "Медианная абсолютная ошибка (MedAE): 17030.640625\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='batch',\n",
        "                          optimizer='sgd', learning_rate=0.001)\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69FcKU3j0BBn"
      },
      "source": [
        "рузультат хуже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrqtrOHx0M6U"
      },
      "outputs": [],
      "source": [
        "def build_and_train_model(architecture, X_train, y_train, X_test, y_test,\n",
        "                          epochs=50,\n",
        "                          batch_size=32,\n",
        "                          norm='batch',\n",
        "                          optimizer='adam',\n",
        "                          learning_rate=0.001,\n",
        "                          dropout=0.2,\n",
        "                          initializer='he_normal'):\n",
        "\n",
        "    input_shape = X_train.shape[1]\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(InputLayer(shape=(input_shape,)))\n",
        "    model.add(Dense(architecture[0], activation='relu',\n",
        "                    kernel_initializer=initializer))\n",
        "\n",
        "    if norm == 'batch':\n",
        "        model.add(BatchNormalization())\n",
        "    elif norm == 'layer':\n",
        "        model.add(LayerNormalization())\n",
        "\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    for neurons in architecture[1:]:\n",
        "        model.add(Dense(neurons, activation='relu', kernel_initializer=initializer))\n",
        "        if norm == 'batch':\n",
        "            model.add(BatchNormalization())\n",
        "        elif norm == 'layer':\n",
        "            model.add(LayerNormalization())\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer == 'sgd':\n",
        "        optimizer = SGD(learning_rate=learning_rate, momentum=0.9, clipnorm=1)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "    metrics = {\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R2': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    return model, history, y_pred, train_time, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ccgPrtR0CxT"
      },
      "source": [
        "3. Попробуем добавить инициализацию весов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ALH103MDQ7",
        "outputId": "6ec768a9-eac1-4680-d8a9-8d1f5de14a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - loss: 17217370112.0000 - mae: 88269.1797 - val_loss: 11391233024.0000 - val_mae: 81347.8750\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - loss: 15828764672.0000 - mae: 77875.5156 - val_loss: 7955078656.0000 - val_mae: 64135.5664\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 10046084096.0000 - mae: 59220.5156 - val_loss: 5109677056.0000 - val_mae: 42636.3945\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 13028814848.0000 - mae: 38886.4297 - val_loss: 3536107264.0000 - val_mae: 28978.2988\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 12185419776.0000 - mae: 30524.8418 - val_loss: 3464095488.0000 - val_mae: 28364.0312\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 19371063296.0000 - mae: 31124.2363 - val_loss: 3346642432.0000 - val_mae: 28789.0098\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 7373279744.0000 - mae: 31114.7305 - val_loss: 3720022016.0000 - val_mae: 29450.1270\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 9082951680.0000 - mae: 31023.7910 - val_loss: 3541901056.0000 - val_mae: 29001.0469\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 7218125824.0000 - mae: 30925.6543 - val_loss: 4018424320.0000 - val_mae: 29329.2246\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 14717040640.0000 - mae: 31141.3262 - val_loss: 4183159552.0000 - val_mae: 30391.2461\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 7842132480.0000 - mae: 30870.2559 - val_loss: 4689335808.0000 - val_mae: 29092.7402\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 8841400320.0000 - mae: 30872.0000 - val_loss: 5108596224.0000 - val_mae: 29212.3750\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 12573528064.0000 - mae: 30831.2461 - val_loss: 3655288064.0000 - val_mae: 29139.9473\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 10242495488.0000 - mae: 30776.3887 - val_loss: 9586555904.0000 - val_mae: 30017.0957\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9572612096.0000 - mae: 30958.4824 - val_loss: 5058691072.0000 - val_mae: 29593.8770\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 5928829952.0000 - mae: 30812.0508 - val_loss: 6214903296.0000 - val_mae: 29345.7422\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
            "Training time: 994.55s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 57850.17083737573\n",
            "R² Score: 0.36032601158029787\n",
            "Средняя абсолютная ошибка (MAE): 28788.989225150493\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 31.83%\n",
            "Медианная абсолютная ошибка (MedAE): 19358.6015625\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='batch',\n",
        "                          optimizer='adam', learning_rate=0.001,\n",
        "                          initializer='he_normal')\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnLN642bDvgd",
        "outputId": "38c7d8d2-8748-4796-d373-1b84f72f8015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - loss: 15399426048.0000 - mae: 86962.5000 - val_loss: 10698916864.0000 - val_mae: 74038.7344\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4ms/step - loss: 28157966336.0000 - mae: 67430.0312 - val_loss: 6773771776.0000 - val_mae: 45026.3945\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - loss: 9473038336.0000 - mae: 42577.0352 - val_loss: 5262173184.0000 - val_mae: 40980.4102\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 8028119040.0000 - mae: 39915.4453 - val_loss: 4342133248.0000 - val_mae: 32681.6816\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 10630411264.0000 - mae: 32699.3203 - val_loss: 3955458048.0000 - val_mae: 29368.4082\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 11717051392.0000 - mae: 31493.7344 - val_loss: 3814597888.0000 - val_mae: 29003.5117\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 12291088384.0000 - mae: 30951.5117 - val_loss: 3726375168.0000 - val_mae: 28758.5176\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 18464043008.0000 - mae: 30558.8105 - val_loss: 3694521088.0000 - val_mae: 28965.2773\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4ms/step - loss: 7322102272.0000 - mae: 29953.7461 - val_loss: 3661570816.0000 - val_mae: 29138.0879\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - loss: 11093483520.0000 - mae: 29903.5918 - val_loss: 3610959104.0000 - val_mae: 27719.5273\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - loss: 18463748096.0000 - mae: 29745.4512 - val_loss: 3607956224.0000 - val_mae: 27632.3418\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - loss: 10775288832.0000 - mae: 29653.9707 - val_loss: 3577038336.0000 - val_mae: 27479.2715\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4ms/step - loss: 7474314240.0000 - mae: 29212.4414 - val_loss: 3561890560.0000 - val_mae: 27416.6895\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 14735082496.0000 - mae: 29405.7695 - val_loss: 3544297984.0000 - val_mae: 27844.9824\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 4ms/step - loss: 7430947840.0000 - mae: 28828.2363 - val_loss: 3540286464.0000 - val_mae: 27806.4570\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 5723455488.0000 - mae: 29077.0352 - val_loss: 3526056704.0000 - val_mae: 27575.6836\n",
            "Epoch 17/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 9068908544.0000 - mae: 28953.1445 - val_loss: 3511515136.0000 - val_mae: 27056.4219\n",
            "Epoch 18/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 9315459072.0000 - mae: 28735.1836 - val_loss: 3504064512.0000 - val_mae: 27028.7344\n",
            "Epoch 19/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 7917801472.0000 - mae: 28834.0762 - val_loss: 3490874624.0000 - val_mae: 27552.1445\n",
            "Epoch 20/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 7763926016.0000 - mae: 28634.3008 - val_loss: 3489754624.0000 - val_mae: 27719.9316\n",
            "Epoch 21/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - loss: 6584118272.0000 - mae: 28776.6641 - val_loss: 3823165184.0000 - val_mae: 33634.7617\n",
            "Epoch 22/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4ms/step - loss: 9772349440.0000 - mae: 28977.0449 - val_loss: 3474893056.0000 - val_mae: 27182.7500\n",
            "Epoch 23/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 9799994368.0000 - mae: 28747.2168 - val_loss: 3458566912.0000 - val_mae: 27191.0898\n",
            "Epoch 24/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4ms/step - loss: 5806806016.0000 - mae: 28699.5488 - val_loss: 3455632384.0000 - val_mae: 26742.5078\n",
            "Epoch 25/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 5098509312.0000 - mae: 28340.8398 - val_loss: 3479008512.0000 - val_mae: 26868.1289\n",
            "Epoch 26/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - loss: 8599115776.0000 - mae: 28614.5234 - val_loss: 3462846720.0000 - val_mae: 27152.0820\n",
            "Epoch 27/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 11301509120.0000 - mae: 28572.9238 - val_loss: 3449485312.0000 - val_mae: 26820.6426\n",
            "Epoch 28/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 12719875072.0000 - mae: 28474.5527 - val_loss: 3419369216.0000 - val_mae: 26940.9883\n",
            "Epoch 29/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4ms/step - loss: 6070976000.0000 - mae: 28499.3926 - val_loss: 3428305920.0000 - val_mae: 27004.2988\n",
            "Epoch 30/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 5528727040.0000 - mae: 28438.4746 - val_loss: 3416605440.0000 - val_mae: 27243.6328\n",
            "Epoch 31/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - loss: 19875956736.0000 - mae: 28879.9141 - val_loss: 3417493504.0000 - val_mae: 26872.9980\n",
            "Epoch 32/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 7225951744.0000 - mae: 28362.9922 - val_loss: 3399693568.0000 - val_mae: 26912.4805\n",
            "Epoch 33/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4ms/step - loss: 4551832064.0000 - mae: 28329.8008 - val_loss: 3436346624.0000 - val_mae: 27475.7422\n",
            "Epoch 34/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 12714420224.0000 - mae: 28823.6855 - val_loss: 3391047936.0000 - val_mae: 27004.5801\n",
            "Epoch 35/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 28026624000.0000 - mae: 29063.4688 - val_loss: 3389654272.0000 - val_mae: 27160.6211\n",
            "Epoch 36/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - loss: 7569732096.0000 - mae: 28365.2168 - val_loss: 3381936640.0000 - val_mae: 26951.0586\n",
            "Epoch 37/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 15223359488.0000 - mae: 28463.4043 - val_loss: 3406327808.0000 - val_mae: 27046.3457\n",
            "Epoch 38/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4ms/step - loss: 5656058880.0000 - mae: 28262.7578 - val_loss: 3397936384.0000 - val_mae: 27191.8789\n",
            "Epoch 39/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 4959628288.0000 - mae: 28348.3691 - val_loss: 3374590720.0000 - val_mae: 27053.6836\n",
            "Epoch 40/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 11769849856.0000 - mae: 28563.5879 - val_loss: 3381153280.0000 - val_mae: 27182.9141\n",
            "Epoch 41/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - loss: 6053552640.0000 - mae: 28324.3867 - val_loss: 3357093120.0000 - val_mae: 26941.7559\n",
            "Epoch 42/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3ms/step - loss: 3798636032.0000 - mae: 28177.9238 - val_loss: 3509848320.0000 - val_mae: 30596.8438\n",
            "Epoch 43/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 6460985344.0000 - mae: 28357.4023 - val_loss: 3372699136.0000 - val_mae: 26786.6191\n",
            "Epoch 44/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - loss: 6759150592.0000 - mae: 28547.5605 - val_loss: 3358391552.0000 - val_mae: 26741.1680\n",
            "Epoch 45/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7781915648.0000 - mae: 28508.3066 - val_loss: 3378884864.0000 - val_mae: 27213.9453\n",
            "Epoch 46/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - loss: 13313030144.0000 - mae: 28517.3477 - val_loss: 3358231296.0000 - val_mae: 26870.1172\n",
            "Epoch 47/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 4ms/step - loss: 8786806784.0000 - mae: 28538.9961 - val_loss: 3349053952.0000 - val_mae: 26955.2070\n",
            "Epoch 48/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - loss: 6785289216.0000 - mae: 28452.2930 - val_loss: 3340902912.0000 - val_mae: 27271.5234\n",
            "Epoch 49/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 4ms/step - loss: 10942002176.0000 - mae: 28374.2324 - val_loss: 3327699712.0000 - val_mae: 26823.8809\n",
            "Epoch 50/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4ms/step - loss: 16784541696.0000 - mae: 28520.1230 - val_loss: 3323313664.0000 - val_mae: 26941.1914\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
            "Training time: 3205.86s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 57648.22837455394\n",
            "R² Score: 0.3647841445001343\n",
            "Средняя абсолютная ошибка (MAE): 26941.194814670434\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 30.10%\n",
            "Медианная абсолютная ошибка (MedAE): 17837.6796875\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='layer',\n",
        "                          optimizer='adam', learning_rate=0.001,\n",
        "                          initializer='he_normal')\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqbDDYOq2cvk",
        "outputId": "efbb31dc-656d-4e8e-acbd-d8ddef508e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3ms/step - loss: 16198064128.0000 - mae: 88131.8984 - val_loss: 11275617280.0000 - val_mae: 80690.5469\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11789763584.0000 - mae: 77674.0000 - val_loss: 7910936064.0000 - val_mae: 62578.3477\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11138646016.0000 - mae: 58718.6602 - val_loss: 5198035968.0000 - val_mae: 42467.7773\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 12154558464.0000 - mae: 38897.1055 - val_loss: 3833204480.0000 - val_mae: 30121.7305\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 11615273984.0000 - mae: 30703.7129 - val_loss: 3500268288.0000 - val_mae: 28966.8809\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 8904513536.0000 - mae: 30740.3027 - val_loss: 3301459456.0000 - val_mae: 28906.5781\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 12243918848.0000 - mae: 31104.0996 - val_loss: 3302234112.0000 - val_mae: 28715.1719\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 6373875200.0000 - mae: 30904.8926 - val_loss: 3352250624.0000 - val_mae: 28531.2871\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 15162571776.0000 - mae: 31245.4590 - val_loss: 3373444608.0000 - val_mae: 27852.5312\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 8618337280.0000 - mae: 30790.5488 - val_loss: 3642604288.0000 - val_mae: 28107.2754\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 13283801088.0000 - mae: 30851.5488 - val_loss: 3934900224.0000 - val_mae: 28363.7695\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 9942752256.0000 - mae: 30782.8750 - val_loss: 4435074048.0000 - val_mae: 28481.4238\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 12287432704.0000 - mae: 30812.7168 - val_loss: 3945276416.0000 - val_mae: 28952.8438\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7264267776.0000 - mae: 30993.5410 - val_loss: 4513320448.0000 - val_mae: 28620.4238\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 13599332352.0000 - mae: 30779.1602 - val_loss: 3565409024.0000 - val_mae: 28329.8750\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 9081585664.0000 - mae: 30853.8809 - val_loss: 3952963584.0000 - val_mae: 29271.9551\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 966.91s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 57458.32583872369\n",
            "R² Score: 0.3689622578376527\n",
            "Средняя абсолютная ошибка (MAE): 28906.59917908273\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 32.10%\n",
            "Медианная абсолютная ошибка (MedAE): 19762.984375\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='batch',\n",
        "                          optimizer='adam', learning_rate=0.001,\n",
        "                          initializer='glorot_uniform')\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXrUK_fuNNOn",
        "outputId": "37c0bae9-d002-4c7f-f8bf-ad3a793788e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - loss: 16716733440.0000 - mae: 87155.6953 - val_loss: 10677915648.0000 - val_mae: 73898.3984\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3ms/step - loss: 16449483776.0000 - mae: 66940.8281 - val_loss: 6772810240.0000 - val_mae: 45019.7266\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11030131712.0000 - mae: 42757.9141 - val_loss: 5258724352.0000 - val_mae: 41041.5000\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 25328199680.0000 - mae: 38429.4453 - val_loss: 4257460992.0000 - val_mae: 31322.4180\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 9073805312.0000 - mae: 32374.2070 - val_loss: 3920040704.0000 - val_mae: 29525.3828\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 5730142720.0000 - mae: 30846.3691 - val_loss: 3805857280.0000 - val_mae: 29141.4492\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 6836457984.0000 - mae: 30137.8066 - val_loss: 3708528384.0000 - val_mae: 28365.1973\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 13641604096.0000 - mae: 30097.2637 - val_loss: 3656403712.0000 - val_mae: 28161.8359\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 9968880640.0000 - mae: 29500.9805 - val_loss: 3617980928.0000 - val_mae: 27916.3125\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9461273600.0000 - mae: 29288.6055 - val_loss: 3590930688.0000 - val_mae: 27972.1289\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 16050887680.0000 - mae: 29418.5586 - val_loss: 3601887232.0000 - val_mae: 27528.9980\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 29704824832.0000 - mae: 29598.8203 - val_loss: 3568696064.0000 - val_mae: 27473.8711\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - loss: 10261017600.0000 - mae: 28864.2148 - val_loss: 3566683648.0000 - val_mae: 28082.5820\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 6070708736.0000 - mae: 28847.7500 - val_loss: 3533845760.0000 - val_mae: 27815.3379\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 29514270720.0000 - mae: 29596.9062 - val_loss: 3516311552.0000 - val_mae: 27413.4199\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 8146552320.0000 - mae: 28905.9844 - val_loss: 3526273280.0000 - val_mae: 28026.0078\n",
            "Epoch 17/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 13468503040.0000 - mae: 28936.7305 - val_loss: 3499950080.0000 - val_mae: 27363.0195\n",
            "Epoch 18/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9105178624.0000 - mae: 28671.7383 - val_loss: 3494334464.0000 - val_mae: 27658.8164\n",
            "Epoch 19/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 21483726848.0000 - mae: 29165.2520 - val_loss: 3491750912.0000 - val_mae: 27307.6738\n",
            "Epoch 20/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 14585850880.0000 - mae: 28777.0762 - val_loss: 3478535680.0000 - val_mae: 27350.0781\n",
            "Epoch 21/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 6420572672.0000 - mae: 28508.3398 - val_loss: 3467508480.0000 - val_mae: 27571.0918\n",
            "Epoch 22/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 27978141696.0000 - mae: 29161.0078 - val_loss: 3478573568.0000 - val_mae: 27443.8105\n",
            "Epoch 23/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6268305408.0000 - mae: 28606.9219 - val_loss: 3524214272.0000 - val_mae: 28931.6777\n",
            "Epoch 24/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 9111282688.0000 - mae: 28591.2129 - val_loss: 3447996672.0000 - val_mae: 27432.7363\n",
            "Epoch 25/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 14821864448.0000 - mae: 28723.8848 - val_loss: 3470407936.0000 - val_mae: 28202.9531\n",
            "Epoch 26/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 7058611712.0000 - mae: 28496.9941 - val_loss: 3445220608.0000 - val_mae: 27251.4746\n",
            "Epoch 27/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 10722796544.0000 - mae: 28695.3340 - val_loss: 3489496832.0000 - val_mae: 28245.6816\n",
            "Epoch 28/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 16472948736.0000 - mae: 28666.1758 - val_loss: 3449938176.0000 - val_mae: 27180.0840\n",
            "Epoch 29/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 11030177792.0000 - mae: 28580.4688 - val_loss: 3446560000.0000 - val_mae: 27197.9961\n",
            "Epoch 30/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 10394900480.0000 - mae: 28634.3164 - val_loss: 3423912448.0000 - val_mae: 27240.3926\n",
            "Epoch 31/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 7625957888.0000 - mae: 28611.4336 - val_loss: 3422243840.0000 - val_mae: 27497.5488\n",
            "Epoch 32/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6014105088.0000 - mae: 28506.0801 - val_loss: 3425510400.0000 - val_mae: 27155.7656\n",
            "Epoch 33/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 4863455744.0000 - mae: 28433.1074 - val_loss: 3415616768.0000 - val_mae: 27454.2734\n",
            "Epoch 34/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 7051449344.0000 - mae: 28439.2344 - val_loss: 3423629824.0000 - val_mae: 27914.4883\n",
            "Epoch 35/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 11827796992.0000 - mae: 28667.0723 - val_loss: 3468400384.0000 - val_mae: 28106.1621\n",
            "Epoch 36/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8553733632.0000 - mae: 28752.6191 - val_loss: 3416537600.0000 - val_mae: 27332.5469\n",
            "Epoch 37/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6740861440.0000 - mae: 28526.5488 - val_loss: 3416025088.0000 - val_mae: 27839.5918\n",
            "Epoch 38/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 10027842560.0000 - mae: 28692.4414 - val_loss: 3407238912.0000 - val_mae: 27276.9121\n",
            "Epoch 39/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5951227392.0000 - mae: 28671.9512 - val_loss: 3399416064.0000 - val_mae: 27933.8457\n",
            "Epoch 40/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6653326848.0000 - mae: 28474.0820 - val_loss: 3399168512.0000 - val_mae: 27301.0898\n",
            "Epoch 41/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9311178752.0000 - mae: 28571.4902 - val_loss: 3399825408.0000 - val_mae: 26949.3301\n",
            "Epoch 42/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 16939443200.0000 - mae: 28839.6094 - val_loss: 3381145344.0000 - val_mae: 27260.6758\n",
            "Epoch 43/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9055962112.0000 - mae: 28549.4102 - val_loss: 3381286400.0000 - val_mae: 27413.7754\n",
            "Epoch 44/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 4620056576.0000 - mae: 28398.7324 - val_loss: 3380871168.0000 - val_mae: 27096.4844\n",
            "Epoch 45/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 5893760000.0000 - mae: 28473.1152 - val_loss: 3375742208.0000 - val_mae: 27139.4863\n",
            "Epoch 46/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9197867008.0000 - mae: 28437.6797 - val_loss: 3366029312.0000 - val_mae: 27088.9609\n",
            "Epoch 47/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 7532080640.0000 - mae: 28638.4473 - val_loss: 3360631040.0000 - val_mae: 27513.0508\n",
            "Epoch 48/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 6648207360.0000 - mae: 28657.7109 - val_loss: 3400867072.0000 - val_mae: 26962.0605\n",
            "Epoch 49/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 19577884672.0000 - mae: 29083.9414 - val_loss: 3369635072.0000 - val_mae: 26914.8164\n",
            "Epoch 50/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 9774221312.0000 - mae: 28463.1602 - val_loss: 3352498432.0000 - val_mae: 27254.6660\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 2846.12s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 57900.800206942244\n",
            "R² Score: 0.3592058606031878\n",
            "Средняя абсолютная ошибка (MAE): 27254.65313113048\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 30.34%\n",
            "Медианная абсолютная ошибка (MedAE): 17967.5859375\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='layer',\n",
        "                          optimizer='adam', learning_rate=0.001,\n",
        "                          initializer='glorot_uniform')\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgSYLUxQMVQD",
        "outputId": "4c7cd9e1-d4c3-4a89-b294-31891761685e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "Epoch 1/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6ms/step - loss: 43797434368.0000 - mae: 79837.6172 - val_loss: 5153621504.0000 - val_mae: 35720.8477\n",
            "Epoch 2/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 11087872000.0000 - mae: 44770.1523 - val_loss: 4228056576.0000 - val_mae: 30778.9922\n",
            "Epoch 3/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 14701904896.0000 - mae: 38874.1016 - val_loss: 4137486848.0000 - val_mae: 30012.8730\n",
            "Epoch 4/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 29279082496.0000 - mae: 37047.8789 - val_loss: 3996696576.0000 - val_mae: 29638.1836\n",
            "Epoch 5/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9247617024.0000 - mae: 35282.5547 - val_loss: 3985769472.0000 - val_mae: 29373.1445\n",
            "Epoch 6/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 8961643520.0000 - mae: 33857.1914 - val_loss: 3832021248.0000 - val_mae: 29511.4258\n",
            "Epoch 7/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3ms/step - loss: 9352681472.0000 - mae: 32838.9375 - val_loss: 3826067968.0000 - val_mae: 29217.9141\n",
            "Epoch 8/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 8247304192.0000 - mae: 32253.5508 - val_loss: 3790801408.0000 - val_mae: 29090.4180\n",
            "Epoch 9/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 18367784960.0000 - mae: 32135.1914 - val_loss: 3780096512.0000 - val_mae: 28812.9180\n",
            "Epoch 10/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 11291783168.0000 - mae: 31675.6562 - val_loss: 3775093504.0000 - val_mae: 28865.3418\n",
            "Epoch 11/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 21493653504.0000 - mae: 31434.7539 - val_loss: 3730554624.0000 - val_mae: 29306.8770\n",
            "Epoch 12/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 5445312512.0000 - mae: 31108.6699 - val_loss: 3716525568.0000 - val_mae: 28858.6875\n",
            "Epoch 13/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 18755250176.0000 - mae: 31343.3691 - val_loss: 3723146496.0000 - val_mae: 28676.0742\n",
            "Epoch 14/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 8045032448.0000 - mae: 30880.0586 - val_loss: 3667185408.0000 - val_mae: 28702.4727\n",
            "Epoch 15/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 13792936960.0000 - mae: 30873.7910 - val_loss: 3669817856.0000 - val_mae: 28209.1270\n",
            "Epoch 16/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7033449472.0000 - mae: 30445.3477 - val_loss: 3628510976.0000 - val_mae: 29355.6641\n",
            "Epoch 17/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 8668232704.0000 - mae: 30264.2422 - val_loss: 3622885376.0000 - val_mae: 29091.4297\n",
            "Epoch 18/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 14396834816.0000 - mae: 30441.4844 - val_loss: 3620022272.0000 - val_mae: 28647.1055\n",
            "Epoch 19/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 4863239680.0000 - mae: 29845.8438 - val_loss: 3617288960.0000 - val_mae: 28405.6758\n",
            "Epoch 20/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 10393605120.0000 - mae: 30238.1035 - val_loss: 3653070848.0000 - val_mae: 28336.5586\n",
            "Epoch 21/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 10687842304.0000 - mae: 29892.6133 - val_loss: 3601848320.0000 - val_mae: 28044.2461\n",
            "Epoch 22/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 5814019584.0000 - mae: 29533.3965 - val_loss: 3621457664.0000 - val_mae: 27907.0840\n",
            "Epoch 23/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 8995392512.0000 - mae: 29706.6758 - val_loss: 3617470976.0000 - val_mae: 27666.9492\n",
            "Epoch 24/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 8356024320.0000 - mae: 29442.4805 - val_loss: 3594108416.0000 - val_mae: 28910.3418\n",
            "Epoch 25/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 9445307392.0000 - mae: 29557.6582 - val_loss: 3602101504.0000 - val_mae: 27968.9473\n",
            "Epoch 26/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 16003341312.0000 - mae: 29490.7949 - val_loss: 3546571520.0000 - val_mae: 27924.2500\n",
            "Epoch 27/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7052434432.0000 - mae: 29337.1426 - val_loss: 3559816448.0000 - val_mae: 28170.7109\n",
            "Epoch 28/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 5834526720.0000 - mae: 29193.8398 - val_loss: 3535954944.0000 - val_mae: 28013.5078\n",
            "Epoch 29/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 7887466496.0000 - mae: 29072.3770 - val_loss: 3544538368.0000 - val_mae: 28158.8066\n",
            "Epoch 30/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 7386468352.0000 - mae: 29168.5781 - val_loss: 3532522752.0000 - val_mae: 28039.1309\n",
            "Epoch 31/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 11252205568.0000 - mae: 29160.4238 - val_loss: 3552468480.0000 - val_mae: 27320.9629\n",
            "Epoch 32/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 10327534592.0000 - mae: 29037.0469 - val_loss: 3534349312.0000 - val_mae: 27304.6387\n",
            "Epoch 33/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 8257492480.0000 - mae: 28867.8535 - val_loss: 3507563264.0000 - val_mae: 27707.2109\n",
            "Epoch 34/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 8593523712.0000 - mae: 28904.5469 - val_loss: 3509311488.0000 - val_mae: 27649.7832\n",
            "Epoch 35/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 12793769984.0000 - mae: 28962.1211 - val_loss: 3517748480.0000 - val_mae: 27538.9336\n",
            "Epoch 36/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 27136233472.0000 - mae: 29224.3770 - val_loss: 3507155712.0000 - val_mae: 27526.8125\n",
            "Epoch 37/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 9609348096.0000 - mae: 28880.1504 - val_loss: 3495325696.0000 - val_mae: 27299.4160\n",
            "Epoch 38/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 12742407168.0000 - mae: 28833.8652 - val_loss: 3502189056.0000 - val_mae: 27220.6914\n",
            "Epoch 39/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 7215043584.0000 - mae: 28544.2832 - val_loss: 3465170176.0000 - val_mae: 27526.7891\n",
            "Epoch 40/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 18699137024.0000 - mae: 28686.9141 - val_loss: 3514791936.0000 - val_mae: 27268.4180\n",
            "Epoch 41/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 28245204992.0000 - mae: 28940.1895 - val_loss: 3460190208.0000 - val_mae: 27388.2168\n",
            "Epoch 42/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 17779572736.0000 - mae: 28656.4688 - val_loss: 3498671872.0000 - val_mae: 26890.7891\n",
            "Epoch 43/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 9427329024.0000 - mae: 28517.0762 - val_loss: 3467735296.0000 - val_mae: 27082.8984\n",
            "Epoch 44/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 21143066624.0000 - mae: 28741.6152 - val_loss: 3478054400.0000 - val_mae: 27032.7832\n",
            "Epoch 45/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - loss: 6270137344.0000 - mae: 28381.0645 - val_loss: 3504408832.0000 - val_mae: 27288.9316\n",
            "Epoch 46/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 7016090112.0000 - mae: 28387.9922 - val_loss: 3523972352.0000 - val_mae: 26988.9980\n",
            "Epoch 47/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6503837696.0000 - mae: 28390.9863 - val_loss: 3466340352.0000 - val_mae: 26911.4668\n",
            "Epoch 48/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3ms/step - loss: 14687248384.0000 - mae: 28492.0859 - val_loss: 3505906688.0000 - val_mae: 26971.5137\n",
            "Epoch 49/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 6616586752.0000 - mae: 28228.8340 - val_loss: 3466342912.0000 - val_mae: 27192.7012\n",
            "Epoch 50/50\n",
            "\u001b[1m13304/13304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 20501182464.0000 - mae: 28593.1836 - val_loss: 3475766528.0000 - val_mae: 26753.7461\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "Training time: 2741.62s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 58823.38453277801\n",
            "R² Score: 0.3386224981979342\n",
            "Средняя абсолютная ошибка (MAE): 27388.212631776045\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 30.60%\n",
            "Медианная абсолютная ошибка (MedAE): 18350.53125\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining small architecture: [64, 32]\")\n",
        "model, history, y_pred, train_time, metrics = build_and_train_model([64, 32], X_train, y_train, X_test, y_test,\n",
        "                          batch_size=32, norm='layer',\n",
        "                          optimizer='sgd', learning_rate=0.001,\n",
        "                          initializer='he_normal')\n",
        "\n",
        "print(f\"Training time: {train_time:.2f}s\")\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3atoZU3w2H2"
      },
      "source": [
        "### TabNet с эмбедингами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNVJmaRgw2H2",
        "outputId": "47c60938-97bc-42b5-a285-b32858bd1d9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 20458232520.29283| train_rmse: 141366.73394| train_mae: 85954.93103| train_smape: 184.45024| val_rmse: 115550.20318| val_mae: 85792.98921| val_smape: 184.45371|  0:00:27s\n",
            "epoch 10 | loss: 10776253501.539| train_rmse: 104593.90374| train_mae: 28305.01043| train_smape: 31.42144| val_rmse: 65855.12264| val_mae: 28382.34076| val_smape: 31.6171 |  0:04:42s\n",
            "epoch 20 | loss: 10656618285.35748| train_rmse: 99652.1698| train_mae: 26755.24988| train_smape: 29.83397| val_rmse: 58971.46058| val_mae: 26900.41583| val_smape: 29.99048|  0:08:50s\n",
            "epoch 30 | loss: 10250648907.63026| train_rmse: 100125.58855| train_mae: 31679.34288| train_smape: 34.87886| val_rmse: 56611.51132| val_mae: 31739.57858| val_smape: 35.01109|  0:13:07s\n",
            "epoch 40 | loss: 10356946640.01888| train_rmse: 99670.80071| train_mae: 27671.52445| train_smape: 30.61571| val_rmse: 57740.39816| val_mae: 27902.08827| val_smape: 30.82985|  0:17:24s\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 44 and best_val_smape = 29.65462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Корень из среднеквадратичной ошибки (RMSE): 48567.14367565235\n",
            "R² Score: 0.5491474560800674\n",
            "Средняя абсолютная ошибка (MAE): 26383.14714622922\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 29.67%\n",
            "Медианная абсолютная ошибка (MedAE): 17413.78125\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "X_train = X_train.to_numpy()\n",
        "X_val = X_val.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "\n",
        "y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "y_val = y_val.to_numpy().reshape(-1, 1)\n",
        "y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "class SMAPE(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"smape\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        return 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tabnet_params = {\n",
        "    \"n_d\": 8,\n",
        "    \"n_a\": 8,\n",
        "    \"n_steps\": 3,\n",
        "    \"gamma\": 1.3,\n",
        "    \"lambda_sparse\": 1e-3,\n",
        "    \"optimizer_fn\": torch.optim.Adam,\n",
        "    \"optimizer_params\": dict(lr=2e-2),\n",
        "    \"mask_type\": \"sparsemax\",\n",
        "    \"scheduler_params\": dict(\n",
        "        mode=\"min\",\n",
        "        patience=5,\n",
        "        min_lr=1e-5,\n",
        "        factor=0.9,\n",
        "    ),\n",
        "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    \"seed\": 42,\n",
        "    \"verbose\": 10\n",
        "}\n",
        "\n",
        "model = TabNetRegressor(**tabnet_params, device_name=device)\n",
        "\n",
        "model.fit(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['rmse', 'mae', SMAPE],\n",
        "    max_epochs=50,\n",
        "    patience=20,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    loss_fn=torch.nn.functional.mse_loss,\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpo8OJWDw2H2"
      },
      "source": [
        "#### Вывод\n",
        "С эмбедингами лучше\n",
        "На cpu быстрее чем на mps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBtS6sEPw2H2"
      },
      "source": [
        "### Оптимизация TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anZ1-W_ew2H2",
        "outputId": "d08e55ae-a2fa-47c3-b1ce-cf635f69cc24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 22587540284.0722|  0:00:11s\n",
            "epoch 0  | loss: 14788413876.21661|  0:00:11s\n",
            "epoch 0  | loss: 24342798154.85921|  0:00:11s\n",
            "epoch 0  | loss: 14777960170.74368|  0:00:12s\n",
            "epoch 0  | loss: 24233168999.50903|  0:00:12s\n",
            "epoch 0  | loss: 22585867312.05776|  0:00:12s\n",
            "epoch 0  | loss: 24335206610.7148|  0:00:12s\n",
            "epoch 0  | loss: 14653618634.39711|  0:00:12s\n",
            "epoch 0  | loss: 22515549468.64982|  0:00:12s\n",
            "epoch 0  | loss: 24042292837.66066|  0:00:14s\n",
            "epoch 0  | loss: 22269967555.9278|  0:00:14s\n",
            "epoch 0  | loss: 14492965089.5018|  0:00:14s\n",
            "epoch 1  | loss: 21886076292.15885|  0:00:22s\n",
            "epoch 1  | loss: 14046154230.75812|  0:00:23s\n",
            "epoch 1  | loss: 23565393128.8953|  0:00:23s\n",
            "epoch 1  | loss: 13529392978.25271|  0:00:24s\n",
            "epoch 1  | loss: 21928937020.99639|  0:00:24s\n",
            "epoch 1  | loss: 23646492727.45126|  0:00:24s\n",
            "epoch 1  | loss: 23107719014.58486|  0:00:24s\n",
            "epoch 1  | loss: 14098606494.0361|  0:00:24s\n",
            "epoch 1  | loss: 21392681104.17329|  0:00:24s\n",
            "epoch 1  | loss: 11411986149.19856|  0:00:28s\n",
            "epoch 1  | loss: 21974521112.95306|  0:00:28s\n",
            "epoch 1  | loss: 12429977398.52708|  0:00:29s\n",
            "epoch 2  | loss: 20879849719.68231|  0:00:34s\n",
            "epoch 2  | loss: 12819276099.4657|  0:00:34s\n",
            "epoch 2  | loss: 22356153129.58845|  0:00:35s\n",
            "epoch 2  | loss: 12011738270.96029|  0:00:36s\n",
            "epoch 2  | loss: 20984842154.97472|  0:00:37s\n",
            "epoch 2  | loss: 22653112027.95668|  0:00:37s\n",
            "epoch 2  | loss: 21684161286.46932|  0:00:37s\n",
            "epoch 2  | loss: 13123329462.06498|  0:00:37s\n",
            "epoch 2  | loss: 19822768394.16606|  0:00:37s\n",
            "epoch 2  | loss: 18022530227.29242|  0:00:43s\n",
            "epoch 2  | loss: 19799762448.63537|  0:00:43s\n",
            "epoch 2  | loss: 10151809802.16606|  0:00:43s\n",
            "epoch 3  | loss: 19701864004.3899|  0:00:45s\n",
            "epoch 3  | loss: 11570432101.66066|  0:00:46s\n",
            "epoch 3  | loss: 21220368164.04332|  0:00:47s\n",
            "epoch 3  | loss: 10529264124.30325|  0:00:49s\n",
            "epoch 3  | loss: 19977282988.82312|  0:00:49s\n",
            "epoch 3  | loss: 20273488267.55234|  0:00:49s\n",
            "epoch 3  | loss: 12037037946.91697|  0:00:49s\n",
            "epoch 3  | loss: 21626097279.5379|  0:00:49s\n",
            "epoch 3  | loss: 18323444978.13719|  0:00:50s\n",
            "epoch 4  | loss: 18447733813.60288|  0:00:56s\n",
            "epoch 3  | loss: 16393924394.51264|  0:00:57s\n",
            "epoch 3  | loss: 18129121379.81228|  0:00:58s\n",
            "epoch 3  | loss: 8129456008.77978|  0:00:58s\n",
            "epoch 4  | loss: 10384064826.22383|  0:00:58s\n",
            "epoch 4  | loss: 20153498354.13718|  0:00:58s\n",
            "epoch 4  | loss: 19134541191.85559|  0:01:01s\n",
            "epoch 4  | loss: 9273918488.95307|  0:01:01s\n",
            "epoch 4  | loss: 19067624436.90974|  0:01:02s\n",
            "epoch 4  | loss: 10961417600.46209|  0:01:02s\n",
            "epoch 4  | loss: 20579488185.76174|  0:01:02s\n",
            "epoch 4  | loss: 17151452618.39711|  0:01:02s\n",
            "epoch 5  | loss: 17379825418.16606|  0:01:08s\n",
            "epoch 5  | loss: 9240345162.8592|  0:01:10s\n",
            "epoch 5  | loss: 19112273590.98917|  0:01:10s\n",
            "epoch 4  | loss: 15125814050.19495|  0:01:12s\n",
            "epoch 4  | loss: 16919889748.10109|  0:01:13s\n",
            "epoch 4  | loss: 6794213954.54152|  0:01:13s\n",
            "epoch 5  | loss: 8197777106.7148|  0:01:14s\n",
            "epoch 5  | loss: 18213278198.75812|  0:01:14s\n",
            "epoch 5  | loss: 9945880307.98556|  0:01:14s\n",
            "epoch 5  | loss: 19653755685.89169|  0:01:14s\n",
            "epoch 5  | loss: 17994042571.3213|  0:01:14s\n",
            "epoch 5  | loss: 16059400301.97834|  0:01:15s\n",
            "epoch 6  | loss: 16511130231.22021|  0:01:19s\n",
            "epoch 6  | loss: 8245150304.11552|  0:01:21s\n",
            "epoch 6  | loss: 18245603510.065|  0:01:22s\n",
            "epoch 6  | loss: 17399138257.79062|  0:01:26s\n",
            "epoch 6  | loss: 7339457129.3574|  0:01:26s\n",
            "epoch 6  | loss: 9055671663.82672|  0:01:27s\n",
            "epoch 5  | loss: 14141987563.66787|  0:01:27s\n",
            "epoch 6  | loss: 18751124112.17329|  0:01:27s\n",
            "epoch 6  | loss: 17100414936.25993|  0:01:27s\n",
            "epoch 5  | loss: 16015823651.11914|  0:01:27s\n",
            "epoch 6  | loss: 15166731076.3899|  0:01:27s\n",
            "epoch 5  | loss: 5966192242.13719|  0:01:28s\n",
            "epoch 7  | loss: 15637658926.20938|  0:01:31s\n",
            "epoch 7  | loss: 7458868733.22743|  0:01:33s\n",
            "epoch 7  | loss: 17383738040.83754|  0:01:34s\n",
            "epoch 7  | loss: 6547168432.51986|  0:01:39s\n",
            "epoch 7  | loss: 8282394294.98916|  0:01:39s\n",
            "epoch 7  | loss: 16566563817.8195|  0:01:39s\n",
            "epoch 7  | loss: 17931836929.84837|  0:01:39s\n",
            "epoch 7  | loss: 16379334085.77617|  0:01:40s\n",
            "epoch 7  | loss: 14451606320.98196|  0:01:40s\n",
            "epoch 6  | loss: 13448037916.64982|  0:01:41s\n",
            "epoch 6  | loss: 15428363792.63538|  0:01:42s\n",
            "epoch 8  | loss: 14876020137.12636|  0:01:42s\n",
            "epoch 6  | loss: 5459861187.00361|  0:01:43s\n",
            "epoch 8  | loss: 6781650868.21661|  0:01:45s\n",
            "epoch 8  | loss: 16708034821.54513|  0:01:45s\n",
            "epoch 8  | loss: 7622690753.15523|  0:01:51s\n",
            "epoch 8  | loss: 15757173835.7834|  0:01:51s\n",
            "epoch 8  | loss: 6011654915.23466|  0:01:51s\n",
            "epoch 8  | loss: 17132827989.94946|  0:01:51s\n",
            "epoch 8  | loss: 15873559801.53068|  0:01:52s\n",
            "epoch 8  | loss: 13927483313.44404|  0:01:53s\n",
            "epoch 9  | loss: 14127324417.84837|  0:01:53s\n",
            "epoch 7  | loss: 13048530860.36101|  0:01:56s\n",
            "epoch 9  | loss: 6213091137.15523|  0:01:56s\n",
            "epoch 9  | loss: 16174503295.99999|  0:01:57s\n",
            "epoch 7  | loss: 15013885219.58123|  0:01:57s\n",
            "epoch 7  | loss: 5215414295.1047|  0:01:58s\n",
            "epoch 9  | loss: 7047083501.51624|  0:02:03s\n",
            "epoch 9  | loss: 15119449964.12996|  0:02:04s\n",
            "epoch 9  | loss: 5620587038.4982|  0:02:04s\n",
            "epoch 9  | loss: 16515449735.85559|  0:02:04s\n",
            "epoch 10 | loss: 13601948062.4982|  0:02:04s\n",
            "epoch 9  | loss: 15363808335.48015|  0:02:05s\n",
            "epoch 9  | loss: 13492589200.63538|  0:02:06s\n",
            "epoch 10 | loss: 5789865784.37545|  0:02:08s\n",
            "epoch 10 | loss: 15703430277.54512|  0:02:09s\n",
            "epoch 8  | loss: 12805308928.0|  0:02:10s\n",
            "epoch 8  | loss: 14791869320.31769|  0:02:12s\n",
            "epoch 8  | loss: 5124396641.50181|  0:02:13s\n",
            "epoch 10 | loss: 6501699774.38267|  0:02:16s\n",
            "epoch 11 | loss: 13251595809.73286|  0:02:16s\n",
            "epoch 10 | loss: 5294785576.66426|  0:02:16s\n",
            "epoch 10 | loss: 14574420070.58484|  0:02:16s\n",
            "epoch 10 | loss: 16009140321.03972|  0:02:17s\n",
            "epoch 10 | loss: 15044807949.40071|  0:02:18s\n",
            "epoch 10 | loss: 13151598914.54152|  0:02:18s\n",
            "epoch 11 | loss: 5451834587.95668|  0:02:20s\n",
            "epoch 11 | loss: 15272402748.5343|  0:02:20s\n",
            "epoch 9  | loss: 12838248472.95307|  0:02:25s\n",
            "epoch 12 | loss: 12987579047.74006|  0:02:27s\n",
            "epoch 9  | loss: 14579862682.33935|  0:02:27s\n",
            "epoch 9  | loss: 5014374099.63899|  0:02:28s\n",
            "epoch 11 | loss: 5982422423.1047|  0:02:28s\n",
            "epoch 11 | loss: 5149507227.26354|  0:02:29s\n",
            "epoch 11 | loss: 14052224358.58483|  0:02:29s\n",
            "epoch 11 | loss: 15553744651.55234|  0:02:29s\n",
            "epoch 11 | loss: 14782768549.8917|  0:02:31s\n",
            "epoch 11 | loss: 12932421043.29242|  0:02:31s\n",
            "epoch 12 | loss: 5169631122.94585|  0:02:32s\n",
            "epoch 12 | loss: 14863693807.82671|  0:02:32s\n",
            "epoch 13 | loss: 12849987624.20217|  0:02:38s\n",
            "epoch 10 | loss: 12778502833.44404|  0:02:39s\n",
            "epoch 12 | loss: 5582118581.14079|  0:02:41s\n",
            "epoch 12 | loss: 13643654949.8917|  0:02:41s\n",
            "epoch 12 | loss: 5018794444.24548|  0:02:41s\n",
            "epoch 12 | loss: 15152966425.41515|  0:02:42s\n",
            "epoch 10 | loss: 14501418318.55596|  0:02:42s\n",
            "epoch 10 | loss: 4969241995.09025|  0:02:43s\n",
            "epoch 12 | loss: 14539975356.0722|  0:02:43s\n",
            "epoch 13 | loss: 5082013085.11191|  0:02:43s\n",
            "epoch 13 | loss: 14642045271.79783|  0:02:44s\n",
            "epoch 12 | loss: 12794686607.7112|  0:02:44s\n",
            "epoch 14 | loss: 12704350471.3935|  0:02:50s\n",
            "epoch 13 | loss: 5335383083.43682|  0:02:53s\n",
            "epoch 13 | loss: 13335366552.95309|  0:02:53s\n",
            "epoch 13 | loss: 4886933692.0722|  0:02:54s\n",
            "epoch 11 | loss: 12675233623.79784|  0:02:54s\n",
            "epoch 13 | loss: 14725076310.87366|  0:02:54s\n",
            "epoch 14 | loss: 4964421699.9278|  0:02:55s\n",
            "epoch 14 | loss: 14503199348.90975|  0:02:55s\n",
            "epoch 13 | loss: 14494479237.54513|  0:02:56s\n",
            "epoch 13 | loss: 12696885490.59926|  0:02:56s\n",
            "epoch 11 | loss: 14374697444.73646|  0:02:57s\n",
            "epoch 11 | loss: 4907477696.23105|  0:02:58s\n",
            "epoch 15 | loss: 12695020433.55957|  0:03:01s\n",
            "epoch 14 | loss: 5068508429.40072|  0:03:05s\n",
            "epoch 14 | loss: 13096844848.05776|  0:03:06s\n",
            "epoch 14 | loss: 4877694790.23827|  0:03:06s\n",
            "epoch 14 | loss: 14619800343.56678|  0:03:07s\n",
            "epoch 15 | loss: 14388334355.87003|  0:03:07s\n",
            "epoch 15 | loss: 4887468392.89531|  0:03:07s\n",
            "epoch 14 | loss: 14375649097.93502|  0:03:08s\n",
            "epoch 12 | loss: 12706500057.6462|  0:03:09s\n",
            "epoch 14 | loss: 12588628277.1408|  0:03:09s\n",
            "epoch 12 | loss: 14296253152.11552|  0:03:12s\n",
            "epoch 16 | loss: 12646444434.48375|  0:03:12s\n",
            "epoch 12 | loss: 4868098358.98917|  0:03:13s\n",
            "epoch 15 | loss: 5064936957.22744|  0:03:18s\n",
            "epoch 15 | loss: 4882476566.6426|  0:03:19s\n",
            "epoch 15 | loss: 12964090311.62454|  0:03:19s\n",
            "epoch 16 | loss: 14341086506.97473|  0:03:19s\n",
            "epoch 16 | loss: 4877380622.787|  0:03:19s\n",
            "epoch 15 | loss: 14355776766.15162|  0:03:19s\n",
            "epoch 15 | loss: 14330042895.2491|  0:03:21s\n",
            "epoch 15 | loss: 12555733083.95667|  0:03:22s\n",
            "epoch 13 | loss: 12773012656.98195|  0:03:23s\n",
            "epoch 17 | loss: 12563495558.46932|  0:03:24s\n",
            "epoch 13 | loss: 14261029027.58123|  0:03:27s\n",
            "epoch 13 | loss: 4828829187.69675|  0:03:28s\n",
            "epoch 16 | loss: 4872580462.44043|  0:03:30s\n",
            "epoch 17 | loss: 14272994656.11552|  0:03:30s\n",
            "epoch 17 | loss: 4906023980.36101|  0:03:30s\n",
            "epoch 16 | loss: 4813246784.69314|  0:03:31s\n",
            "epoch 16 | loss: 12827858459.72563|  0:03:31s\n",
            "epoch 16 | loss: 14346355972.15884|  0:03:32s\n",
            "epoch 16 | loss: 14315137385.8195|  0:03:34s\n",
            "epoch 16 | loss: 12492199311.71119|  0:03:34s\n",
            "epoch 18 | loss: 12560920891.14801|  0:03:35s\n",
            "epoch 14 | loss: 12820163063.68231|  0:03:38s\n",
            "epoch 18 | loss: 14239326274.54151|  0:03:42s\n",
            "epoch 18 | loss: 4876293180.5343|  0:03:42s\n",
            "epoch 14 | loss: 14202645342.26715|  0:03:42s\n",
            "epoch 17 | loss: 4771195309.74729|  0:03:43s\n",
            "epoch 17 | loss: 4785552379.84115|  0:03:43s\n",
            "epoch 14 | loss: 4792882732.82311|  0:03:43s\n",
            "epoch 17 | loss: 12867403005.22744|  0:03:43s\n",
            "epoch 17 | loss: 14189122637.63178|  0:03:44s\n",
            "epoch 19 | loss: 12565499654.00722|  0:03:46s\n",
            "epoch 17 | loss: 14259433307.95668|  0:03:46s\n",
            "epoch 17 | loss: 12479421306.45488|  0:03:47s\n",
            "epoch 15 | loss: 12758200281.1841|  0:03:53s\n",
            "epoch 19 | loss: 14193155371.43682|  0:03:54s\n",
            "epoch 19 | loss: 4806755010.07942|  0:03:53s\n",
            "epoch 18 | loss: 4736774504.43321|  0:03:55s\n",
            "epoch 18 | loss: 4830968322.31047|  0:03:56s\n",
            "epoch 18 | loss: 12688191495.8556|  0:03:56s\n",
            "epoch 15 | loss: 14148229198.09385|  0:03:57s\n",
            "epoch 18 | loss: 14146896673.27075|  0:03:57s\n",
            "epoch 20 | loss: 12731582804.10108|  0:03:57s\n",
            "epoch 15 | loss: 4760852631.56679|  0:03:58s\n",
            "epoch 18 | loss: 14294897045.71842|  0:03:59s\n",
            "epoch 18 | loss: 12473348982.29604|  0:04:00s\n",
            "epoch 20 | loss: 14192969238.1805|  0:04:05s\n",
            "epoch 20 | loss: 4810822407.3935|  0:04:05s\n",
            "epoch 16 | loss: 12711298068.79422|  0:04:07s\n",
            "epoch 19 | loss: 4666362752.92418|  0:04:08s\n",
            "epoch 19 | loss: 4795182258.36823|  0:04:08s\n",
            "epoch 21 | loss: 12745745371.03249|  0:04:08s\n",
            "epoch 19 | loss: 12766865762.88809|  0:04:09s\n",
            "epoch 19 | loss: 14183437658.57039|  0:04:10s\n",
            "epoch 16 | loss: 14082539630.44043|  0:04:12s\n",
            "epoch 19 | loss: 14206299827.75452|  0:04:12s\n",
            "epoch 19 | loss: 12508545764.73646|  0:04:12s\n",
            "epoch 16 | loss: 4729149662.72924|  0:04:13s\n",
            "epoch 21 | loss: 14253499713.15522|  0:04:17s\n",
            "epoch 21 | loss: 4712950018.31047|  0:04:17s\n",
            "epoch 22 | loss: 12691798664.77978|  0:04:20s\n",
            "epoch 20 | loss: 4678992354.88809|  0:04:20s\n",
            "epoch 20 | loss: 4671234276.73646|  0:04:20s\n",
            "epoch 20 | loss: 12681109768.3177|  0:04:21s\n",
            "epoch 17 | loss: 12638339658.85921|  0:04:22s\n",
            "epoch 20 | loss: 14086901516.01444|  0:04:22s\n",
            "epoch 20 | loss: 14195264622.44043|  0:04:25s\n",
            "epoch 20 | loss: 12443644702.0361|  0:04:25s\n",
            "epoch 17 | loss: 14038967119.01804|  0:04:27s\n",
            "epoch 17 | loss: 4681705847.68231|  0:04:28s\n",
            "epoch 22 | loss: 4777318879.65343|  0:04:28s\n",
            "epoch 22 | loss: 14121806171.0325|  0:04:29s\n",
            "epoch 23 | loss: 12633976819.98556|  0:04:31s\n",
            "epoch 21 | loss: 4655264948.2166|  0:04:33s\n",
            "epoch 21 | loss: 4647035365.66065|  0:04:33s\n",
            "epoch 21 | loss: 12684159484.76534|  0:04:34s\n",
            "epoch 21 | loss: 14075077277.1119|  0:04:36s\n",
            "epoch 18 | loss: 12628803208.77978|  0:04:37s\n",
            "epoch 21 | loss: 14118240408.02887|  0:04:39s\n",
            "epoch 21 | loss: 12407580665.53069|  0:04:40s\n",
            "epoch 23 | loss: 4688500078.44043|  0:04:42s\n",
            "epoch 23 | loss: 14117901062.46931|  0:04:43s\n",
            "epoch 18 | loss: 13932708216.1444|  0:04:45s\n",
            "epoch 24 | loss: 12694050003.63898|  0:04:45s\n",
            "epoch 18 | loss: 4641340556.47653|  0:04:46s\n",
            "epoch 22 | loss: 4619310988.01444|  0:04:47s\n",
            "epoch 22 | loss: 4689180591.59567|  0:04:47s\n",
            "epoch 22 | loss: 12601931830.06499|  0:04:49s\n",
            "epoch 22 | loss: 14086524911.82671|  0:04:50s\n",
            "epoch 22 | loss: 14163156248.49097|  0:04:53s\n",
            "epoch 19 | loss: 12648307778.54152|  0:04:54s\n",
            "epoch 22 | loss: 12403965702.93141|  0:04:53s\n",
            "epoch 24 | loss: 4723322267.72564|  0:04:54s\n",
            "epoch 24 | loss: 14294113658.45487|  0:04:55s\n",
            "epoch 25 | loss: 12744581052.99638|  0:04:57s\n",
            "epoch 23 | loss: 4607144357.8917|  0:05:00s\n",
            "epoch 23 | loss: 4598914296.6065|  0:05:00s\n",
            "epoch 19 | loss: 13922177953.27077|  0:05:01s\n",
            "epoch 23 | loss: 12570835290.10831|  0:05:02s\n",
            "epoch 19 | loss: 4640950649.99278|  0:05:02s\n",
            "epoch 23 | loss: 14042050304.46209|  0:05:04s\n",
            "epoch 23 | loss: 14113849459.06137|  0:05:06s\n",
            "epoch 25 | loss: 4745290925.2852|  0:05:06s\n",
            "epoch 23 | loss: 12349580442.33935|  0:05:07s\n",
            "epoch 25 | loss: 14416048990.72922|  0:05:07s\n",
            "epoch 26 | loss: 12664678115.35018|  0:05:09s\n",
            "epoch 20 | loss: 12653954614.06499|  0:05:09s\n",
            "epoch 24 | loss: 4637873199.13357|  0:05:13s\n",
            "epoch 24 | loss: 4626116487.8556|  0:05:13s\n",
            "epoch 24 | loss: 12564032542.0361|  0:05:14s\n",
            "epoch 20 | loss: 13791456918.6426|  0:05:16s\n",
            "epoch 24 | loss: 14077294665.47293|  0:05:17s\n",
            "epoch 20 | loss: 4564070202.68592|  0:05:17s\n",
            "epoch 26 | loss: 4681683338.39711|  0:05:18s\n",
            "epoch 26 | loss: 14474805131.09025|  0:05:19s\n",
            "epoch 24 | loss: 14138995259.14802|  0:05:19s\n",
            "epoch 24 | loss: 12363013639.8556|  0:05:20s\n",
            "epoch 27 | loss: 12628658242.54152|  0:05:20s\n",
            "epoch 21 | loss: 12591058819.69675|  0:05:24s\n",
            "epoch 25 | loss: 4597398601.93502|  0:05:25s\n",
            "epoch 25 | loss: 4569147566.20938|  0:05:26s\n",
            "epoch 25 | loss: 12538462274.54154|  0:05:27s\n",
            "epoch 25 | loss: 13967793320.20216|  0:05:29s\n",
            "epoch 27 | loss: 4635485883.14802|  0:05:30s\n",
            "epoch 27 | loss: 14272066644.56318|  0:05:31s\n",
            "epoch 21 | loss: 13789496262.70036|  0:05:31s\n",
            "epoch 28 | loss: 12567820280.60649|  0:05:31s\n",
            "epoch 25 | loss: 14061504087.33574|  0:05:32s\n",
            "epoch 21 | loss: 4592253935.82671|  0:05:33s\n",
            "epoch 25 | loss: 12355453541.66066|  0:05:33s\n",
            "epoch 26 | loss: 4726111101.22744|  0:05:37s\n",
            "epoch 26 | loss: 4488289448.20217|  0:05:38s\n",
            "epoch 22 | loss: 12527377547.55234|  0:05:38s\n",
            "epoch 26 | loss: 12471009127.97112|  0:05:40s\n",
            "epoch 28 | loss: 4624704256.0|  0:05:42s\n",
            "epoch 26 | loss: 13968988893.34296|  0:05:42s\n",
            "epoch 28 | loss: 14048160483.35018|  0:05:43s\n",
            "epoch 29 | loss: 12568385392.7509|  0:05:42s\n",
            "epoch 26 | loss: 13920116622.32492|  0:05:45s\n",
            "epoch 26 | loss: 12282961246.26714|  0:05:45s\n",
            "epoch 22 | loss: 13639899661.40072|  0:05:46s\n",
            "epoch 22 | loss: 4513303472.51985|  0:05:48s\n",
            "epoch 27 | loss: 4576888435.52346|  0:05:49s\n",
            "epoch 27 | loss: 4569430243.35018|  0:05:50s\n",
            "epoch 27 | loss: 12445548737.61732|  0:05:52s\n",
            "epoch 23 | loss: 12486735410.36822|  0:05:53s\n",
            "epoch 29 | loss: 4587732778.97473|  0:05:53s\n",
            "epoch 30 | loss: 12515335484.5343|  0:05:54s\n",
            "epoch 29 | loss: 14042414886.81588|  0:05:54s\n",
            "epoch 27 | loss: 13959786476.59206|  0:05:55s\n",
            "epoch 27 | loss: 14070309183.30686|  0:05:58s\n",
            "epoch 27 | loss: 12245393876.10108|  0:05:58s\n",
            "epoch 23 | loss: 13692583380.10108|  0:06:01s\n",
            "epoch 28 | loss: 4637243256.6065|  0:06:02s\n",
            "epoch 28 | loss: 4427886367.42238|  0:06:03s\n",
            "epoch 23 | loss: 4427047712.34657|  0:06:03s\n",
            "epoch 31 | loss: 12524881468.0722|  0:06:05s\n",
            "epoch 30 | loss: 4559312369.67509|  0:06:05s\n",
            "epoch 28 | loss: 12470129322.97472|  0:06:05s\n",
            "epoch 30 | loss: 14120295033.99278|  0:06:06s\n",
            "epoch 28 | loss: 13952641962.51264|  0:06:08s\n",
            "epoch 24 | loss: 12434289229.16968|  0:06:08s\n",
            "epoch 28 | loss: 14240608186.68592|  0:06:10s\n",
            "epoch 28 | loss: 12218573543.04694|  0:06:11s\n",
            "epoch 29 | loss: 4610437810.83033|  0:06:14s\n",
            "epoch 29 | loss: 4394258240.69314|  0:06:15s\n",
            "epoch 24 | loss: 13656694543.7112|  0:06:16s\n",
            "epoch 32 | loss: 12589314623.76895|  0:06:16s\n",
            "epoch 31 | loss: 4629577892.96751|  0:06:17s\n",
            "epoch 29 | loss: 12388153426.2527|  0:06:18s\n",
            "epoch 31 | loss: 14196201650.36823|  0:06:18s\n",
            "epoch 24 | loss: 4549999403.89892|  0:06:18s\n",
            "epoch 29 | loss: 13889400222.9603|  0:06:20s\n",
            "epoch 25 | loss: 12435307032.49097|  0:06:23s\n",
            "epoch 29 | loss: 14079830694.81588|  0:06:23s\n",
            "epoch 29 | loss: 12178348090.22383|  0:06:24s\n",
            "epoch 30 | loss: 4524044972.8231|  0:06:26s\n",
            "epoch 33 | loss: 12502503450.33936|  0:06:28s\n",
            "epoch 30 | loss: 4369847952.17329|  0:06:28s\n",
            "epoch 32 | loss: 4532404414.84477|  0:06:29s\n",
            "epoch 32 | loss: 14111334787.23466|  0:06:30s\n",
            "epoch 25 | loss: 13621151165.45848|  0:06:31s\n",
            "epoch 30 | loss: 12383516993.15523|  0:06:31s\n",
            "epoch 30 | loss: 13836046455.22022|  0:06:33s\n",
            "epoch 25 | loss: 4634396218.22383|  0:06:34s\n",
            "epoch 30 | loss: 13880631853.7473|  0:06:36s\n",
            "epoch 30 | loss: 12157457870.55596|  0:06:36s\n",
            "epoch 26 | loss: 12521127218.36823|  0:06:38s\n",
            "epoch 34 | loss: 12488514536.89531|  0:06:39s\n",
            "epoch 31 | loss: 4493637472.57762|  0:06:39s\n",
            "epoch 31 | loss: 4366255110.00722|  0:06:41s\n",
            "epoch 33 | loss: 4547372686.32491|  0:06:41s\n",
            "epoch 33 | loss: 14095078125.05415|  0:06:42s\n",
            "epoch 31 | loss: 12370337792.0|  0:06:44s\n",
            "epoch 31 | loss: 13823619563.20576|  0:06:46s\n",
            "epoch 26 | loss: 13555177713.213|  0:06:46s\n",
            "epoch 26 | loss: 4627648371.98556|  0:06:49s\n",
            "epoch 31 | loss: 13930624701.92058|  0:06:49s\n",
            "epoch 31 | loss: 12204776567.68231|  0:06:49s\n",
            "epoch 35 | loss: 12445587052.59205|  0:06:50s\n",
            "epoch 32 | loss: 4643920709.77617|  0:06:51s\n",
            "epoch 34 | loss: 4536045350.81588|  0:06:52s\n",
            "epoch 27 | loss: 12385287922.59928|  0:06:53s\n",
            "epoch 32 | loss: 4427397085.80505|  0:06:53s\n",
            "epoch 34 | loss: 14026546483.29242|  0:06:54s\n",
            "epoch 32 | loss: 12323754378.16607|  0:06:57s\n",
            "epoch 32 | loss: 13884630902.29603|  0:06:59s\n",
            "epoch 27 | loss: 13453250588.41878|  0:07:01s\n",
            "epoch 36 | loss: 12468823183.7112|  0:07:01s\n",
            "epoch 32 | loss: 14040136482.19495|  0:07:01s\n",
            "epoch 32 | loss: 12219627538.94585|  0:07:02s\n",
            "epoch 33 | loss: 4627837661.80505|  0:07:04s\n",
            "epoch 35 | loss: 4502826993.67509|  0:07:04s\n",
            "epoch 27 | loss: 4567079839.42238|  0:07:04s\n",
            "epoch 33 | loss: 4512528806.81589|  0:07:05s\n",
            "epoch 35 | loss: 13978840209.55957|  0:07:06s\n",
            "epoch 28 | loss: 12226433080.83755|  0:07:08s\n",
            "epoch 33 | loss: 12347183563.3213|  0:07:09s\n",
            "epoch 33 | loss: 13821709866.51263|  0:07:11s\n",
            "epoch 37 | loss: 12481792679.27798|  0:07:12s\n",
            "epoch 33 | loss: 14046381910.87365|  0:07:14s\n",
            "epoch 33 | loss: 12195086244.96751|  0:07:14s\n",
            "epoch 36 | loss: 4499702050.65704|  0:07:16s\n",
            "epoch 34 | loss: 4572339586.31047|  0:07:16s\n",
            "epoch 28 | loss: 13417713816.49097|  0:07:16s\n",
            "epoch 36 | loss: 14034601289.93502|  0:07:17s\n",
            "epoch 34 | loss: 4528334813.80505|  0:07:18s\n",
            "epoch 28 | loss: 4490164425.93502|  0:07:19s\n",
            "epoch 34 | loss: 12310000757.83394|  0:07:22s\n",
            "epoch 29 | loss: 12267813453.63176|  0:07:22s\n",
            "epoch 38 | loss: 12433566317.97834|  0:07:23s\n",
            "epoch 34 | loss: 13824899866.80144|  0:07:24s\n",
            "epoch 34 | loss: 12108376270.09387|  0:07:27s\n",
            "epoch 34 | loss: 13961619285.02527|  0:07:27s\n",
            "epoch 37 | loss: 4454082120.08664|  0:07:27s\n",
            "epoch 35 | loss: 4573764021.14079|  0:07:29s\n",
            "epoch 37 | loss: 13992518224.40433|  0:07:29s\n",
            "epoch 35 | loss: 4430608891.37906|  0:07:30s\n",
            "epoch 29 | loss: 13359249243.49458|  0:07:31s\n",
            "epoch 39 | loss: 12436666880.46209|  0:07:34s\n",
            "epoch 29 | loss: 4517312159.88448|  0:07:34s\n",
            "epoch 35 | loss: 12250010351.36462|  0:07:35s\n",
            "epoch 35 | loss: 13715597371.37906|  0:07:36s\n",
            "epoch 30 | loss: 12259788924.30326|  0:07:37s\n",
            "epoch 38 | loss: 4525690865.213|  0:07:39s\n",
            "epoch 35 | loss: 12067816325.54513|  0:07:39s\n",
            "epoch 35 | loss: 13857246362.33936|  0:07:40s\n",
            "epoch 38 | loss: 13936448150.64261|  0:07:41s\n",
            "epoch 36 | loss: 4507075258.22383|  0:07:41s\n",
            "epoch 36 | loss: 4399979697.44405|  0:07:42s\n",
            "epoch 40 | loss: 12293814171.26354|  0:07:45s\n",
            "epoch 30 | loss: 13378034047.53791|  0:07:46s\n",
            "epoch 36 | loss: 12222910549.02526|  0:07:47s\n",
            "epoch 36 | loss: 13745263064.25992|  0:07:49s\n",
            "epoch 30 | loss: 4510543183.01805|  0:07:49s\n",
            "epoch 39 | loss: 4523249855.76896|  0:07:50s\n",
            "epoch 36 | loss: 12008625647.36462|  0:07:52s\n",
            "epoch 36 | loss: 13896351026.36823|  0:07:52s\n",
            "epoch 39 | loss: 13961393522.59928|  0:07:52s\n",
            "epoch 31 | loss: 12202358281.24187|  0:07:52s\n",
            "epoch 37 | loss: 4511162809.76173|  0:07:54s\n",
            "epoch 37 | loss: 4433864567.91336|  0:07:55s\n",
            "epoch 41 | loss: 12242328315.37907|  0:07:56s\n",
            "epoch 37 | loss: 12166040070.9314|  0:08:00s\n",
            "epoch 31 | loss: 13354780391.50903|  0:08:00s\n",
            "epoch 37 | loss: 13771322330.5704|  0:08:01s\n",
            "epoch 40 | loss: 4528620825.41516|  0:08:02s\n",
            "epoch 40 | loss: 13950042677.14079|  0:08:04s\n",
            "epoch 31 | loss: 4475435715.00361|  0:08:04s\n",
            "epoch 37 | loss: 11996109413.19855|  0:08:05s\n",
            "epoch 37 | loss: 14121741113.76174|  0:08:05s\n",
            "epoch 38 | loss: 4490918551.10469|  0:08:06s\n",
            "epoch 42 | loss: 12155199857.21299|  0:08:07s\n",
            "epoch 38 | loss: 4276179677.34296|  0:08:07s\n",
            "epoch 32 | loss: 12163731544.72202|  0:08:07s\n",
            "epoch 38 | loss: 12197250919.04693|  0:08:13s\n",
            "epoch 41 | loss: 4445209331.06137|  0:08:13s\n",
            "epoch 38 | loss: 13759324520.43322|  0:08:14s\n",
            "epoch 32 | loss: 13233891525.31408|  0:08:15s\n",
            "epoch 41 | loss: 13815610717.80504|  0:08:16s\n",
            "epoch 38 | loss: 11947283848.77979|  0:08:17s\n",
            "epoch 38 | loss: 14064103409.213|  0:08:18s\n",
            "epoch 39 | loss: 4407859403.78339|  0:08:18s\n",
            "epoch 43 | loss: 12086063127.56679|  0:08:18s\n",
            "epoch 32 | loss: 4515515397.08303|  0:08:19s\n",
            "epoch 39 | loss: 4253549400.25993|  0:08:19s\n",
            "epoch 33 | loss: 12196291151.48014|  0:08:22s\n",
            "epoch 42 | loss: 4445299495.74007|  0:08:25s\n",
            "epoch 39 | loss: 12125376496.7509|  0:08:25s\n",
            "epoch 39 | loss: 13542005099.66786|  0:08:27s\n",
            "epoch 42 | loss: 13729110544.17328|  0:08:28s\n",
            "epoch 39 | loss: 11962995494.81588|  0:08:29s\n",
            "epoch 44 | loss: 12259090222.20938|  0:08:29s\n",
            "epoch 39 | loss: 13984786714.80144|  0:08:30s\n",
            "epoch 33 | loss: 13144222367.88448|  0:08:30s\n",
            "epoch 40 | loss: 4570647491.9278|  0:08:30s\n",
            "epoch 40 | loss: 4205085510.93141|  0:08:32s\n",
            "epoch 33 | loss: 4539104049.44404|  0:08:35s\n",
            "epoch 43 | loss: 4426440591.2491|  0:08:36s\n",
            "epoch 34 | loss: 12147627819.89892|  0:08:37s\n",
            "epoch 40 | loss: 12091244501.02527|  0:08:38s\n",
            "epoch 40 | loss: 13585365046.52708|  0:08:39s\n",
            "epoch 43 | loss: 13818256267.55235|  0:08:40s\n",
            "epoch 45 | loss: 12123876784.05776|  0:08:40s\n",
            "epoch 40 | loss: 11914706569.47292|  0:08:42s\n",
            "epoch 41 | loss: 4535231226.45487|  0:08:43s\n",
            "epoch 40 | loss: 13963196372.56317|  0:08:43s\n",
            "epoch 41 | loss: 4143647536.51985|  0:08:44s\n",
            "epoch 34 | loss: 13153167120.17328|  0:08:45s\n",
            "epoch 44 | loss: 4418481833.12636|  0:08:48s\n",
            "epoch 34 | loss: 4492997790.4982|  0:08:50s\n",
            "epoch 41 | loss: 12047901140.10108|  0:08:51s\n",
            "epoch 44 | loss: 13822502222.09387|  0:08:51s\n",
            "epoch 46 | loss: 12094473481.24187|  0:08:52s\n",
            "epoch 35 | loss: 12072232831.53791|  0:08:52s\n",
            "epoch 41 | loss: 13500240966.23826|  0:08:52s\n",
            "epoch 41 | loss: 11888561359.94224|  0:08:54s\n",
            "epoch 42 | loss: 4492639860.90975|  0:08:55s\n",
            "epoch 41 | loss: 13794513170.48376|  0:08:55s\n",
            "epoch 42 | loss: 4185863587.11913|  0:08:56s\n",
            "epoch 45 | loss: 4374685199.71119|  0:08:59s\n",
            "epoch 35 | loss: 13205973877.83393|  0:09:00s\n",
            "epoch 47 | loss: 12040845962.62816|  0:09:03s\n",
            "epoch 45 | loss: 13816484934.23827|  0:09:03s\n",
            "epoch 42 | loss: 12075316552.54874|  0:09:04s\n",
            "epoch 42 | loss: 13605320886.06498|  0:09:05s\n",
            "epoch 35 | loss: 4811052068.04332|  0:09:05s\n",
            "epoch 42 | loss: 11871918516.6787|  0:09:07s\n",
            "epoch 36 | loss: 12038170511.2491|  0:09:07s\n",
            "epoch 43 | loss: 4456825337.0686|  0:09:07s\n",
            "epoch 42 | loss: 13738169961.3574|  0:09:08s\n",
            "epoch 43 | loss: 4224619714.54152|  0:09:09s\n",
            "epoch 46 | loss: 4327800245.14079|  0:09:11s\n",
            "epoch 48 | loss: 12293801385.58845|  0:09:14s\n",
            "epoch 36 | loss: 13103134255.13357|  0:09:15s\n",
            "epoch 46 | loss: 13774072037.66065|  0:09:15s\n",
            "epoch 43 | loss: 12181061291.89892|  0:09:17s\n",
            "epoch 43 | loss: 13735237132.01445|  0:09:18s\n",
            "epoch 43 | loss: 11800950800.17328|  0:09:19s\n",
            "epoch 44 | loss: 4305908381.574|  0:09:20s\n",
            "epoch 43 | loss: 13762167490.07942|  0:09:20s\n",
            "epoch 36 | loss: 5339066629.08303|  0:09:20s\n",
            "epoch 44 | loss: 4206813785.18411|  0:09:21s\n",
            "epoch 37 | loss: 12042042743.22022|  0:09:22s\n",
            "epoch 47 | loss: 4310993191.74007|  0:09:22s\n",
            "epoch 49 | loss: 12387739446.98917|  0:09:25s\n",
            "epoch 47 | loss: 13759170882.07943|  0:09:27s\n",
            "epoch 37 | loss: 12986593243.95669|  0:09:29s\n",
            "epoch 44 | loss: 12112840960.46209|  0:09:29s\n",
            "epoch 44 | loss: 13821705680.40433|  0:09:30s\n",
            "epoch 44 | loss: 11799398715.61011|  0:09:32s\n",
            "epoch 45 | loss: 4267075251.29241|  0:09:32s\n",
            "epoch 44 | loss: 13744765890.54151|  0:09:33s\n",
            "epoch 45 | loss: 4155109784.49097|  0:09:33s\n",
            "epoch 48 | loss: 4302145219.9278|  0:09:34s\n",
            "epoch 37 | loss: 5493580964.50542|  0:09:35s\n",
            "epoch 38 | loss: 12009176007.62455|  0:09:37s\n",
            "epoch 50 | loss: 12245257402.22382|  0:09:37s\n",
            "epoch 48 | loss: 13789506815.07581|  0:09:39s\n",
            "epoch 45 | loss: 12038839783.04693|  0:09:42s\n",
            "epoch 45 | loss: 13684875316.2166|  0:09:43s\n",
            "epoch 38 | loss: 13071211150.787|  0:09:44s\n",
            "epoch 45 | loss: 11781423303.62455|  0:09:45s\n",
            "epoch 46 | loss: 4201108650.05054|  0:09:45s\n",
            "epoch 45 | loss: 13656201081.53068|  0:09:45s\n",
            "epoch 49 | loss: 4236781202.02166|  0:09:45s\n",
            "epoch 46 | loss: 4058230893.97834|  0:09:46s\n",
            "epoch 51 | loss: 12038787887.13357|  0:09:48s\n",
            "epoch 49 | loss: 13875770507.09026|  0:09:50s\n",
            "epoch 38 | loss: 5063271554.31047|  0:09:51s\n",
            "epoch 39 | loss: 11971102774.52708|  0:09:52s\n",
            "epoch 46 | loss: 12125268098.31047|  0:09:55s\n",
            "epoch 46 | loss: 13711502192.28882|  0:09:56s\n",
            "epoch 50 | loss: 4190535387.49458|  0:09:57s\n",
            "epoch 46 | loss: 11772063331.81227|  0:09:57s\n",
            "epoch 47 | loss: 4295064975.2491|  0:09:57s\n",
            "epoch 46 | loss: 13544755764.6787|  0:09:58s\n",
            "epoch 47 | loss: 4162482324.79422|  0:09:58s\n",
            "epoch 52 | loss: 11967601074.83032|  0:09:59s\n",
            "epoch 39 | loss: 13041024693.1408|  0:10:00s\n",
            "epoch 50 | loss: 13807947073.61733|  0:10:02s\n",
            "epoch 39 | loss: 4705586472.20217|  0:10:05s\n",
            "epoch 40 | loss: 12032958330.91697|  0:10:07s\n",
            "epoch 47 | loss: 12006497637.66064|  0:10:08s\n",
            "epoch 51 | loss: 4206183106.07942|  0:10:08s\n",
            "epoch 47 | loss: 13625652664.83754|  0:10:09s\n",
            "epoch 47 | loss: 11803905332.21662|  0:10:09s\n",
            "epoch 48 | loss: 4390815871.07581|  0:10:10s\n",
            "epoch 53 | loss: 12053238253.97834|  0:10:10s\n",
            "epoch 48 | loss: 4061640388.3899|  0:10:10s\n",
            "epoch 47 | loss: 13312636687.2491|  0:10:10s\n",
            "epoch 51 | loss: 13886150443.43682|  0:10:13s\n",
            "epoch 40 | loss: 13000945196.36101|  0:10:15s\n",
            "epoch 52 | loss: 4148893265.32852|  0:10:20s\n",
            "epoch 40 | loss: 4738324406.98917|  0:10:21s\n",
            "epoch 48 | loss: 11973795325.22745|  0:10:21s\n",
            "epoch 54 | loss: 12160211656.08664|  0:10:21s\n",
            "epoch 48 | loss: 13714585546.39712|  0:10:21s\n",
            "epoch 41 | loss: 11942598764.59206|  0:10:21s\n",
            "epoch 49 | loss: 4367178051.9278|  0:10:22s\n",
            "epoch 48 | loss: 11986237275.03249|  0:10:22s\n",
            "epoch 48 | loss: 13502796384.11552|  0:10:23s\n",
            "epoch 49 | loss: 3947259870.72924|  0:10:23s\n",
            "epoch 52 | loss: 13790821611.66786|  0:10:25s\n",
            "epoch 41 | loss: 13018190478.78701|  0:10:30s\n",
            "epoch 55 | loss: 12122193193.12636|  0:10:32s\n",
            "epoch 53 | loss: 4191066886.46931|  0:10:32s\n",
            "epoch 49 | loss: 11945522226.83033|  0:10:34s\n",
            "epoch 49 | loss: 13780137770.97473|  0:10:34s\n",
            "epoch 50 | loss: 4356949718.87364|  0:10:34s\n",
            "epoch 49 | loss: 11776017965.2852|  0:10:34s\n",
            "epoch 49 | loss: 13403546171.14801|  0:10:35s\n",
            "epoch 50 | loss: 4004881015.22021|  0:10:35s\n",
            "epoch 41 | loss: 4749694942.72924|  0:10:36s\n",
            "epoch 42 | loss: 11883202233.29964|  0:10:36s\n",
            "epoch 53 | loss: 13816442352.7509|  0:10:37s\n",
            "epoch 56 | loss: 12121364233.70397|  0:10:43s\n",
            "epoch 54 | loss: 4095303277.51625|  0:10:43s\n",
            "epoch 42 | loss: 12913326304.57762|  0:10:45s\n",
            "epoch 50 | loss: 11975030186.05054|  0:10:47s\n",
            "epoch 51 | loss: 4273172829.34296|  0:10:47s\n",
            "epoch 50 | loss: 13585299088.1733|  0:10:47s\n",
            "epoch 50 | loss: 11719583262.0361|  0:10:47s\n",
            "epoch 51 | loss: 4032142357.25631|  0:10:48s\n",
            "epoch 50 | loss: 13431863699.40794|  0:10:48s\n",
            "epoch 54 | loss: 13726913650.13718|  0:10:49s\n",
            "epoch 43 | loss: 11928977825.5018|  0:10:51s\n",
            "epoch 42 | loss: 4739416738.19495|  0:10:51s\n",
            "epoch 57 | loss: 12141988263.74007|  0:10:54s\n",
            "epoch 55 | loss: 4079823340.59206|  0:10:55s\n",
            "epoch 51 | loss: 11982302395.61011|  0:10:59s\n",
            "epoch 52 | loss: 4172663517.80505|  0:10:59s\n",
            "epoch 43 | loss: 12907518362.33934|  0:11:00s\n",
            "epoch 51 | loss: 13734164800.69314|  0:10:59s\n",
            "epoch 51 | loss: 11752806121.3574|  0:11:00s\n",
            "epoch 55 | loss: 13782121016.37546|  0:11:00s\n",
            "epoch 52 | loss: 4336225664.0|  0:11:01s\n",
            "epoch 51 | loss: 13408764867.92779|  0:11:01s\n",
            "epoch 58 | loss: 12173476210.13718|  0:11:05s\n",
            "epoch 44 | loss: 11877987384.83754|  0:11:05s\n",
            "epoch 43 | loss: 4744669458.02166|  0:11:06s\n",
            "epoch 56 | loss: 4112117229.97834|  0:11:06s\n",
            "epoch 52 | loss: 13566624786.94584|  0:11:12s\n",
            "epoch 53 | loss: 3998458814.84476|  0:11:12s\n",
            "epoch 52 | loss: 11687569387.43682|  0:11:12s\n",
            "epoch 52 | loss: 11926364335.13358|  0:11:12s\n",
            "epoch 56 | loss: 13830407669.37184|  0:11:12s\n",
            "epoch 53 | loss: 4235090290.59928|  0:11:13s\n",
            "epoch 52 | loss: 13405094425.87726|  0:11:13s\n",
            "epoch 44 | loss: 13046515470.787|  0:11:15s\n",
            "epoch 59 | loss: 12043312105.8195|  0:11:16s\n",
            "epoch 57 | loss: 4064149390.78701|  0:11:18s\n",
            "epoch 45 | loss: 11845786249.24188|  0:11:20s\n",
            "epoch 44 | loss: 4756158181.19856|  0:11:21s\n",
            "epoch 57 | loss: 13902696869.42961|  0:11:24s\n",
            "epoch 53 | loss: 11860562715.26354|  0:11:24s\n",
            "epoch 54 | loss: 4040623256.95307|  0:11:25s\n",
            "epoch 53 | loss: 13559892577.03972|  0:11:25s\n",
            "epoch 53 | loss: 12018868065.9639|  0:11:25s\n",
            "epoch 53 | loss: 13466992580.85198|  0:11:26s\n",
            "epoch 54 | loss: 4091061137.09747|  0:11:26s\n",
            "epoch 60 | loss: 11890509890.07942|  0:11:27s\n",
            "epoch 45 | loss: 12911185626.1083|  0:11:29s\n",
            "epoch 58 | loss: 4075280954.68592|  0:11:29s\n",
            "epoch 46 | loss: 11782100371.40794|  0:11:35s\n",
            "epoch 45 | loss: 4762595381.60289|  0:11:36s\n",
            "epoch 58 | loss: 13823752416.11551|  0:11:36s\n",
            "epoch 54 | loss: 11953929916.0722|  0:11:36s\n",
            "epoch 55 | loss: 4358866173.22744|  0:11:37s\n",
            "epoch 54 | loss: 13530037748.44766|  0:11:37s\n",
            "epoch 54 | loss: 11976570162.83032|  0:11:38s\n",
            "epoch 54 | loss: 13309441332.6787|  0:11:38s\n",
            "epoch 55 | loss: 4150743875.00361|  0:11:38s\n",
            "epoch 61 | loss: 11800480745.3574|  0:11:38s\n",
            "epoch 59 | loss: 4097649110.87365|  0:11:41s\n",
            "epoch 46 | loss: 12883209552.40434|  0:11:44s\n",
            "epoch 59 | loss: 13833298532.73646|  0:11:48s\n",
            "epoch 55 | loss: 11904440479.88448|  0:11:49s\n",
            "epoch 56 | loss: 4165785304.72202|  0:11:49s\n",
            "epoch 47 | loss: 11692427460.85199|  0:11:49s\n",
            "epoch 62 | loss: 11871346778.1083|  0:11:50s\n",
            "epoch 55 | loss: 13571142070.98917|  0:11:50s\n",
            "epoch 46 | loss: 4759335047.8556|  0:11:51s\n",
            "epoch 56 | loss: 4095716561.79061|  0:11:51s\n",
            "epoch 55 | loss: 13389176294.12275|  0:11:51s\n",
            "epoch 55 | loss: 11923272462.787|  0:11:51s\n",
            "epoch 60 | loss: 4113360553.12636|  0:11:52s\n",
            "epoch 47 | loss: 12855211949.7473|  0:11:59s\n",
            "epoch 60 | loss: 13823840524.93864|  0:12:00s\n",
            "epoch 63 | loss: 11793298644.56318|  0:12:00s\n",
            "epoch 57 | loss: 4167921741.16967|  0:12:01s\n",
            "epoch 56 | loss: 11797710915.4657|  0:12:01s\n",
            "epoch 56 | loss: 13477695498.16606|  0:12:03s\n",
            "epoch 56 | loss: 13600124846.67149|  0:12:03s\n",
            "epoch 57 | loss: 4087300973.97834|  0:12:03s\n",
            "epoch 61 | loss: 4123922571.09025|  0:12:04s\n",
            "epoch 48 | loss: 11734174414.09386|  0:12:04s\n",
            "epoch 56 | loss: 11857042799.36462|  0:12:04s\n",
            "epoch 47 | loss: 4767116574.4982|  0:12:05s\n",
            "epoch 64 | loss: 11968421120.92419|  0:12:11s\n",
            "epoch 61 | loss: 13792601225.24188|  0:12:12s\n",
            "epoch 58 | loss: 4324937264.51986|  0:12:13s\n",
            "epoch 57 | loss: 11726769825.27076|  0:12:13s\n",
            "epoch 48 | loss: 12816648511.30686|  0:12:14s\n",
            "epoch 57 | loss: 13289076655.13358|  0:12:15s\n",
            "epoch 62 | loss: 4088359775.19134|  0:12:16s\n",
            "epoch 57 | loss: 13470151069.57399|  0:12:16s\n",
            "epoch 58 | loss: 4118504179.98556|  0:12:16s\n",
            "epoch 57 | loss: 11828194875.14801|  0:12:17s\n",
            "epoch 49 | loss: 11717355279.2491|  0:12:19s\n",
            "epoch 48 | loss: 4769795937.03971|  0:12:20s\n",
            "epoch 65 | loss: 11848922108.76534|  0:12:23s\n",
            "epoch 62 | loss: 13691449170.7148|  0:12:24s\n",
            "epoch 59 | loss: 4480369073.90613|  0:12:24s\n",
            "epoch 58 | loss: 11680457570.88809|  0:12:26s\n",
            "epoch 63 | loss: 4068587799.10469|  0:12:27s\n",
            "epoch 58 | loss: 13382368046.20938|  0:12:28s\n",
            "epoch 58 | loss: 13520371490.65703|  0:12:28s\n",
            "epoch 59 | loss: 3959007681.61733|  0:12:29s\n",
            "epoch 49 | loss: 12738081546.16606|  0:12:29s\n",
            "epoch 58 | loss: 11816460551.85559|  0:12:30s\n",
            "epoch 50 | loss: 11666970724.27436|  0:12:33s\n",
            "epoch 66 | loss: 12261225807.48014|  0:12:34s\n",
            "epoch 63 | loss: 13619472348.41877|  0:12:35s\n",
            "epoch 49 | loss: 4783433933.63177|  0:12:35s\n",
            "epoch 60 | loss: 4470353986.77256|  0:12:37s\n",
            "epoch 59 | loss: 11665257075.06137|  0:12:38s\n",
            "epoch 64 | loss: 4065845312.23104|  0:12:39s\n",
            "epoch 59 | loss: 13642307686.58484|  0:12:40s\n",
            "epoch 59 | loss: 13381741819.37906|  0:12:41s\n",
            "epoch 60 | loss: 4065278887.74007|  0:12:42s\n",
            "epoch 59 | loss: 11914643997.57401|  0:12:43s\n",
            "epoch 50 | loss: 12818422402.31046|  0:12:44s\n",
            "epoch 67 | loss: 12216036983.22022|  0:12:45s\n",
            "epoch 64 | loss: 13593173447.16246|  0:12:47s\n",
            "epoch 51 | loss: 11677236132.50541|  0:12:48s\n",
            "epoch 61 | loss: 4197491299.35018|  0:12:49s\n",
            "epoch 65 | loss: 4004689766.58484|  0:12:50s\n",
            "epoch 50 | loss: 4762547884.36101|  0:12:51s\n",
            "epoch 60 | loss: 11721185719.22021|  0:12:51s\n",
            "epoch 60 | loss: 13393800467.87005|  0:12:53s\n",
            "epoch 60 | loss: 13311888440.37546|  0:12:53s\n",
            "epoch 61 | loss: 4052804734.15163|  0:12:54s\n",
            "epoch 68 | loss: 12150631062.6426|  0:12:55s\n",
            "epoch 60 | loss: 11828149111.22022|  0:12:56s\n",
            "epoch 65 | loss: 13597878421.25632|  0:12:59s\n",
            "epoch 51 | loss: 12728837233.67507|  0:12:59s\n",
            "epoch 62 | loss: 4088075575.91336|  0:13:02s\n",
            "epoch 66 | loss: 4140672510.61372|  0:13:02s\n",
            "epoch 52 | loss: 11759451137.84838|  0:13:03s\n",
            "epoch 61 | loss: 11591890236.99639|  0:13:03s\n",
            "epoch 51 | loss: 4774020011.89892|  0:13:06s\n",
            "epoch 61 | loss: 13156268472.37546|  0:13:06s\n",
            "epoch 61 | loss: 13466056067.23464|  0:13:06s\n",
            "epoch 69 | loss: 12091002843.03249|  0:13:06s\n",
            "epoch 62 | loss: 3944573195.55235|  0:13:07s\n",
            "epoch 61 | loss: 11882859111.04693|  0:13:09s\n",
            "epoch 66 | loss: 13582750000.51986|  0:13:11s\n",
            "epoch 63 | loss: 4080077731.58123|  0:13:14s\n",
            "epoch 52 | loss: 12691810826.16606|  0:13:14s\n",
            "epoch 67 | loss: 4036957274.1083|  0:13:14s\n",
            "epoch 62 | loss: 11539543125.48737|  0:13:16s\n",
            "epoch 70 | loss: 12106956629.02527|  0:13:17s\n",
            "epoch 53 | loss: 11598329889.73285|  0:13:18s\n",
            "epoch 62 | loss: 13289477303.91337|  0:13:19s\n",
            "epoch 62 | loss: 13274759433.70397|  0:13:19s\n",
            "epoch 63 | loss: 3971809806.32491|  0:13:20s\n",
            "epoch 52 | loss: 4753617258.74368|  0:13:21s\n",
            "epoch 62 | loss: 11915172193.5018|  0:13:22s\n",
            "epoch 67 | loss: 13799416910.09386|  0:13:23s\n",
            "epoch 68 | loss: 4090332682.16606|  0:13:25s\n",
            "epoch 64 | loss: 3729438119.74007|  0:13:26s\n",
            "epoch 71 | loss: 12056736742.58484|  0:13:28s\n",
            "epoch 63 | loss: 11596120100.50542|  0:13:28s\n",
            "epoch 53 | loss: 12853530406.58484|  0:13:29s\n",
            "epoch 63 | loss: 13256014707.98556|  0:13:31s\n",
            "epoch 63 | loss: 13167196172.93862|  0:13:32s\n",
            "epoch 54 | loss: 11546781817.53068|  0:13:32s\n",
            "epoch 64 | loss: 3995415778.426|  0:13:32s\n",
            "epoch 68 | loss: 13477749823.76896|  0:13:34s\n",
            "epoch 63 | loss: 11966708437.94946|  0:13:35s\n",
            "epoch 53 | loss: 4762828536.6065|  0:13:36s\n",
            "epoch 69 | loss: 3973877243.37906|  0:13:37s\n",
            "epoch 65 | loss: 3832280468.56318|  0:13:38s\n",
            "epoch 72 | loss: 12031327367.3935|  0:13:39s\n",
            "epoch 64 | loss: 11653543597.74729|  0:13:41s\n",
            "epoch 64 | loss: 13296503098.68592|  0:13:44s\n",
            "epoch 54 | loss: 12720846933.02527|  0:13:44s\n",
            "epoch 64 | loss: 13091250353.213|  0:13:44s\n",
            "epoch 65 | loss: 3938641536.92419|  0:13:45s\n",
            "epoch 69 | loss: 13625372903.97112|  0:13:46s\n",
            "epoch 55 | loss: 11552547382.06498|  0:13:46s\n",
            "epoch 64 | loss: 11986895777.27076|  0:13:48s\n",
            "epoch 70 | loss: 4025408196.38989|  0:13:49s\n",
            "epoch 73 | loss: 12061946831.01805|  0:13:50s\n",
            "epoch 66 | loss: 3854078089.70397|  0:13:51s\n",
            "epoch 54 | loss: 4769163436.8231|  0:13:51s\n",
            "epoch 65 | loss: 11678956662.29602|  0:13:53s\n",
            "epoch 65 | loss: 13277419603.1769|  0:13:56s\n",
            "epoch 65 | loss: 13396304604.41877|  0:13:57s\n",
            "epoch 66 | loss: 3895043778.07942|  0:13:57s\n",
            "epoch 70 | loss: 13383207954.02166|  0:13:58s\n",
            "epoch 55 | loss: 12546780077.7473|  0:13:59s\n",
            "epoch 71 | loss: 3912897052.64982|  0:14:01s\n",
            "epoch 65 | loss: 11994081195.20578|  0:14:01s\n",
            "epoch 74 | loss: 12054495296.23105|  0:14:01s\n",
            "epoch 56 | loss: 11593915173.42961|  0:14:01s\n",
            "epoch 67 | loss: 3903723944.66426|  0:14:03s\n",
            "epoch 66 | loss: 11595323154.48376|  0:14:05s\n",
            "epoch 55 | loss: 4769960352.34657|  0:14:06s\n",
            "epoch 66 | loss: 13325266644.10109|  0:14:09s\n",
            "epoch 66 | loss: 13141998156.70758|  0:14:10s\n",
            "epoch 67 | loss: 3884070734.55596|  0:14:10s\n",
            "epoch 71 | loss: 13458437496.60651|  0:14:10s\n",
            "epoch 75 | loss: 11880201711.82672|  0:14:12s\n",
            "epoch 72 | loss: 3933344315.14801|  0:14:12s\n",
            "epoch 56 | loss: 12807196431.71119|  0:14:14s\n",
            "epoch 66 | loss: 11922019653.77617|  0:14:14s\n",
            "epoch 68 | loss: 4035598410.8592|  0:14:15s\n",
            "epoch 57 | loss: 11473796931.9278|  0:14:16s\n",
            "epoch 67 | loss: 11578450696.31769|  0:14:18s\n",
            "epoch 67 | loss: 13289433951.65342|  0:14:21s\n",
            "epoch 56 | loss: 4742219389.68953|  0:14:21s\n",
            "epoch 72 | loss: 13584472419.35018|  0:14:22s\n",
            "epoch 67 | loss: 13188799776.34657|  0:14:22s\n",
            "epoch 68 | loss: 3959403696.51986|  0:14:22s\n",
            "epoch 76 | loss: 11871379721.70397|  0:14:23s\n",
            "epoch 73 | loss: 3939277455.2491|  0:14:24s\n",
            "epoch 67 | loss: 11789751227.84116|  0:14:27s\n",
            "epoch 69 | loss: 4225341009.79062|  0:14:27s\n",
            "epoch 57 | loss: 12980575750.46932|  0:14:29s\n",
            "epoch 58 | loss: 11538603959.45126|  0:14:30s\n",
            "epoch 68 | loss: 11497333699.4657|  0:14:30s\n",
            "epoch 73 | loss: 12156040880.05776|  0:14:33s\n",
            "epoch 68 | loss: 13152400756.90975|  0:14:33s\n",
            "epoch 77 | loss: 11879556791.91336|  0:14:34s\n",
            "epoch 68 | loss: 13197265376.57763|  0:14:35s\n",
            "epoch 69 | loss: 3840666290.83032|  0:14:35s\n",
            "epoch 74 | loss: 3998570002.48376|  0:14:36s\n",
            "epoch 57 | loss: 4752563361.27076|  0:14:36s\n",
            "epoch 70 | loss: 4224102998.41155|  0:14:40s\n",
            "epoch 68 | loss: 11788499783.16245|  0:14:40s\n",
            "epoch 69 | loss: 11500864407.10469|  0:14:43s\n",
            "epoch 58 | loss: 12828683148.93863|  0:14:44s\n",
            "epoch 74 | loss: 13339278835.06137|  0:14:45s\n",
            "epoch 78 | loss: 11900321472.23106|  0:14:45s\n",
            "epoch 59 | loss: 11448217921.15524|  0:14:45s\n",
            "epoch 69 | loss: 13232663486.38267|  0:14:46s\n",
            "epoch 70 | loss: 3902682950.23827|  0:14:48s\n",
            "epoch 69 | loss: 13198720949.14079|  0:14:47s\n",
            "epoch 75 | loss: 3903282803.52347|  0:14:48s\n",
            "epoch 58 | loss: 4747045202.25271|  0:14:52s\n",
            "epoch 71 | loss: 4156806672.63538|  0:14:52s\n",
            "epoch 69 | loss: 11778191505.09747|  0:14:53s\n",
            "epoch 70 | loss: 11514290163.52346|  0:14:56s\n",
            "epoch 79 | loss: 11824089510.81588|  0:14:56s\n",
            "epoch 75 | loss: 13489670514.59928|  0:14:57s\n",
            "epoch 59 | loss: 12651191215.59567|  0:14:58s\n",
            "epoch 70 | loss: 13596456294.58483|  0:14:59s\n",
            "epoch 76 | loss: 4003140932.85198|  0:14:59s\n",
            "epoch 60 | loss: 11485927957.25631|  0:15:00s\n",
            "epoch 70 | loss: 13194633516.36101|  0:15:00s\n",
            "epoch 71 | loss: 3729186251.78339|  0:15:00s\n",
            "epoch 72 | loss: 4118007346.83033|  0:15:04s\n",
            "epoch 70 | loss: 11745280730.5704|  0:15:06s\n",
            "epoch 59 | loss: 4739059697.67509|  0:15:07s\n",
            "epoch 80 | loss: 11785808227.81227|  0:15:07s\n",
            "epoch 71 | loss: 11391709160.43321|  0:15:08s\n",
            "epoch 76 | loss: 13337046803.87003|  0:15:08s\n",
            "epoch 71 | loss: 13287980154.45489|  0:15:11s\n",
            "epoch 77 | loss: 4096874299.84116|  0:15:11s\n",
            "epoch 71 | loss: 13215757622.98917|  0:15:12s\n",
            "epoch 60 | loss: 12746856207.2491|  0:15:13s\n",
            "epoch 72 | loss: 3870697653.83393|  0:15:13s\n",
            "epoch 61 | loss: 11520178273.50181|  0:15:14s\n",
            "epoch 73 | loss: 4010803038.72924|  0:15:16s\n",
            "epoch 81 | loss: 11856994288.28881|  0:15:18s\n",
            "epoch 71 | loss: 11675539742.0361|  0:15:19s\n",
            "epoch 77 | loss: 13361471411.29242|  0:15:20s\n",
            "epoch 72 | loss: 11318706021.66065|  0:15:21s\n",
            "epoch 60 | loss: 4751506327.10469|  0:15:22s\n",
            "epoch 78 | loss: 3883510253.97834|  0:15:23s\n",
            "epoch 72 | loss: 13169869349.4296|  0:15:24s\n",
            "epoch 72 | loss: 13083688730.33935|  0:15:25s\n",
            "epoch 73 | loss: 3986782331.14801|  0:15:25s\n",
            "epoch 61 | loss: 12149924857.53068|  0:15:28s\n",
            "epoch 74 | loss: 3925692394.28159|  0:15:29s\n",
            "epoch 62 | loss: 11635849503.88447|  0:15:29s\n",
            "epoch 82 | loss: 11784356712.43322|  0:15:29s\n",
            "epoch 72 | loss: 11745728680.66426|  0:15:32s\n",
            "epoch 78 | loss: 13316041608.77978|  0:15:32s\n",
            "epoch 73 | loss: 11451737406.38267|  0:15:33s\n",
            "epoch 79 | loss: 3978612606.15163|  0:15:34s\n",
            "epoch 73 | loss: 13066850740.2166|  0:15:36s\n",
            "epoch 61 | loss: 4768517723.49458|  0:15:37s\n",
            "epoch 73 | loss: 13075885206.6426|  0:15:37s\n",
            "epoch 74 | loss: 4069529919.76896|  0:15:38s\n",
            "epoch 83 | loss: 11858460205.2852|  0:15:40s\n",
            "epoch 75 | loss: 3921645697.84837|  0:15:41s\n",
            "epoch 62 | loss: 12544399979.20578|  0:15:42s\n",
            "epoch 79 | loss: 13317608720.63538|  0:15:44s\n",
            "epoch 63 | loss: 11596110402.54152|  0:15:44s\n",
            "epoch 73 | loss: 11702747788.01444|  0:15:45s\n",
            "epoch 80 | loss: 3977841089.61733|  0:15:46s\n",
            "epoch 74 | loss: 12124001538.77256|  0:15:46s\n",
            "epoch 74 | loss: 13121172874.16606|  0:15:49s\n",
            "epoch 74 | loss: 12787474791.50902|  0:15:50s\n",
            "epoch 75 | loss: 3952151737.76174|  0:15:51s\n",
            "epoch 84 | loss: 11727089662.15162|  0:15:51s\n",
            "epoch 62 | loss: 4755213248.23105|  0:15:52s\n",
            "epoch 76 | loss: 3821439440.40433|  0:15:53s\n",
            "epoch 80 | loss: 13282173947.84116|  0:15:55s\n",
            "epoch 63 | loss: 12314717802.74368|  0:15:57s\n",
            "epoch 74 | loss: 11689897641.12635|  0:15:57s\n",
            "epoch 81 | loss: 3828890255.2491|  0:15:57s\n",
            "epoch 75 | loss: 11975269041.90614|  0:15:58s\n",
            "epoch 64 | loss: 11579934375.74007|  0:15:59s\n",
            "epoch 75 | loss: 12981182293.02527|  0:16:01s\n",
            "epoch 75 | loss: 12993964928.92418|  0:16:02s\n",
            "epoch 85 | loss: 11739197450.62816|  0:16:02s\n",
            "epoch 76 | loss: 3802860203.43682|  0:16:04s\n",
            "epoch 77 | loss: 3734835277.63177|  0:16:05s\n",
            "epoch 81 | loss: 13463471901.574|  0:16:07s\n",
            "epoch 63 | loss: 4774012087.91336|  0:16:07s\n",
            "epoch 82 | loss: 3939130352.7509|  0:16:09s\n",
            "epoch 75 | loss: 11637423673.76174|  0:16:10s\n",
            "epoch 76 | loss: 11330680869.8917|  0:16:11s\n",
            "epoch 64 | loss: 12604625314.19494|  0:16:12s\n",
            "epoch 76 | loss: 13127158867.17691|  0:16:13s\n",
            "epoch 86 | loss: 11819882815.76895|  0:16:13s\n",
            "epoch 65 | loss: 11433394973.34296|  0:16:14s\n",
            "epoch 76 | loss: 12794464374.75812|  0:16:15s\n",
            "epoch 77 | loss: 3598097809.55957|  0:16:16s\n",
            "epoch 78 | loss: 4104505491.40794|  0:16:18s\n",
            "epoch 82 | loss: 13420512448.23105|  0:16:19s\n",
            "epoch 83 | loss: 3895526942.0361|  0:16:20s\n",
            "epoch 64 | loss: 4818644890.33935|  0:16:22s\n",
            "epoch 76 | loss: 11762552463.71119|  0:16:23s\n",
            "epoch 77 | loss: 11368412740.3899|  0:16:23s\n",
            "epoch 87 | loss: 11691921433.87725|  0:16:24s\n",
            "epoch 77 | loss: 13033607385.64621|  0:16:26s\n",
            "epoch 65 | loss: 12165915053.05416|  0:16:27s\n",
            "epoch 77 | loss: 12863789075.40794|  0:16:27s\n",
            "epoch 66 | loss: 11410283194.68592|  0:16:28s\n",
            "epoch 78 | loss: 3538687404.8231|  0:16:29s\n",
            "epoch 79 | loss: 4056260741.08303|  0:16:30s\n",
            "epoch 83 | loss: 13447849309.34296|  0:16:31s\n",
            "epoch 84 | loss: 3942407651.81228|  0:16:32s\n",
            "epoch 88 | loss: 11666536681.3574|  0:16:35s\n",
            "epoch 77 | loss: 11669961624.49097|  0:16:36s\n",
            "epoch 78 | loss: 11404202003.87003|  0:16:36s\n",
            "epoch 65 | loss: 4765874187.55234|  0:16:37s\n",
            "epoch 78 | loss: 12911989071.01805|  0:16:39s\n",
            "epoch 78 | loss: 12718031242.62816|  0:16:40s\n",
            "epoch 66 | loss: 12542391910.58484|  0:16:41s\n",
            "epoch 79 | loss: 3696190128.05776|  0:16:41s\n",
            "epoch 80 | loss: 3957533838.32491|  0:16:42s\n",
            "epoch 67 | loss: 11415339928.95306|  0:16:43s\n",
            "epoch 84 | loss: 13239426389.94946|  0:16:43s\n",
            "epoch 85 | loss: 3906910159.01805|  0:16:44s\n",
            "epoch 89 | loss: 11735813110.75812|  0:16:46s\n",
            "epoch 79 | loss: 11324291657.01083|  0:16:48s\n",
            "epoch 78 | loss: 11600210725.8917|  0:16:49s\n",
            "epoch 79 | loss: 13069765885.22744|  0:16:51s\n",
            "epoch 79 | loss: 12939192215.10469|  0:16:52s\n",
            "epoch 66 | loss: 4782769278.15162|  0:16:52s\n",
            "epoch 80 | loss: 3895072926.4982|  0:16:54s\n",
            "epoch 81 | loss: 3815261086.0361|  0:16:54s\n",
            "epoch 85 | loss: 13481284446.72924|  0:16:55s\n",
            "epoch 86 | loss: 3825178327.33574|  0:16:55s\n",
            "epoch 67 | loss: 12495313742.09386|  0:16:56s\n",
            "epoch 68 | loss: 11549528983.33574|  0:16:57s\n",
            "epoch 90 | loss: 11726361100.93863|  0:16:58s\n",
            "epoch 80 | loss: 11310641682.48375|  0:17:01s\n",
            "epoch 79 | loss: 11590115140.85198|  0:17:02s\n",
            "epoch 80 | loss: 12977988815.48015|  0:17:04s\n",
            "epoch 80 | loss: 12830746689.61732|  0:17:05s\n",
            "epoch 81 | loss: 3792826605.2852|  0:17:07s\n",
            "epoch 86 | loss: 13253795095.10468|  0:17:07s\n",
            "epoch 82 | loss: 3815632726.41155|  0:17:07s\n",
            "epoch 87 | loss: 3888898564.62094|  0:17:07s\n",
            "epoch 67 | loss: 4791449864.77978|  0:17:08s\n",
            "epoch 91 | loss: 11712444179.87004|  0:17:09s\n",
            "epoch 68 | loss: 12140276912.51985|  0:17:11s\n",
            "epoch 69 | loss: 11396465700.50542|  0:17:12s\n",
            "epoch 81 | loss: 11334412666.91696|  0:17:13s\n",
            "epoch 80 | loss: 11561910216.08664|  0:17:15s\n",
            "epoch 81 | loss: 12959615434.8592|  0:17:16s\n",
            "epoch 81 | loss: 12776773906.02165|  0:17:17s\n",
            "epoch 87 | loss: 13232520259.00362|  0:17:19s\n",
            "epoch 88 | loss: 3971048450.77256|  0:17:19s\n",
            "epoch 83 | loss: 3783871199.19133|  0:17:19s\n",
            "epoch 82 | loss: 3709274313.01083|  0:17:19s\n",
            "epoch 92 | loss: 11672557112.37545|  0:17:20s\n",
            "epoch 68 | loss: 4773098603.66787|  0:17:22s\n",
            "epoch 69 | loss: 12413607488.92419|  0:17:25s\n",
            "epoch 82 | loss: 11330512802.19495|  0:17:26s\n",
            "epoch 70 | loss: 11305890610.83032|  0:17:27s\n",
            "epoch 81 | loss: 11515123125.1408|  0:17:27s\n",
            "epoch 82 | loss: 13036736689.67508|  0:17:28s\n",
            "epoch 82 | loss: 12691013777.09748|  0:17:30s\n",
            "epoch 89 | loss: 3958193252.73646|  0:17:30s\n",
            "epoch 88 | loss: 13436703353.5307|  0:17:31s\n",
            "epoch 93 | loss: 11600564115.87004|  0:17:31s\n",
            "epoch 84 | loss: 3920673877.94946|  0:17:31s\n",
            "epoch 83 | loss: 3714418940.76534|  0:17:32s\n",
            "epoch 69 | loss: 4799566915.00361|  0:17:37s\n",
            "epoch 83 | loss: 11342542484.33213|  0:17:39s\n",
            "epoch 70 | loss: 12451401433.64622|  0:17:40s\n",
            "epoch 82 | loss: 11559406773.83393|  0:17:40s\n",
            "epoch 83 | loss: 13054518758.12274|  0:17:41s\n",
            "epoch 71 | loss: 11421924194.88809|  0:17:41s\n",
            "epoch 94 | loss: 11598110573.05416|  0:17:42s\n",
            "epoch 90 | loss: 3825880757.60289|  0:17:42s\n",
            "epoch 83 | loss: 12682897609.93502|  0:17:42s\n",
            "epoch 89 | loss: 13136188816.17329|  0:17:43s\n",
            "epoch 85 | loss: 3634539534.32491|  0:17:43s\n",
            "epoch 84 | loss: 3680519783.97112|  0:17:45s\n",
            "epoch 84 | loss: 11332268629.94946|  0:17:51s\n",
            "epoch 95 | loss: 11663036855.45127|  0:17:53s\n",
            "epoch 70 | loss: 4783819463.62455|  0:17:53s\n",
            "epoch 83 | loss: 11529988661.60288|  0:17:53s\n",
            "epoch 84 | loss: 13029445917.574|  0:17:53s\n",
            "epoch 91 | loss: 3866852912.51986|  0:17:54s\n",
            "epoch 71 | loss: 12222505949.34296|  0:17:54s\n",
            "epoch 90 | loss: 13418546475.89892|  0:17:55s\n",
            "epoch 84 | loss: 13051154895.94224|  0:17:55s\n",
            "epoch 86 | loss: 3741850189.63177|  0:17:55s\n",
            "epoch 72 | loss: 11409349244.76534|  0:17:56s\n",
            "epoch 85 | loss: 3528964281.76173|  0:17:57s\n",
            "epoch 96 | loss: 11587174564.50541|  0:18:03s\n",
            "epoch 85 | loss: 11283897378.19494|  0:18:04s\n",
            "epoch 92 | loss: 3832206858.16606|  0:18:05s\n",
            "epoch 85 | loss: 13063584158.72924|  0:18:06s\n",
            "epoch 84 | loss: 11823751769.18412|  0:18:06s\n",
            "epoch 91 | loss: 13304555339.3213|  0:18:07s\n",
            "epoch 85 | loss: 12641508275.75451|  0:18:07s\n",
            "epoch 71 | loss: 4747108809.47292|  0:18:07s\n",
            "epoch 87 | loss: 3737106256.86643|  0:18:08s\n",
            "epoch 72 | loss: 12272076230.70036|  0:18:09s\n",
            "epoch 86 | loss: 3680138214.12274|  0:18:09s\n",
            "epoch 73 | loss: 11456175085.2852|  0:18:11s\n",
            "epoch 97 | loss: 11700457014.98917|  0:18:14s\n",
            "epoch 86 | loss: 11374399276.36101|  0:18:16s\n",
            "epoch 93 | loss: 3905015889.32852|  0:18:17s\n",
            "epoch 92 | loss: 13716301986.19494|  0:18:18s\n",
            "epoch 86 | loss: 12981021867.89891|  0:18:18s\n",
            "epoch 85 | loss: 11687159169.38628|  0:18:19s\n",
            "epoch 86 | loss: 12822282492.76534|  0:18:20s\n",
            "epoch 88 | loss: 3802963807.88448|  0:18:20s\n",
            "epoch 87 | loss: 3630286388.21661|  0:18:22s\n",
            "epoch 72 | loss: 4773807127.1047|  0:18:22s\n",
            "epoch 73 | loss: 12539055253.71842|  0:18:23s\n",
            "epoch 74 | loss: 11313307624.43322|  0:18:25s\n",
            "epoch 98 | loss: 11586591145.58845|  0:18:25s\n",
            "epoch 94 | loss: 3856946682.45488|  0:18:28s\n",
            "epoch 87 | loss: 11429759208.89531|  0:18:29s\n",
            "epoch 93 | loss: 13641883529.70397|  0:18:30s\n",
            "epoch 87 | loss: 12848323136.23106|  0:18:31s\n",
            "epoch 87 | loss: 12592086376.20217|  0:18:32s\n",
            "epoch 86 | loss: 11567194817.61732|  0:18:32s\n",
            "epoch 89 | loss: 3760209085.22744|  0:18:32s\n",
            "epoch 88 | loss: 3716456965.54513|  0:18:34s\n",
            "epoch 99 | loss: 11534740437.94946|  0:18:36s\n",
            "epoch 73 | loss: 4766372108.01444|  0:18:38s\n",
            "epoch 74 | loss: 12486964405.14079|  0:18:39s\n",
            "epoch 75 | loss: 11347248688.7509|  0:18:40s\n",
            "epoch 95 | loss: 3785899615.65343|  0:18:41s\n",
            "epoch 88 | loss: 11350609996.47654|  0:18:42s\n",
            "epoch 94 | loss: 13459429264.63538|  0:18:43s\n",
            "epoch 88 | loss: 12976760411.03249|  0:18:44s\n",
            "epoch 88 | loss: 12448913312.34657|  0:18:45s\n",
            "epoch 90 | loss: 3776045378.54152|  0:18:45s\n",
            "epoch 87 | loss: 11549515950.67148|  0:18:46s\n",
            "epoch 89 | loss: 3729944437.83394|  0:18:48s\n",
            "epoch 96 | loss: 3824166260.44765|  0:18:53s\n",
            "epoch 74 | loss: 4780146913.50181|  0:18:54s\n",
            "epoch 75 | loss: 12503755131.84116|  0:18:54s\n",
            "epoch 76 | loss: 11326095495.16246|  0:18:55s\n",
            "epoch 89 | loss: 11344139288.49097|  0:18:55s\n",
            "epoch 95 | loss: 13289356549.54512|  0:18:56s\n",
            "epoch 89 | loss: 13031031323.72564|  0:18:58s\n",
            "epoch 89 | loss: 12570681687.56679|  0:18:59s\n",
            "epoch 91 | loss: 3620049807.71119|  0:18:59s\n",
            "epoch 88 | loss: 11490280763.61011|  0:19:00s\n",
            "epoch 90 | loss: 3769903581.80506|  0:19:02s\n",
            "epoch 97 | loss: 3837702972.5343|  0:19:06s\n",
            "epoch 96 | loss: 13384335384.25993|  0:19:09s\n",
            "epoch 90 | loss: 11378809545.47292|  0:19:09s\n",
            "epoch 75 | loss: 4775109735.97112|  0:19:10s\n",
            "epoch 76 | loss: 11766612769.73285|  0:19:10s\n",
            "epoch 77 | loss: 11301709348.96751|  0:19:11s\n",
            "epoch 90 | loss: 12950597034.05056|  0:19:11s\n",
            "epoch 90 | loss: 12524399685.77617|  0:19:12s\n",
            "epoch 92 | loss: 3640563212.01444|  0:19:13s\n",
            "epoch 89 | loss: 11549098083.35018|  0:19:14s\n",
            "epoch 91 | loss: 3639164895.65343|  0:19:15s\n",
            "[CV] END .......................................n_a=8, n_d=8; total time=19.3min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 98 | loss: 3731624963.4657|  0:19:18s\n",
            "epoch 97 | loss: 13342032494.44043|  0:19:21s\n",
            "epoch 91 | loss: 11258647704.02888|  0:19:22s\n",
            "epoch 91 | loss: 13060198895.36462|  0:19:24s\n",
            "epoch 76 | loss: 4747083958.98917|  0:19:25s\n",
            "epoch 77 | loss: 12240111558.46932|  0:19:25s\n",
            "epoch 93 | loss: 3637731686.12274|  0:19:25s\n",
            "epoch 91 | loss: 12724124681.24188|  0:19:25s\n",
            "epoch 78 | loss: 11248172145.90614|  0:19:26s\n",
            "epoch 90 | loss: 11446747203.00361|  0:19:27s\n",
            "epoch 92 | loss: 3522880634.45487|  0:19:28s\n",
            "epoch 99 | loss: 3812422182.81588|  0:19:29s\n",
            "epoch 0  | loss: 22469755774.61372|  0:00:15s\n",
            "epoch 98 | loss: 13328110463.07581|  0:19:33s\n",
            "epoch 92 | loss: 11257455728.05776|  0:19:35s\n",
            "epoch 92 | loss: 13003553261.05415|  0:19:37s\n",
            "epoch 94 | loss: 3531443824.28881|  0:19:38s\n",
            "epoch 92 | loss: 12576258092.82311|  0:19:38s\n",
            "epoch 77 | loss: 4766113147.37906|  0:19:40s\n",
            "epoch 78 | loss: 12263723579.84116|  0:19:40s\n",
            "epoch 79 | loss: 11238618932.21661|  0:19:41s\n",
            "epoch 91 | loss: 11483212338.36824|  0:19:41s\n",
            "epoch 93 | loss: 3563792863.65343|  0:19:41s\n",
            "epoch 99 | loss: 13393646389.14079|  0:19:46s\n",
            "epoch 93 | loss: 11316329382.81589|  0:19:49s\n",
            "epoch 1  | loss: 21180927024.05776|  0:00:32s\n",
            "epoch 93 | loss: 13000746255.7112|  0:19:51s\n",
            "epoch 95 | loss: 3609030160.63538|  0:19:52s\n",
            "epoch 93 | loss: 12542931581.22744|  0:19:52s\n",
            "epoch 92 | loss: 11465160131.4657|  0:19:56s\n",
            "epoch 94 | loss: 3564962325.25632|  0:19:56s\n",
            "epoch 80 | loss: 11280140667.84116|  0:19:57s\n",
            "epoch 78 | loss: 4790519567.71119|  0:19:57s\n",
            "epoch 79 | loss: 12595534682.1083|  0:19:58s\n",
            "epoch 94 | loss: 11276133882.91696|  0:20:04s\n",
            "epoch 94 | loss: 12904166576.98195|  0:20:07s\n",
            "epoch 96 | loss: 3564989496.83755|  0:20:07s\n",
            "epoch 94 | loss: 12513553180.64982|  0:20:08s\n",
            "epoch 2  | loss: 19512221111.91337|  0:00:53s\n",
            "epoch 93 | loss: 11530203645.22744|  0:20:11s\n",
            "[CV] END .......................................n_a=8, n_d=8; total time=20.2min\n",
            "epoch 95 | loss: 3576270589.68953|  0:20:12s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 81 | loss: 11233078687.65343|  0:20:14s\n",
            "epoch 80 | loss: 12171098556.99639|  0:20:15s\n",
            "epoch 79 | loss: 4785495146.28159|  0:20:15s\n",
            "epoch 95 | loss: 11295952698.68592|  0:20:19s\n",
            "epoch 97 | loss: 3588067896.83754|  0:20:21s\n",
            "epoch 95 | loss: 12950035744.80867|  0:20:21s\n",
            "epoch 95 | loss: 12875829846.1805|  0:20:22s\n",
            "epoch 94 | loss: 11419768595.40794|  0:20:25s\n",
            "epoch 96 | loss: 3569794218.97473|  0:20:25s\n",
            "epoch 3  | loss: 17897269756.30325|  0:01:10s\n",
            "[CV] END .......................................n_a=8, n_d=8; total time=20.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 14653702887.04694|  0:00:16s\n",
            "epoch 82 | loss: 11179808645.08303|  0:20:29s\n",
            "epoch 81 | loss: 12136536281.6462|  0:20:30s\n",
            "epoch 80 | loss: 4799935494.93141|  0:20:31s\n",
            "epoch 96 | loss: 11329043449.06859|  0:20:32s\n",
            "epoch 98 | loss: 3565662079.07581|  0:20:33s\n",
            "epoch 96 | loss: 13042945705.12635|  0:20:34s\n",
            "epoch 96 | loss: 12957958732.2455|  0:20:34s\n",
            "epoch 97 | loss: 3537623509.02527|  0:20:38s\n",
            "epoch 95 | loss: 11490368374.29603|  0:20:38s\n",
            "epoch 4  | loss: 16472620286.15164|  0:01:25s\n",
            "epoch 0  | loss: 24241415851.89892|  0:00:15s\n",
            "epoch 83 | loss: 11130201125.4296|  0:20:44s\n",
            "epoch 1  | loss: 13361289325.05415|  0:00:32s\n",
            "epoch 97 | loss: 11312409896.20216|  0:20:44s\n",
            "epoch 82 | loss: 12394681301.94946|  0:20:45s\n",
            "epoch 99 | loss: 3561374475.7834|  0:20:46s\n",
            "epoch 81 | loss: 4764607405.2852|  0:20:46s\n",
            "epoch 97 | loss: 12959958812.64982|  0:20:47s\n",
            "epoch 97 | loss: 12525717013.48736|  0:20:47s\n",
            "epoch 98 | loss: 3608420052.10109|  0:20:51s\n",
            "epoch 96 | loss: 11433777779.52346|  0:20:51s\n",
            "epoch 98 | loss: 11266602529.27076|  0:20:57s\n",
            "epoch 5  | loss: 15424202338.88806|  0:01:41s\n",
            "epoch 84 | loss: 11458556498.7148|  0:20:59s\n",
            "epoch 83 | loss: 12078899312.28882|  0:21:00s\n",
            "epoch 1  | loss: 22949064770.54151|  0:00:31s\n",
            "epoch 2  | loss: 11759690753.84837|  0:00:48s\n",
            "epoch 98 | loss: 12538884654.20938|  0:21:00s\n",
            "epoch 98 | loss: 13157432979.87003|  0:21:00s\n",
            "epoch 82 | loss: 4801308796.76534|  0:21:02s\n",
            "epoch 99 | loss: 3388132287.76895|  0:21:04s\n",
            "epoch 97 | loss: 11397261978.80144|  0:21:05s\n",
            "epoch 99 | loss: 11396204740.85199|  0:21:12s\n",
            "epoch 99 | loss: 13021741575.8556|  0:21:15s\n",
            "epoch 99 | loss: 12495024944.05776|  0:21:15s\n",
            "epoch 85 | loss: 11159883670.41155|  0:21:16s\n",
            "epoch 84 | loss: 11894273471.76895|  0:21:17s\n",
            "epoch 6  | loss: 14618785339.14802|  0:02:00s\n",
            "epoch 83 | loss: 4790754236.5343|  0:21:20s\n",
            "epoch 2  | loss: 21157552699.14802|  0:00:51s\n",
            "epoch 3  | loss: 10205519990.29603|  0:01:08s\n",
            "epoch 98 | loss: 11380210247.62454|  0:21:21s\n",
            "epoch 86 | loss: 11191936755.98556|  0:21:34s\n",
            "[CV] END ......................................n_a=8, n_d=16; total time=21.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 85 | loss: 12315485962.62816|  0:21:36s\n",
            "epoch 99 | loss: 11427826627.4657|  0:21:36s\n",
            "epoch 84 | loss: 4803666196.33213|  0:21:38s\n",
            "epoch 7  | loss: 14095527612.5343|  0:02:24s\n",
            "epoch 4  | loss: 8907319670.29603|  0:01:31s\n",
            "epoch 3  | loss: 19601339804.18772|  0:01:15s\n",
            "epoch 87 | loss: 11185097660.99639|  0:21:52s\n",
            "epoch 86 | loss: 12264207606.29603|  0:21:55s\n",
            "epoch 85 | loss: 4783313536.46209|  0:21:56s\n",
            "epoch 0  | loss: 22332517693.92058|  0:00:27s\n",
            "epoch 8  | loss: 13635001445.19857|  0:02:47s\n",
            "epoch 5  | loss: 7874757889.84838|  0:01:53s\n",
            "epoch 4  | loss: 18342428195.11914|  0:01:37s\n",
            "epoch 88 | loss: 11209187528.77978|  0:22:10s\n",
            "epoch 87 | loss: 12226432649.93502|  0:22:14s\n",
            "epoch 86 | loss: 4806413165.51625|  0:22:14s\n",
            "[CV] END ......................................n_a=16, n_d=8; total time=22.3min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ......................................n_a=8, n_d=16; total time=22.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9  | loss: 13317317153.73286|  0:03:11s\n",
            "epoch 6  | loss: 7064550939.72563|  0:02:16s\n",
            "epoch 5  | loss: 17340270213.08304|  0:02:00s\n",
            "epoch 89 | loss: 11057891827.98556|  0:22:29s\n",
            "[CV] END ......................................n_a=8, n_d=16; total time=22.5min\n",
            "[CV] END ......................................n_a=16, n_d=8; total time=22.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1  | loss: 20262603217.79061|  0:00:54s\n",
            "epoch 87 | loss: 4795434691.4657|  0:22:33s\n",
            "epoch 88 | loss: 12055501442.31046|  0:22:34s\n",
            "epoch 0  | loss: 14541767328.80866|  0:00:23s\n",
            "[CV] END ......................................n_a=16, n_d=8; total time=22.7min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 10 | loss: 13023129606.00722|  0:03:28s\n",
            "epoch 90 | loss: 11799271322.5704|  0:22:45s\n",
            "epoch 6  | loss: 16468685608.66426|  0:02:17s\n",
            "epoch 7  | loss: 6444478786.54152|  0:02:34s\n",
            "epoch 0  | loss: 24089733330.7148|  0:00:18s\n",
            "epoch 0  | loss: 14777786626.77256|  0:00:17s\n",
            "epoch 0  | loss: 22582694412.93863|  0:00:17s\n",
            "epoch 88 | loss: 4795510721.15523|  0:22:49s\n",
            "epoch 89 | loss: 12343657066.51263|  0:22:49s\n",
            "epoch 2  | loss: 17894057606.93141|  0:01:13s\n",
            "epoch 1  | loss: 12533369904.05776|  0:00:40s\n",
            "epoch 0  | loss: 24258735274.05054|  0:00:17s\n",
            "epoch 91 | loss: 11214404453.8917|  0:23:01s\n",
            "epoch 11 | loss: 12842628348.30325|  0:03:44s\n",
            "epoch 7  | loss: 15833553621.48735|  0:02:32s\n",
            "epoch 8  | loss: 5963389580.93863|  0:02:50s\n",
            "epoch 1  | loss: 21935691169.73286|  0:00:36s\n",
            "epoch 90 | loss: 12100984517.77617|  0:23:04s\n",
            "epoch 1  | loss: 14097036217.76174|  0:00:33s\n",
            "epoch 89 | loss: 4808711878.70036|  0:23:04s\n",
            "epoch 1  | loss: 21898590991.71119|  0:00:34s\n",
            "epoch 3  | loss: 15941998311.97112|  0:01:32s\n",
            "epoch 2  | loss: 10181057182.96029|  0:00:57s\n",
            "epoch 92 | loss: 11214286440.8953|  0:23:16s\n",
            "epoch 1  | loss: 23689149162.74368|  0:00:34s\n",
            "epoch 12 | loss: 12769911003.49459|  0:03:59s\n",
            "epoch 8  | loss: 15323108900.04332|  0:02:48s\n",
            "epoch 9  | loss: 5545739254.75812|  0:03:06s\n",
            "epoch 91 | loss: 11970501778.25271|  0:23:19s\n",
            "epoch 90 | loss: 4797063954.48375|  0:23:20s\n",
            "epoch 2  | loss: 12979089975.45126|  0:00:50s\n",
            "epoch 2  | loss: 19522135089.90614|  0:00:53s\n",
            "epoch 2  | loss: 20780425650.36823|  0:00:51s\n",
            "epoch 4  | loss: 14615650517.48735|  0:01:50s\n",
            "epoch 3  | loss: 8204550137.53068|  0:01:14s\n",
            "epoch 93 | loss: 11208200952.6065|  0:23:31s\n",
            "epoch 13 | loss: 12807615013.8917|  0:04:15s\n",
            "epoch 9  | loss: 14993091697.67509|  0:03:03s\n",
            "epoch 2  | loss: 22778050375.16246|  0:00:51s\n",
            "epoch 10 | loss: 5254013688.1444|  0:03:21s\n",
            "epoch 92 | loss: 11861005535.19133|  0:23:34s\n",
            "epoch 91 | loss: 4803718140.30325|  0:23:36s\n",
            "epoch 3  | loss: 11800476391.04693|  0:01:06s\n",
            "epoch 3  | loss: 19617637359.36463|  0:01:07s\n",
            "epoch 3  | loss: 17737810443.09025|  0:01:10s\n",
            "epoch 5  | loss: 13800085398.6426|  0:02:08s\n",
            "epoch 94 | loss: 11171113746.94585|  0:23:46s\n",
            "epoch 4  | loss: 6904948061.34296|  0:01:31s\n",
            "epoch 10 | loss: 14698457145.76173|  0:03:18s\n",
            "epoch 14 | loss: 12701063376.40433|  0:04:31s\n",
            "epoch 11 | loss: 5077508229.08303|  0:03:37s\n",
            "epoch 93 | loss: 12274303250.48375|  0:23:50s\n",
            "epoch 3  | loss: 21819958562.19495|  0:01:08s\n",
            "epoch 92 | loss: 4800368808.66426|  0:23:51s\n",
            "epoch 4  | loss: 10685784757.1408|  0:01:23s\n",
            "epoch 4  | loss: 18467266563.69676|  0:01:24s\n",
            "epoch 4  | loss: 16560258873.29965|  0:01:27s\n",
            "epoch 95 | loss: 11087938346.28158|  0:24:01s\n",
            "epoch 11 | loss: 14503070307.35018|  0:03:33s\n",
            "epoch 6  | loss: 13257778910.26716|  0:02:26s\n",
            "epoch 15 | loss: 12635695875.69676|  0:04:46s\n",
            "epoch 94 | loss: 11871464213.48736|  0:24:04s\n",
            "epoch 5  | loss: 6085974184.66426|  0:01:48s\n",
            "epoch 12 | loss: 5098805073.32852|  0:03:52s\n",
            "epoch 93 | loss: 4793131864.72202|  0:24:06s\n",
            "epoch 4  | loss: 20854254989.40072|  0:01:24s\n",
            "epoch 5  | loss: 9706120959.07581|  0:01:38s\n",
            "epoch 5  | loss: 17453551473.67509|  0:01:40s\n",
            "epoch 5  | loss: 15778022094.09384|  0:01:44s\n",
            "epoch 96 | loss: 11119971072.23104|  0:24:16s\n",
            "epoch 12 | loss: 14371627552.80866|  0:03:49s\n",
            "epoch 16 | loss: 12745061886.15164|  0:05:02s\n",
            "epoch 95 | loss: 12251067382.29603|  0:24:19s\n",
            "epoch 13 | loss: 4867941457.32852|  0:04:07s\n",
            "epoch 7  | loss: 12968011257.53069|  0:02:43s\n",
            "epoch 6  | loss: 5568514685.22744|  0:02:05s\n",
            "epoch 94 | loss: 4816113227.3213|  0:24:22s\n",
            "epoch 5  | loss: 19921439232.00001|  0:01:42s\n",
            "epoch 6  | loss: 8696255716.27436|  0:01:54s\n",
            "epoch 6  | loss: 16524057814.41156|  0:01:56s\n",
            "epoch 6  | loss: 15301378117.77617|  0:02:01s\n",
            "epoch 97 | loss: 11170032822.06498|  0:24:30s\n",
            "epoch 13 | loss: 14230821354.28159|  0:04:04s\n",
            "epoch 17 | loss: 12647602121.93502|  0:05:16s\n",
            "epoch 96 | loss: 12063570578.02165|  0:24:34s\n",
            "epoch 14 | loss: 5083697557.25632|  0:04:23s\n",
            "epoch 95 | loss: 4793223593.12635|  0:24:37s\n",
            "epoch 7  | loss: 5287104498.13718|  0:02:21s\n",
            "epoch 8  | loss: 12832191839.65342|  0:03:01s\n",
            "epoch 6  | loss: 18887427044.27438|  0:01:59s\n",
            "epoch 7  | loss: 7840228345.53069|  0:02:10s\n",
            "epoch 7  | loss: 15691693122.54152|  0:02:13s\n",
            "epoch 98 | loss: 11203779692.12996|  0:24:45s\n",
            "epoch 7  | loss: 14943681199.13357|  0:02:18s\n",
            "epoch 18 | loss: 12718553948.41877|  0:05:31s\n",
            "epoch 14 | loss: 14260303629.40072|  0:04:20s\n",
            "epoch 97 | loss: 11839198036.56318|  0:24:49s\n",
            "epoch 15 | loss: 4984307847.3935|  0:04:38s\n",
            "epoch 96 | loss: 4805656007.16245|  0:24:53s\n",
            "epoch 8  | loss: 5093979521.38628|  0:02:39s\n",
            "epoch 9  | loss: 12772960383.99999|  0:03:19s\n",
            "epoch 8  | loss: 6922209713.44404|  0:02:26s\n",
            "epoch 7  | loss: 17796918262.75812|  0:02:16s\n",
            "epoch 99 | loss: 11244297727.53791|  0:25:01s\n",
            "epoch 8  | loss: 15002610236.99638|  0:02:30s\n",
            "epoch 19 | loss: 12663811674.1083|  0:05:46s\n",
            "epoch 8  | loss: 14643870380.36101|  0:02:36s\n",
            "epoch 15 | loss: 14212837101.51624|  0:04:35s\n",
            "epoch 98 | loss: 12166833309.11192|  0:25:05s\n",
            "epoch 16 | loss: 4908030067.52346|  0:04:55s\n",
            "epoch 97 | loss: 4809513160.08664|  0:25:09s\n",
            "epoch 9  | loss: 5009019375.82671|  0:02:56s\n",
            "epoch 9  | loss: 6211833379.58123|  0:02:42s\n",
            "epoch 10 | loss: 12679420916.90974|  0:03:37s\n",
            "epoch 8  | loss: 16786402852.9675|  0:02:34s\n",
            "epoch 9  | loss: 14387914546.83034|  0:02:48s\n",
            "epoch 20 | loss: 12570393963.20577|  0:06:02s\n",
            "epoch 99 | loss: 11762934674.94585|  0:25:21s\n",
            "epoch 16 | loss: 14149448310.29602|  0:04:52s\n",
            "epoch 9  | loss: 14462317495.91335|  0:02:54s\n",
            "epoch 17 | loss: 4882919930.45488|  0:05:13s\n",
            "epoch 98 | loss: 4820086795.09025|  0:25:26s\n",
            "epoch 10 | loss: 5691857344.69314|  0:03:03s\n",
            "epoch 10 | loss: 4940225314.19495|  0:03:18s\n",
            "epoch 9  | loss: 15927743677.45848|  0:02:56s\n",
            "epoch 11 | loss: 12648558166.41156|  0:04:02s\n",
            "epoch 21 | loss: 12498531293.80505|  0:06:25s\n",
            "epoch 10 | loss: 13891263298.54153|  0:03:13s\n",
            "epoch 17 | loss: 14137227991.79784|  0:05:15s\n",
            "[CV] END ......................................n_a=8, n_d=32; total time=25.8min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 99 | loss: 4791219352.02888|  0:25:46s\n",
            "epoch 10 | loss: 14356831697.79061|  0:03:19s\n",
            "epoch 18 | loss: 4892343074.65704|  0:05:35s\n",
            "epoch 11 | loss: 5225360332.70758|  0:03:26s\n",
            "epoch 11 | loss: 4877133448.31769|  0:03:42s\n",
            "epoch 10 | loss: 15303058110.84477|  0:03:19s\n",
            "epoch 22 | loss: 12418492910.90253|  0:06:46s\n",
            "epoch 12 | loss: 12692005014.6426|  0:04:28s\n",
            "epoch 18 | loss: 14091799865.76173|  0:05:37s\n",
            "epoch 11 | loss: 13475838185.35738|  0:03:36s\n",
            "[CV] END ......................................n_a=8, n_d=32; total time=26.2min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 19 | loss: 4817460973.51624|  0:05:57s\n",
            "epoch 11 | loss: 14281510695.27796|  0:03:42s\n",
            "epoch 0  | loss: 22499835674.80144|  0:00:27s\n",
            "epoch 12 | loss: 4994841813.94946|  0:03:48s\n",
            "epoch 12 | loss: 4765708656.2888|  0:04:04s\n",
            "epoch 23 | loss: 12405738908.18773|  0:07:05s\n",
            "epoch 11 | loss: 14862215805.22744|  0:03:41s\n",
            "epoch 19 | loss: 14088621021.80506|  0:05:57s\n",
            "epoch 13 | loss: 12581356479.30686|  0:04:51s\n",
            "epoch 12 | loss: 13170535234.07942|  0:03:58s\n",
            "epoch 20 | loss: 4774974569.8195|  0:06:17s\n",
            "epoch 12 | loss: 14342244423.62456|  0:04:04s\n",
            "epoch 0  | loss: 14712623159.45126|  0:00:23s\n",
            "[CV] END ......................................n_a=8, n_d=32; total time=26.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1  | loss: 21409401377.27076|  0:00:49s\n",
            "epoch 13 | loss: 4814743996.0722|  0:04:06s\n",
            "epoch 24 | loss: 12373786395.72563|  0:07:21s\n",
            "epoch 13 | loss: 4734441132.8231|  0:04:23s\n",
            "epoch 12 | loss: 14461103829.94947|  0:03:59s\n",
            "epoch 20 | loss: 14046484574.72924|  0:06:13s\n",
            "epoch 21 | loss: 4732178748.0722|  0:06:32s\n",
            "epoch 13 | loss: 12900564112.63537|  0:04:14s\n",
            "epoch 14 | loss: 12493874997.14079|  0:05:09s\n",
            "epoch 13 | loss: 14298746141.574|  0:04:21s\n",
            "epoch 1  | loss: 13679694293.48736|  0:00:42s\n",
            "epoch 0  | loss: 24269590823.74008|  0:00:18s\n",
            "epoch 14 | loss: 4668441721.53069|  0:04:21s\n",
            "epoch 25 | loss: 12414967283.98556|  0:07:36s\n",
            "epoch 2  | loss: 19853471997.22742|  0:01:08s\n",
            "epoch 14 | loss: 4697951042.07942|  0:04:39s\n",
            "epoch 13 | loss: 14283536813.2852|  0:04:15s\n",
            "epoch 21 | loss: 13997714648.25993|  0:06:28s\n",
            "epoch 22 | loss: 4703513782.52707|  0:06:48s\n",
            "epoch 14 | loss: 12727800931.35017|  0:04:31s\n",
            "epoch 15 | loss: 12432914110.38268|  0:05:26s\n",
            "epoch 14 | loss: 14236848740.73646|  0:04:38s\n",
            "epoch 26 | loss: 12411293511.16246|  0:07:51s\n",
            "epoch 15 | loss: 4565661111.45126|  0:04:37s\n",
            "epoch 2  | loss: 11996278070.52708|  0:01:01s\n",
            "epoch 1  | loss: 23224746573.63176|  0:00:38s\n",
            "epoch 22 | loss: 13977803026.94585|  0:06:43s\n",
            "epoch 15 | loss: 4575931365.66065|  0:04:56s\n",
            "epoch 14 | loss: 14206333577.70397|  0:04:31s\n",
            "epoch 3  | loss: 18382320246.29603|  0:01:28s\n",
            "epoch 23 | loss: 4654714694.70036|  0:07:03s\n",
            "epoch 15 | loss: 12600625767.50902|  0:04:47s\n",
            "epoch 16 | loss: 12426531085.40072|  0:05:44s\n",
            "epoch 27 | loss: 12310422150.46932|  0:08:05s\n",
            "epoch 15 | loss: 14218981581.63176|  0:04:55s\n",
            "epoch 16 | loss: 4606512270.787|  0:04:54s\n",
            "epoch 23 | loss: 13966988077.74729|  0:06:59s\n",
            "epoch 3  | loss: 10472413429.83393|  0:01:20s\n",
            "epoch 16 | loss: 4664349033.81949|  0:05:13s\n",
            "epoch 15 | loss: 14057779331.23466|  0:04:48s\n",
            "epoch 2  | loss: 21841727177.47292|  0:00:57s\n",
            "epoch 24 | loss: 4611040316.0722|  0:07:19s\n",
            "epoch 4  | loss: 17030176426.05054|  0:01:47s\n",
            "epoch 16 | loss: 12521486092.01444|  0:05:03s\n",
            "epoch 28 | loss: 12306742028.93863|  0:08:20s\n",
            "epoch 17 | loss: 12346880786.48376|  0:06:02s\n",
            "epoch 16 | loss: 14154219725.63176|  0:05:12s\n",
            "epoch 17 | loss: 4514514805.83394|  0:05:10s\n",
            "epoch 24 | loss: 14117888769.38628|  0:07:14s\n",
            "epoch 17 | loss: 4529403398.00722|  0:05:30s\n",
            "epoch 16 | loss: 14012739729.55956|  0:05:04s\n",
            "epoch 25 | loss: 4545463776.11552|  0:07:35s\n",
            "epoch 4  | loss: 9156453642.16607|  0:01:38s\n",
            "epoch 3  | loss: 20464529056.80866|  0:01:16s\n",
            "epoch 17 | loss: 12462424901.77617|  0:05:20s\n",
            "epoch 29 | loss: 12246376892.5343|  0:08:35s\n",
            "epoch 5  | loss: 15850439689.24188|  0:02:06s\n",
            "epoch 18 | loss: 12273986571.09025|  0:06:19s\n",
            "epoch 18 | loss: 4484347207.62455|  0:05:26s\n",
            "epoch 17 | loss: 13929953146.91697|  0:05:30s\n",
            "epoch 25 | loss: 14128988502.41156|  0:07:30s\n",
            "epoch 18 | loss: 4470884559.94224|  0:05:46s\n",
            "epoch 17 | loss: 13969937863.16246|  0:05:21s\n",
            "epoch 26 | loss: 4500058687.30686|  0:07:51s\n",
            "epoch 18 | loss: 12443303430.93141|  0:05:36s\n",
            "epoch 5  | loss: 8119619597.86282|  0:01:58s\n",
            "epoch 30 | loss: 12245711778.19495|  0:08:50s\n",
            "epoch 4  | loss: 19251863548.30324|  0:01:35s\n",
            "epoch 6  | loss: 14844515455.53793|  0:02:24s\n",
            "epoch 19 | loss: 4570736859.49459|  0:05:42s\n",
            "epoch 19 | loss: 12203541832.08664|  0:06:37s\n",
            "epoch 26 | loss: 14078057868.47654|  0:07:45s\n",
            "epoch 18 | loss: 13934205167.82672|  0:05:47s\n",
            "epoch 27 | loss: 4626497309.11191|  0:08:06s\n",
            "epoch 18 | loss: 14058095650.65704|  0:05:37s\n",
            "epoch 19 | loss: 4477531103.65343|  0:06:03s\n",
            "epoch 31 | loss: 12140757384.77978|  0:09:05s\n",
            "epoch 19 | loss: 12418854314.51264|  0:05:52s\n",
            "epoch 6  | loss: 7180563104.80867|  0:02:16s\n",
            "epoch 5  | loss: 18294569416.54875|  0:01:54s\n",
            "epoch 20 | loss: 4562576694.98917|  0:05:58s\n",
            "epoch 7  | loss: 14076767383.56679|  0:02:43s\n",
            "epoch 27 | loss: 13932142061.97834|  0:08:01s\n",
            "epoch 20 | loss: 12164612683.3213|  0:06:55s\n",
            "epoch 19 | loss: 13855647522.19495|  0:06:04s\n",
            "epoch 28 | loss: 4524803629.74729|  0:08:21s\n",
            "epoch 19 | loss: 13894918405.08304|  0:05:54s\n",
            "epoch 20 | loss: 4541186541.05415|  0:06:19s\n",
            "epoch 32 | loss: 12021102645.1408|  0:09:20s\n",
            "epoch 20 | loss: 12327290373.08303|  0:06:09s\n",
            "epoch 7  | loss: 6388967513.64621|  0:02:35s\n",
            "epoch 28 | loss: 13944935504.86643|  0:08:16s\n",
            "epoch 21 | loss: 4484169585.67509|  0:06:15s\n",
            "epoch 6  | loss: 17491452366.09386|  0:02:14s\n",
            "epoch 8  | loss: 13535375313.32851|  0:03:01s\n",
            "epoch 21 | loss: 12111076160.23105|  0:07:12s\n",
            "epoch 29 | loss: 4499726177.03971|  0:08:37s\n",
            "epoch 20 | loss: 13907716922.68592|  0:06:21s\n",
            "epoch 20 | loss: 14039402146.65704|  0:06:10s\n",
            "epoch 33 | loss: 11970770961.09746|  0:09:35s\n",
            "epoch 21 | loss: 4412900706.42599|  0:06:36s\n",
            "epoch 21 | loss: 12344881825.27076|  0:06:25s\n",
            "epoch 29 | loss: 13768063440.40434|  0:08:31s\n",
            "epoch 22 | loss: 4450653500.53429|  0:06:31s\n",
            "epoch 8  | loss: 5953058747.14801|  0:02:54s\n",
            "epoch 30 | loss: 4425215865.53069|  0:08:53s\n",
            "epoch 22 | loss: 12114628033.61732|  0:07:30s\n",
            "epoch 7  | loss: 16547628678.9314|  0:02:34s\n",
            "epoch 21 | loss: 13829855817.01083|  0:06:39s\n",
            "epoch 34 | loss: 11959232839.16245|  0:09:50s\n",
            "epoch 9  | loss: 13156297744.17329|  0:03:20s\n",
            "epoch 21 | loss: 14030017997.16968|  0:06:26s\n",
            "epoch 22 | loss: 4313184712.08664|  0:06:53s\n",
            "epoch 22 | loss: 12245166567.50902|  0:06:41s\n",
            "epoch 30 | loss: 13757329499.9567|  0:08:47s\n",
            "epoch 23 | loss: 4382167835.72563|  0:06:47s\n",
            "epoch 31 | loss: 4334183349.14079|  0:09:09s\n",
            "epoch 9  | loss: 5411293972.33213|  0:03:13s\n",
            "epoch 35 | loss: 11887950359.56679|  0:10:05s\n",
            "epoch 22 | loss: 13964744340.79422|  0:06:42s\n",
            "epoch 23 | loss: 12049232887.68231|  0:07:48s\n",
            "epoch 22 | loss: 13710275709.68953|  0:06:57s\n",
            "epoch 23 | loss: 4209121533.45848|  0:07:10s\n",
            "epoch 10 | loss: 12845301400.02888|  0:03:39s\n",
            "epoch 8  | loss: 15863369391.59568|  0:02:53s\n",
            "epoch 23 | loss: 12234930556.30324|  0:06:58s\n",
            "epoch 31 | loss: 13725683776.23105|  0:09:02s\n",
            "epoch 24 | loss: 4413774994.94585|  0:07:03s\n",
            "epoch 32 | loss: 4348476799.53791|  0:09:25s\n",
            "epoch 36 | loss: 11728489314.42598|  0:10:20s\n",
            "epoch 23 | loss: 13917676686.787|  0:06:58s\n",
            "epoch 10 | loss: 5070928067.4657|  0:03:31s\n",
            "epoch 23 | loss: 13598648657.32852|  0:07:14s\n",
            "epoch 24 | loss: 12077484294.46932|  0:08:06s\n",
            "epoch 24 | loss: 4196473269.60288|  0:07:27s\n",
            "epoch 11 | loss: 12735227644.30326|  0:03:58s\n",
            "epoch 24 | loss: 12290702622.96029|  0:07:14s\n",
            "epoch 9  | loss: 15375764034.07942|  0:03:13s\n",
            "epoch 32 | loss: 13679708218.68592|  0:09:17s\n",
            "epoch 25 | loss: 4301201746.25271|  0:07:19s\n",
            "epoch 37 | loss: 11788613361.67509|  0:10:35s\n",
            "epoch 33 | loss: 4356538448.40433|  0:09:40s\n",
            "epoch 24 | loss: 13901147012.62094|  0:07:15s\n",
            "epoch 11 | loss: 4874923477.94946|  0:03:51s\n",
            "epoch 24 | loss: 13538603503.82672|  0:07:32s\n",
            "epoch 25 | loss: 12162289874.7148|  0:08:25s\n",
            "epoch 25 | loss: 4126786567.3935|  0:07:45s\n",
            "epoch 25 | loss: 12329929782.06498|  0:07:32s\n",
            "epoch 33 | loss: 13606627092.33213|  0:09:35s\n",
            "epoch 12 | loss: 12598619535.71119|  0:04:20s\n",
            "epoch 10 | loss: 14888930686.61372|  0:03:36s\n",
            "epoch 26 | loss: 4274813311.5379|  0:07:40s\n",
            "epoch 38 | loss: 12095325189.77617|  0:10:54s\n",
            "epoch 34 | loss: 4330293956.38989|  0:10:00s\n",
            "epoch 25 | loss: 13886431204.27438|  0:07:36s\n",
            "epoch 25 | loss: 13515573992.89531|  0:07:55s\n",
            "epoch 26 | loss: 4052646374.12275|  0:08:07s\n",
            "epoch 34 | loss: 13567194916.96751|  0:09:54s\n",
            "epoch 12 | loss: 4791060365.40073|  0:04:15s\n",
            "epoch 26 | loss: 12153513703.97111|  0:07:53s\n",
            "epoch 26 | loss: 12073554434.77256|  0:08:48s\n",
            "epoch 27 | loss: 4242764487.16245|  0:07:59s\n",
            "epoch 39 | loss: 11901774236.64982|  0:11:13s\n",
            "epoch 13 | loss: 12532436121.87726|  0:04:43s\n",
            "epoch 35 | loss: 4353954029.05415|  0:10:19s\n",
            "epoch 11 | loss: 14548932929.15523|  0:04:00s\n",
            "epoch 26 | loss: 13976372070.58484|  0:07:56s\n",
            "epoch 35 | loss: 13557821745.90613|  0:10:12s\n",
            "epoch 27 | loss: 4126897384.20217|  0:08:26s\n",
            "epoch 26 | loss: 13372548954.5704|  0:08:15s\n",
            "epoch 27 | loss: 12162170922.97473|  0:08:13s\n",
            "epoch 27 | loss: 11973122093.74729|  0:09:09s\n",
            "epoch 13 | loss: 4708049537.38628|  0:04:37s\n",
            "epoch 40 | loss: 11827071504.86642|  0:11:30s\n",
            "epoch 28 | loss: 4245875721.70397|  0:08:17s\n",
            "epoch 36 | loss: 4359233895.97112|  0:10:37s\n",
            "epoch 14 | loss: 12441735772.88087|  0:05:05s\n",
            "epoch 12 | loss: 14345136193.61735|  0:04:22s\n",
            "epoch 27 | loss: 13893839150.67148|  0:08:14s\n",
            "epoch 36 | loss: 13665482041.99278|  0:10:30s\n",
            "epoch 28 | loss: 3967995454.84477|  0:08:45s\n",
            "epoch 28 | loss: 12154918960.98195|  0:08:32s\n",
            "epoch 27 | loss: 13330881185.9639|  0:08:35s\n",
            "epoch 41 | loss: 11802068181.02527|  0:11:48s\n",
            "epoch 28 | loss: 11919784312.6065|  0:09:29s\n",
            "epoch 29 | loss: 4214846488.95307|  0:08:35s\n",
            "epoch 37 | loss: 4169161069.05415|  0:10:55s\n",
            "epoch 14 | loss: 4589801152.23105|  0:04:58s\n",
            "epoch 15 | loss: 12535879728.98197|  0:05:26s\n",
            "epoch 28 | loss: 13905651819.66786|  0:08:33s\n",
            "epoch 37 | loss: 13484778336.11552|  0:10:48s\n",
            "epoch 13 | loss: 14252390368.57762|  0:04:44s\n",
            "epoch 29 | loss: 4052359739.37906|  0:09:04s\n",
            "epoch 29 | loss: 12041378791.04693|  0:08:51s\n",
            "epoch 42 | loss: 11979278431.19134|  0:12:05s\n",
            "epoch 28 | loss: 13317043659.3213|  0:08:55s\n",
            "epoch 30 | loss: 4143344492.59206|  0:08:54s\n",
            "epoch 38 | loss: 4043269566.38267|  0:11:13s\n",
            "epoch 29 | loss: 11858006879.42238|  0:09:50s\n",
            "epoch 15 | loss: 4599133297.67509|  0:05:19s\n",
            "epoch 38 | loss: 13481228203.89892|  0:11:06s\n",
            "epoch 29 | loss: 13925516265.3574|  0:08:53s\n",
            "epoch 16 | loss: 12475049751.56678|  0:05:48s\n",
            "epoch 30 | loss: 3851837501.45848|  0:09:23s\n",
            "epoch 30 | loss: 12160944928.34656|  0:09:09s\n",
            "epoch 14 | loss: 14149982553.18412|  0:05:07s\n",
            "epoch 43 | loss: 11888322875.61011|  0:12:23s\n",
            "epoch 29 | loss: 13184463724.12997|  0:09:15s\n",
            "epoch 39 | loss: 3988105772.82311|  0:11:31s\n",
            "epoch 31 | loss: 4143623758.09386|  0:09:13s\n",
            "epoch 30 | loss: 11815896964.62094|  0:10:11s\n",
            "epoch 16 | loss: 4543116140.12996|  0:05:42s\n",
            "epoch 39 | loss: 13446889109.71842|  0:11:24s\n",
            "epoch 30 | loss: 13696151850.97474|  0:09:12s\n",
            "epoch 17 | loss: 12461247200.11553|  0:06:11s\n",
            "epoch 44 | loss: 11768588946.94585|  0:12:41s\n",
            "epoch 31 | loss: 3788815901.80506|  0:09:43s\n",
            "epoch 31 | loss: 12112984108.36101|  0:09:29s\n",
            "epoch 40 | loss: 4006094581.83394|  0:11:49s\n",
            "epoch 32 | loss: 4185490996.90975|  0:09:31s\n",
            "epoch 15 | loss: 14048239094.29602|  0:05:29s\n",
            "epoch 30 | loss: 13251785470.61372|  0:09:36s\n",
            "epoch 31 | loss: 11772036096.0|  0:10:32s\n",
            "epoch 40 | loss: 13296781798.58484|  0:11:42s\n",
            "epoch 31 | loss: 13698918403.69676|  0:09:30s\n",
            "epoch 17 | loss: 4497232460.24549|  0:06:04s\n",
            "epoch 45 | loss: 11749972856.1444|  0:13:00s\n",
            "epoch 32 | loss: 12070340277.60289|  0:09:48s\n",
            "epoch 32 | loss: 4010851725.40072|  0:10:03s\n",
            "epoch 18 | loss: 12509298564.15884|  0:06:33s\n",
            "epoch 41 | loss: 4051218688.00001|  0:12:08s\n",
            "epoch 33 | loss: 4067473635.35018|  0:09:50s\n",
            "epoch 31 | loss: 13210867262.84477|  0:09:56s\n",
            "epoch 16 | loss: 14111879661.05416|  0:05:52s\n",
            "epoch 41 | loss: 13327549554.13718|  0:12:00s\n",
            "epoch 32 | loss: 11808253026.88809|  0:10:52s\n",
            "epoch 32 | loss: 13624737631.19133|  0:09:50s\n",
            "epoch 46 | loss: 11816252355.00361|  0:13:17s\n",
            "epoch 18 | loss: 4592584918.87365|  0:06:26s\n",
            "epoch 33 | loss: 12090207848.89531|  0:10:07s\n",
            "epoch 33 | loss: 3688793452.59206|  0:10:22s\n",
            "epoch 42 | loss: 4109620239.71119|  0:12:26s\n",
            "epoch 34 | loss: 4058215042.77256|  0:10:09s\n",
            "epoch 19 | loss: 12513529852.76534|  0:06:55s\n",
            "epoch 32 | loss: 13128091460.38989|  0:10:16s\n",
            "epoch 42 | loss: 13459116738.07941|  0:12:18s\n",
            "epoch 17 | loss: 14060884478.15162|  0:06:15s\n",
            "epoch 33 | loss: 11755198896.28881|  0:11:13s\n",
            "epoch 33 | loss: 13547768619.89892|  0:10:09s\n",
            "epoch 47 | loss: 11663011480.95307|  0:13:35s\n",
            "epoch 34 | loss: 11984734421.48736|  0:10:26s\n",
            "epoch 43 | loss: 3944476178.48375|  0:12:45s\n",
            "epoch 34 | loss: 3779407700.10108|  0:10:41s\n",
            "epoch 19 | loss: 4547746352.05776|  0:06:49s\n",
            "epoch 35 | loss: 4029369942.87365|  0:10:28s\n",
            "epoch 20 | loss: 12694187904.4621|  0:07:17s\n",
            "epoch 33 | loss: 13166332929.84838|  0:10:36s\n",
            "epoch 43 | loss: 13219330137.18412|  0:12:36s\n",
            "epoch 48 | loss: 11629977793.38628|  0:13:52s\n",
            "epoch 34 | loss: 13538342459.61011|  0:10:28s\n",
            "epoch 34 | loss: 11657307280.63538|  0:11:34s\n",
            "epoch 18 | loss: 14194845377.15524|  0:06:38s\n",
            "epoch 44 | loss: 3981747338.62816|  0:13:03s\n",
            "epoch 35 | loss: 11908696689.6751|  0:10:45s\n",
            "epoch 35 | loss: 3587262125.97834|  0:11:01s\n",
            "epoch 36 | loss: 3990516666.22383|  0:10:47s\n",
            "epoch 20 | loss: 4492557793.9639|  0:07:11s\n",
            "epoch 44 | loss: 13287865955.81228|  0:12:54s\n",
            "epoch 34 | loss: 13044238368.80867|  0:10:56s\n",
            "epoch 21 | loss: 12624817223.62455|  0:07:40s\n",
            "epoch 49 | loss: 11616174551.33574|  0:14:10s\n",
            "epoch 35 | loss: 13463886525.92058|  0:10:48s\n",
            "epoch 35 | loss: 11663781700.38988|  0:11:55s\n",
            "epoch 19 | loss: 14202271462.58484|  0:07:01s\n",
            "epoch 45 | loss: 4006258394.5704|  0:13:22s\n",
            "epoch 36 | loss: 11957420845.74729|  0:11:05s\n",
            "epoch 37 | loss: 3952224416.80867|  0:11:05s\n",
            "epoch 36 | loss: 3495174278.93141|  0:11:20s\n",
            "epoch 45 | loss: 13126440933.66065|  0:13:12s\n",
            "epoch 21 | loss: 4472368622.44043|  0:07:33s\n",
            "epoch 35 | loss: 12879054019.4657|  0:11:17s\n",
            "epoch 50 | loss: 11498774962.83033|  0:14:29s\n",
            "epoch 36 | loss: 13361948330.97474|  0:11:07s\n",
            "epoch 22 | loss: 12382184211.87004|  0:08:03s\n",
            "epoch 36 | loss: 11616174920.08664|  0:12:15s\n",
            "epoch 46 | loss: 3916819783.62455|  0:13:41s\n",
            "epoch 37 | loss: 11807387413.48736|  0:11:24s\n",
            "epoch 38 | loss: 3901996302.32491|  0:11:24s\n",
            "epoch 37 | loss: 3568470303.42238|  0:11:40s\n",
            "epoch 20 | loss: 14055675496.43321|  0:07:24s\n",
            "epoch 46 | loss: 13418601338.91697|  0:13:31s\n",
            "epoch 51 | loss: 11523626452.56318|  0:14:47s\n",
            "epoch 22 | loss: 4407760951.45126|  0:07:55s\n",
            "epoch 36 | loss: 12873646927.2491|  0:11:38s\n",
            "epoch 37 | loss: 13330634721.9639|  0:11:26s\n",
            "epoch 47 | loss: 3855558731.3213|  0:13:59s\n",
            "epoch 23 | loss: 12371177511.27797|  0:08:26s\n",
            "epoch 39 | loss: 3976298827.55235|  0:11:43s\n",
            "epoch 37 | loss: 11621555282.25271|  0:12:37s\n",
            "epoch 38 | loss: 11799957203.63899|  0:11:43s\n",
            "epoch 38 | loss: 3399429504.92419|  0:12:00s\n",
            "epoch 47 | loss: 13558204263.04693|  0:13:49s\n",
            "epoch 21 | loss: 13930900560.86643|  0:07:48s\n",
            "epoch 52 | loss: 11579242043.14802|  0:15:04s\n",
            "epoch 37 | loss: 12760095931.14802|  0:11:58s\n",
            "epoch 23 | loss: 4388605555.52347|  0:08:17s\n",
            "epoch 38 | loss: 13312246242.42599|  0:11:45s\n",
            "epoch 48 | loss: 3815502592.0|  0:14:17s\n",
            "epoch 40 | loss: 3938521917.22744|  0:12:01s\n",
            "epoch 39 | loss: 11754040304.28881|  0:12:02s\n",
            "epoch 24 | loss: 12231148111.48015|  0:08:47s\n",
            "epoch 38 | loss: 11519501716.33212|  0:12:58s\n",
            "epoch 39 | loss: 3435667260.0722|  0:12:19s\n",
            "epoch 48 | loss: 13441097838.44043|  0:14:06s\n",
            "epoch 53 | loss: 11562392661.94946|  0:15:21s\n",
            "epoch 22 | loss: 13837995746.42599|  0:08:10s\n",
            "epoch 39 | loss: 13328259053.05414|  0:12:03s\n",
            "epoch 38 | loss: 12970045222.81588|  0:12:18s\n",
            "epoch 49 | loss: 3829607538.13718|  0:14:35s\n",
            "epoch 24 | loss: 4350752167.74007|  0:08:38s\n",
            "epoch 41 | loss: 3899277368.1444|  0:12:20s\n",
            "epoch 40 | loss: 11711594169.76174|  0:12:20s\n",
            "epoch 49 | loss: 13280681667.9278|  0:14:24s\n",
            "epoch 40 | loss: 3495593543.62454|  0:12:37s\n",
            "epoch 39 | loss: 11500555739.03249|  0:13:18s\n",
            "epoch 54 | loss: 11476140668.30325|  0:15:39s\n",
            "epoch 25 | loss: 12237384917.02527|  0:09:09s\n",
            "epoch 40 | loss: 13199951588.73647|  0:12:22s\n",
            "epoch 23 | loss: 13808657903.36462|  0:08:31s\n",
            "epoch 50 | loss: 3838644867.23466|  0:14:53s\n",
            "epoch 39 | loss: 13096765566.15162|  0:12:37s\n",
            "epoch 42 | loss: 3856593446.35379|  0:12:38s\n",
            "epoch 25 | loss: 4416730834.7148|  0:09:00s\n",
            "epoch 41 | loss: 11659515771.37906|  0:12:39s\n",
            "epoch 50 | loss: 13298310498.42599|  0:14:41s\n",
            "epoch 41 | loss: 3326595626.97473|  0:12:57s\n",
            "epoch 55 | loss: 11397453351.27798|  0:15:56s\n",
            "epoch 40 | loss: 11665630771.98556|  0:13:39s\n",
            "epoch 26 | loss: 12216967832.95308|  0:09:31s\n",
            "epoch 41 | loss: 13134499276.93863|  0:12:40s\n",
            "epoch 51 | loss: 3913911646.72924|  0:15:10s\n",
            "epoch 40 | loss: 12951554180.15884|  0:12:57s\n",
            "epoch 24 | loss: 13857637478.58484|  0:08:54s\n",
            "epoch 43 | loss: 3810934159.71119|  0:12:56s\n",
            "epoch 51 | loss: 13176743264.11552|  0:14:59s\n",
            "epoch 42 | loss: 11764319422.61372|  0:12:57s\n",
            "epoch 56 | loss: 11349909006.09386|  0:16:13s\n",
            "epoch 26 | loss: 4234593596.5343|  0:09:22s\n",
            "epoch 42 | loss: 3314920346.33935|  0:13:16s\n",
            "epoch 41 | loss: 11787896955.84115|  0:13:59s\n",
            "epoch 27 | loss: 12460205580.01444|  0:09:52s\n",
            "epoch 52 | loss: 3884940544.0|  0:15:28s\n",
            "epoch 42 | loss: 13117591905.5018|  0:12:59s\n",
            "epoch 41 | loss: 12799525223.50903|  0:13:17s\n",
            "epoch 44 | loss: 3796342398.61372|  0:13:14s\n",
            "epoch 52 | loss: 12907897527.91336|  0:15:17s\n",
            "epoch 43 | loss: 11637707810.88809|  0:13:16s\n",
            "epoch 57 | loss: 11458680835.23465|  0:16:30s\n",
            "epoch 25 | loss: 13758235254.75812|  0:09:15s\n",
            "epoch 43 | loss: 3304087650.65704|  0:13:34s\n",
            "epoch 27 | loss: 4212031828.10108|  0:09:43s\n",
            "epoch 42 | loss: 11468035529.01083|  0:14:19s\n",
            "epoch 53 | loss: 3862666302.38267|  0:15:46s\n",
            "epoch 43 | loss: 13100248520.54874|  0:13:17s\n",
            "epoch 28 | loss: 12196260008.20217|  0:10:13s\n",
            "epoch 45 | loss: 3677641552.63538|  0:13:32s\n",
            "epoch 53 | loss: 11900703328.57762|  0:15:34s\n",
            "epoch 42 | loss: 12863292392.43321|  0:13:36s\n",
            "epoch 58 | loss: 11470811890.13718|  0:16:48s\n",
            "epoch 44 | loss: 11573648351.19134|  0:13:35s\n",
            "epoch 44 | loss: 3430978219.43682|  0:13:53s\n",
            "epoch 26 | loss: 13685347918.09386|  0:09:37s\n",
            "epoch 28 | loss: 4178084573.34296|  0:10:04s\n",
            "epoch 54 | loss: 3703680192.23105|  0:16:04s\n",
            "epoch 43 | loss: 11438104113.44404|  0:14:40s\n",
            "epoch 44 | loss: 13125399780.73646|  0:13:36s\n",
            "epoch 54 | loss: 13044954784.34657|  0:15:52s\n",
            "epoch 46 | loss: 3666475789.40072|  0:13:50s\n",
            "epoch 29 | loss: 12107611115.66786|  0:10:35s\n",
            "epoch 59 | loss: 11456822391.68231|  0:17:05s\n",
            "epoch 45 | loss: 11564592755.98556|  0:13:53s\n",
            "epoch 43 | loss: 12827559951.48015|  0:13:56s\n",
            "epoch 45 | loss: 3507062723.00361|  0:14:12s\n",
            "epoch 27 | loss: 13654747233.03971|  0:09:59s\n",
            "epoch 55 | loss: 3612049346.07942|  0:16:21s\n",
            "epoch 29 | loss: 4050155831.22022|  0:10:26s\n",
            "epoch 45 | loss: 13076126006.06498|  0:13:54s\n",
            "epoch 44 | loss: 11338662104.95307|  0:15:00s\n",
            "epoch 55 | loss: 13006434703.71119|  0:16:09s\n",
            "epoch 60 | loss: 11398372971.66787|  0:17:22s\n",
            "epoch 47 | loss: 3785885290.28159|  0:14:09s\n",
            "epoch 46 | loss: 11570027218.48376|  0:14:12s\n",
            "epoch 30 | loss: 12039697167.2491|  0:10:57s\n",
            "epoch 44 | loss: 12820121586.59928|  0:14:15s\n",
            "epoch 46 | loss: 3240987024.63538|  0:14:31s\n",
            "epoch 56 | loss: 3784070364.88087|  0:16:39s\n",
            "epoch 28 | loss: 13689194480.2888|  0:10:21s\n",
            "epoch 56 | loss: 12957010168.14441|  0:16:26s\n",
            "epoch 46 | loss: 12966341783.10469|  0:14:13s\n",
            "epoch 30 | loss: 4082524630.41155|  0:10:47s\n",
            "epoch 61 | loss: 11629619278.55596|  0:17:39s\n",
            "epoch 45 | loss: 11512644784.7509|  0:15:20s\n",
            "epoch 48 | loss: 3742138977.73285|  0:14:27s\n",
            "epoch 47 | loss: 11552782385.6751|  0:14:30s\n",
            "epoch 45 | loss: 12791403740.88087|  0:14:35s\n",
            "epoch 31 | loss: 12088965538.19495|  0:11:19s\n",
            "epoch 47 | loss: 3136863835.95668|  0:14:50s\n",
            "epoch 57 | loss: 3644283490.88809|  0:16:57s\n",
            "epoch 57 | loss: 12915861278.4982|  0:16:44s\n",
            "epoch 62 | loss: 11682051315.98556|  0:17:56s\n",
            "epoch 47 | loss: 13102827995.49458|  0:14:31s\n",
            "epoch 49 | loss: 3657074847.42238|  0:14:44s\n",
            "epoch 29 | loss: 13570406101.94945|  0:10:43s\n",
            "epoch 31 | loss: 4055136021.71841|  0:11:08s\n",
            "epoch 46 | loss: 11467102753.9639|  0:15:41s\n",
            "epoch 48 | loss: 11551787762.13718|  0:14:49s\n",
            "epoch 46 | loss: 12532942968.1444|  0:14:55s\n",
            "epoch 48 | loss: 3113377284.15884|  0:15:09s\n",
            "epoch 32 | loss: 12057479348.6787|  0:11:41s\n",
            "epoch 58 | loss: 3635941875.52347|  0:17:15s\n",
            "epoch 58 | loss: 12896915727.2491|  0:17:01s\n",
            "epoch 63 | loss: 11672793345.38628|  0:18:13s\n",
            "epoch 48 | loss: 13128298180.62094|  0:14:51s\n",
            "epoch 50 | loss: 3566110123.66787|  0:15:03s\n",
            "epoch 30 | loss: 13537584353.03972|  0:11:04s\n",
            "epoch 49 | loss: 11454309364.6787|  0:15:07s\n",
            "epoch 47 | loss: 11310730133.25632|  0:16:02s\n",
            "epoch 32 | loss: 3999033538.54151|  0:11:29s\n",
            "epoch 47 | loss: 12427511605.14079|  0:15:14s\n",
            "epoch 49 | loss: 3050792666.80144|  0:15:28s\n",
            "epoch 59 | loss: 3641990186.97473|  0:17:33s\n",
            "epoch 59 | loss: 4284864622.67148|  0:17:18s\n",
            "epoch 64 | loss: 11496736157.574|  0:18:30s\n",
            "epoch 33 | loss: 12047171596.93863|  0:12:02s\n",
            "epoch 49 | loss: 12962309628.76535|  0:15:10s\n",
            "epoch 51 | loss: 3528472432.28881|  0:15:21s\n",
            "epoch 50 | loss: 11372573954.77257|  0:15:26s\n",
            "epoch 48 | loss: 11241399043.23466|  0:16:22s\n",
            "epoch 33 | loss: 4020593597.45848|  0:11:50s\n",
            "epoch 31 | loss: 13524539959.91336|  0:11:27s\n",
            "epoch 48 | loss: 12632789165.2852|  0:15:33s\n",
            "epoch 50 | loss: 3012966941.80505|  0:15:47s\n",
            "epoch 60 | loss: 3578036884.33213|  0:17:51s\n",
            "epoch 65 | loss: 11264554077.34296|  0:18:47s\n",
            "epoch 60 | loss: 13013070484.33213|  0:17:36s\n",
            "epoch 34 | loss: 11990097200.51986|  0:12:22s\n",
            "epoch 52 | loss: 3552698928.98195|  0:15:39s\n",
            "epoch 50 | loss: 13084831845.42962|  0:15:29s\n",
            "epoch 51 | loss: 11511897770.97472|  0:15:44s\n",
            "epoch 49 | loss: 11269431541.37184|  0:16:42s\n",
            "epoch 49 | loss: 12400582273.84838|  0:15:53s\n",
            "epoch 61 | loss: 3642291734.6426|  0:18:08s\n",
            "epoch 34 | loss: 4019738727.74008|  0:12:12s\n",
            "epoch 66 | loss: 11271095282.13718|  0:19:04s\n",
            "epoch 51 | loss: 3031785855.53791|  0:16:06s\n",
            "epoch 32 | loss: 13484488525.16968|  0:11:49s\n",
            "epoch 61 | loss: 12778940058.33935|  0:17:53s\n",
            "epoch 53 | loss: 3587124316.41877|  0:15:58s\n",
            "epoch 51 | loss: 12917531464.54874|  0:15:48s\n",
            "epoch 35 | loss: 11982723753.8195|  0:12:44s\n",
            "epoch 52 | loss: 11574985008.51985|  0:16:03s\n",
            "epoch 67 | loss: 11231309255.62455|  0:19:21s\n",
            "epoch 62 | loss: 3572208151.10469|  0:18:26s\n",
            "epoch 50 | loss: 11563966813.80506|  0:17:03s\n",
            "epoch 62 | loss: 13044146159.36462|  0:18:11s\n",
            "epoch 50 | loss: 12258122280.66426|  0:16:12s\n",
            "epoch 52 | loss: 2945299614.0361|  0:16:25s\n",
            "epoch 35 | loss: 3903184268.47654|  0:12:33s\n",
            "epoch 33 | loss: 13394036200.8953|  0:12:11s\n",
            "epoch 54 | loss: 3458336825.76173|  0:16:16s\n",
            "epoch 52 | loss: 12883424481.03972|  0:16:06s\n",
            "epoch 53 | loss: 11546438914.54152|  0:16:22s\n",
            "epoch 36 | loss: 11836723553.0397|  0:13:06s\n",
            "epoch 68 | loss: 11240282177.38628|  0:19:39s\n",
            "epoch 63 | loss: 3480963346.94585|  0:18:44s\n",
            "epoch 63 | loss: 12733846639.82672|  0:18:28s\n",
            "epoch 51 | loss: 11270810583.10469|  0:17:23s\n",
            "epoch 53 | loss: 2917184853.25632|  0:16:44s\n",
            "epoch 51 | loss: 12473031993.29964|  0:16:32s\n",
            "epoch 36 | loss: 3899260488.31769|  0:12:54s\n",
            "epoch 55 | loss: 3488159508.79422|  0:16:34s\n",
            "epoch 34 | loss: 13334830496.34656|  0:12:33s\n",
            "epoch 53 | loss: 12839764864.92419|  0:16:25s\n",
            "epoch 54 | loss: 11486404330.51264|  0:16:40s\n",
            "epoch 69 | loss: 11304267627.20578|  0:19:55s\n",
            "epoch 64 | loss: 3497536573.45848|  0:19:02s\n",
            "epoch 37 | loss: 11846909953.38628|  0:13:28s\n",
            "epoch 64 | loss: 12753905751.33575|  0:18:46s\n",
            "epoch 54 | loss: 3470290677.14079|  0:17:03s\n",
            "epoch 52 | loss: 12188949455.71118|  0:16:52s\n",
            "epoch 52 | loss: 11163073233.79061|  0:17:43s\n",
            "epoch 56 | loss: 3482922680.83755|  0:16:53s\n",
            "epoch 37 | loss: 3889592092.18772|  0:13:15s\n",
            "epoch 54 | loss: 12677602894.55596|  0:16:44s\n",
            "epoch 35 | loss: 13312431947.7834|  0:12:55s\n",
            "epoch 55 | loss: 11412082547.75451|  0:16:59s\n",
            "epoch 70 | loss: 11151778915.35018|  0:20:13s\n",
            "epoch 65 | loss: 3535913008.05776|  0:19:20s\n",
            "epoch 65 | loss: 12983985967.36462|  0:19:03s\n",
            "epoch 38 | loss: 11997246257.90614|  0:13:50s\n",
            "epoch 55 | loss: 3172329172.56318|  0:17:21s\n",
            "epoch 53 | loss: 12252270435.81228|  0:17:11s\n",
            "epoch 53 | loss: 11092123875.81228|  0:18:04s\n",
            "epoch 57 | loss: 3371074996.44765|  0:17:11s\n",
            "epoch 55 | loss: 12788775226.91696|  0:17:03s\n",
            "epoch 38 | loss: 3912250762.62816|  0:13:37s\n",
            "epoch 71 | loss: 11181385246.96029|  0:20:30s\n",
            "epoch 56 | loss: 11367620715.20577|  0:17:18s\n",
            "epoch 66 | loss: 12826785083.14801|  0:19:21s\n",
            "epoch 66 | loss: 3478562079.88448|  0:19:38s\n",
            "epoch 36 | loss: 13288104016.40433|  0:13:17s\n",
            "epoch 56 | loss: 3060011892.44766|  0:17:41s\n",
            "epoch 39 | loss: 11691369446.35379|  0:14:12s\n",
            "epoch 54 | loss: 12182625493.02527|  0:17:31s\n",
            "epoch 58 | loss: 3374708582.12275|  0:17:30s\n",
            "epoch 54 | loss: 11086447586.88808|  0:18:24s\n",
            "epoch 56 | loss: 12812745432.25992|  0:17:22s\n",
            "epoch 72 | loss: 11107153932.01444|  0:20:48s\n",
            "epoch 67 | loss: 12783192741.4296|  0:19:38s\n",
            "epoch 39 | loss: 3763436453.19856|  0:13:58s\n",
            "epoch 57 | loss: 11380743836.18772|  0:17:37s\n",
            "epoch 67 | loss: 3526563970.54152|  0:19:56s\n",
            "epoch 37 | loss: 13252136004.3899|  0:13:40s\n",
            "epoch 57 | loss: 3365799898.1083|  0:18:00s\n",
            "epoch 55 | loss: 12369944556.12996|  0:17:51s\n",
            "epoch 59 | loss: 3369547953.67509|  0:17:48s\n",
            "epoch 40 | loss: 11762126861.86282|  0:14:34s\n",
            "epoch 55 | loss: 11039402480.7509|  0:18:45s\n",
            "epoch 73 | loss: 11183191137.03971|  0:21:05s\n",
            "epoch 57 | loss: 12732372645.89168|  0:17:41s\n",
            "epoch 68 | loss: 12562039664.28882|  0:19:56s\n",
            "epoch 68 | loss: 3674417351.16246|  0:20:13s\n",
            "epoch 58 | loss: 11249784565.83394|  0:17:55s\n",
            "epoch 40 | loss: 3925989787.26354|  0:14:20s\n",
            "epoch 58 | loss: 2937289175.33574|  0:18:19s\n",
            "epoch 38 | loss: 13264606810.1083|  0:14:03s\n",
            "epoch 60 | loss: 3376414480.17328|  0:18:06s\n",
            "epoch 74 | loss: 11255543367.62455|  0:21:22s\n",
            "epoch 56 | loss: 12302103801.06859|  0:18:11s\n",
            "epoch 56 | loss: 11323954651.26354|  0:19:05s\n",
            "epoch 69 | loss: 12636935123.63898|  0:20:13s\n",
            "epoch 41 | loss: 11562451688.20216|  0:14:56s\n",
            "epoch 58 | loss: 12780553295.71119|  0:18:01s\n",
            "epoch 69 | loss: 3389949404.88087|  0:20:30s\n",
            "epoch 59 | loss: 11229586431.30686|  0:18:13s\n",
            "epoch 41 | loss: 3828201553.55956|  0:14:41s\n",
            "epoch 59 | loss: 2924985756.18773|  0:18:38s\n",
            "epoch 61 | loss: 3370951866.68592|  0:18:24s\n",
            "epoch 75 | loss: 11173258978.42599|  0:21:38s\n",
            "epoch 39 | loss: 13164081519.36462|  0:14:25s\n",
            "epoch 57 | loss: 12120929595.37906|  0:18:31s\n",
            "epoch 70 | loss: 12516715960.37545|  0:20:30s\n",
            "epoch 70 | loss: 3423506594.19495|  0:20:48s\n",
            "epoch 59 | loss: 12747661765.08304|  0:18:19s\n",
            "epoch 57 | loss: 11253316047.48015|  0:19:25s\n",
            "epoch 60 | loss: 11114589359.59567|  0:18:32s\n",
            "epoch 42 | loss: 11681241423.48014|  0:15:17s\n",
            "epoch 42 | loss: 3744982757.19856|  0:15:02s\n",
            "epoch 76 | loss: 11288048699.61011|  0:21:55s\n",
            "epoch 60 | loss: 2824272938.51264|  0:18:57s\n",
            "epoch 62 | loss: 3235163037.57401|  0:18:42s\n",
            "epoch 71 | loss: 12711639034.45487|  0:20:47s\n",
            "epoch 71 | loss: 3297863802.91697|  0:21:06s\n",
            "epoch 58 | loss: 11947931976.54873|  0:18:50s\n",
            "epoch 60 | loss: 12591346663.97111|  0:18:38s\n",
            "epoch 61 | loss: 11087254804.33213|  0:18:50s\n",
            "epoch 40 | loss: 13282925338.33935|  0:14:48s\n",
            "epoch 58 | loss: 11185715109.19856|  0:19:45s\n",
            "epoch 43 | loss: 11487646330.45486|  0:15:39s\n",
            "epoch 77 | loss: 11153335019.66787|  0:22:13s\n",
            "epoch 63 | loss: 3388444687.94224|  0:19:01s\n",
            "epoch 61 | loss: 3027903194.1083|  0:19:16s\n",
            "epoch 43 | loss: 3677892517.4296|  0:15:24s\n",
            "epoch 72 | loss: 12454613489.6751|  0:21:05s\n",
            "epoch 72 | loss: 3319291722.16606|  0:21:24s\n",
            "epoch 59 | loss: 12008283757.51624|  0:19:10s\n",
            "epoch 61 | loss: 12546563078.46932|  0:18:57s\n",
            "epoch 62 | loss: 10964480009.93502|  0:19:08s\n",
            "epoch 59 | loss: 11158295029.60289|  0:20:05s\n",
            "epoch 41 | loss: 13631498488.60652|  0:15:09s\n",
            "epoch 44 | loss: 11397413063.16246|  0:16:00s\n",
            "epoch 78 | loss: 11172591390.0361|  0:22:31s\n",
            "epoch 64 | loss: 3375545849.29964|  0:19:19s\n",
            "epoch 62 | loss: 2944964328.20217|  0:19:34s\n",
            "epoch 73 | loss: 12991575939.23466|  0:21:22s\n",
            "epoch 73 | loss: 3585071166.84477|  0:21:41s\n",
            "epoch 44 | loss: 3670799981.74729|  0:15:44s\n",
            "epoch 63 | loss: 10987397382.00722|  0:19:26s\n",
            "epoch 62 | loss: 12584272829.92058|  0:19:15s\n",
            "epoch 60 | loss: 11907427608.95307|  0:19:30s\n",
            "epoch 60 | loss: 11135881521.21299|  0:20:25s\n",
            "epoch 42 | loss: 13373322586.1083|  0:15:32s\n",
            "epoch 79 | loss: 11165446981.31408|  0:22:48s\n",
            "epoch 45 | loss: 11334129958.81588|  0:16:21s\n",
            "epoch 65 | loss: 3271701936.28881|  0:19:37s\n",
            "epoch 74 | loss: 12821085043.98556|  0:21:39s\n",
            "epoch 63 | loss: 2896117344.80866|  0:19:53s\n",
            "epoch 74 | loss: 3138838088.77978|  0:21:59s\n",
            "epoch 45 | loss: 3677709233.44404|  0:16:06s\n",
            "epoch 64 | loss: 11133813650.48375|  0:19:45s\n",
            "epoch 63 | loss: 12257137625.41516|  0:19:34s\n",
            "epoch 61 | loss: 11887487179.3213|  0:19:49s\n",
            "epoch 61 | loss: 11164920359.74008|  0:20:46s\n",
            "epoch 80 | loss: 11094053868.59206|  0:23:06s\n",
            "epoch 75 | loss: 12571885308.30325|  0:21:57s\n",
            "epoch 66 | loss: 3376707593.24188|  0:19:56s\n",
            "epoch 43 | loss: 13266876160.0|  0:15:54s\n",
            "epoch 64 | loss: 2873183248.86643|  0:20:12s\n",
            "epoch 75 | loss: 3348268269.2852|  0:22:17s\n",
            "epoch 46 | loss: 11459830065.44404|  0:16:43s\n",
            "epoch 65 | loss: 11074882627.23466|  0:20:04s\n",
            "epoch 64 | loss: 13110240366.44043|  0:19:53s\n",
            "epoch 62 | loss: 11957081133.74729|  0:20:09s\n",
            "epoch 46 | loss: 3589016217.64621|  0:16:28s\n",
            "epoch 81 | loss: 11120513531.84116|  0:23:24s\n",
            "epoch 62 | loss: 11006092062.4982|  0:21:07s\n",
            "epoch 76 | loss: 12690719697.79061|  0:22:15s\n",
            "epoch 67 | loss: 3298094181.19856|  0:20:14s\n",
            "epoch 76 | loss: 3100092201.12635|  0:22:34s\n",
            "epoch 65 | loss: 3132346942.38267|  0:20:32s\n",
            "epoch 44 | loss: 13075441648.28881|  0:16:17s\n",
            "epoch 47 | loss: 11366829762.07942|  0:17:05s\n",
            "epoch 66 | loss: 11106849181.11191|  0:20:23s\n",
            "epoch 65 | loss: 13024056456.31769|  0:20:12s\n",
            "epoch 63 | loss: 12003442655.19135|  0:20:30s\n",
            "epoch 82 | loss: 11139709970.94585|  0:23:41s\n",
            "epoch 47 | loss: 3622454923.3213|  0:16:50s\n",
            "epoch 77 | loss: 12607408692.6787|  0:22:33s\n",
            "epoch 68 | loss: 3183523129.29964|  0:20:32s\n",
            "epoch 63 | loss: 11089339887.36462|  0:21:27s\n",
            "epoch 77 | loss: 3380093120.23105|  0:22:53s\n",
            "epoch 66 | loss: 2766711524.27437|  0:20:51s\n",
            "epoch 45 | loss: 13190879136.34658|  0:16:39s\n",
            "epoch 67 | loss: 11244361569.03971|  0:20:42s\n",
            "epoch 66 | loss: 12964889495.10468|  0:20:31s\n",
            "epoch 48 | loss: 11315874575.2491|  0:17:27s\n",
            "epoch 83 | loss: 11146724857.06859|  0:23:59s\n",
            "epoch 64 | loss: 12421503339.89892|  0:20:50s\n",
            "epoch 78 | loss: 12600649171.1769|  0:22:50s\n",
            "epoch 69 | loss: 3267566419.17689|  0:20:51s\n",
            "epoch 48 | loss: 3535481852.5343|  0:17:12s\n",
            "epoch 78 | loss: 3381946892.01444|  0:23:11s\n",
            "epoch 64 | loss: 10919634549.60289|  0:21:49s\n",
            "epoch 67 | loss: 2781226034.83033|  0:21:10s\n",
            "epoch 68 | loss: 10947003030.18051|  0:21:01s\n",
            "epoch 67 | loss: 12927179729.55956|  0:20:50s\n",
            "epoch 84 | loss: 11099183408.28881|  0:24:16s\n",
            "epoch 46 | loss: 13076913430.6426|  0:17:02s\n",
            "epoch 49 | loss: 11364263821.40072|  0:17:50s\n",
            "epoch 79 | loss: 12618341796.50542|  0:23:08s\n",
            "epoch 65 | loss: 12031069810.59928|  0:21:10s\n",
            "epoch 70 | loss: 3220218403.58123|  0:21:09s\n",
            "epoch 79 | loss: 3325222168.95307|  0:23:29s\n",
            "epoch 49 | loss: 3536569072.7509|  0:17:33s\n",
            "epoch 68 | loss: 2676883259.61011|  0:21:29s\n",
            "epoch 65 | loss: 10897277985.73286|  0:22:09s\n",
            "epoch 68 | loss: 12906521476.15885|  0:21:09s\n",
            "epoch 69 | loss: 10783526429.34296|  0:21:21s\n",
            "epoch 85 | loss: 11135936101.4296|  0:24:34s\n",
            "epoch 80 | loss: 12397915788.93863|  0:23:26s\n",
            "epoch 47 | loss: 13061537119.65343|  0:17:25s\n",
            "epoch 66 | loss: 11915898489.76174|  0:21:30s\n",
            "epoch 71 | loss: 3284113698.65704|  0:21:28s\n",
            "epoch 50 | loss: 11244829281.9639|  0:18:12s\n",
            "epoch 80 | loss: 3069491028.56318|  0:23:47s\n",
            "epoch 50 | loss: 3476007637.94946|  0:17:56s\n",
            "epoch 69 | loss: 2804346543.13357|  0:21:49s\n",
            "epoch 66 | loss: 10702165889.15524|  0:22:30s\n",
            "epoch 86 | loss: 11054427929.87726|  0:24:52s\n",
            "epoch 69 | loss: 12807246842.45488|  0:21:28s\n",
            "epoch 70 | loss: 11049378458.80145|  0:21:40s\n",
            "epoch 81 | loss: 12370807500.24548|  0:23:43s\n",
            "epoch 81 | loss: 2962883755.43682|  0:24:04s\n",
            "epoch 72 | loss: 3138876793.53069|  0:21:46s\n",
            "epoch 67 | loss: 11968834262.41155|  0:21:50s\n",
            "epoch 48 | loss: 12813183544.37545|  0:17:47s\n",
            "epoch 51 | loss: 11253586727.74007|  0:18:34s\n",
            "epoch 70 | loss: 3028657944.49098|  0:22:08s\n",
            "epoch 87 | loss: 11065923374.20938|  0:25:09s\n",
            "epoch 51 | loss: 3527614363.95668|  0:18:17s\n",
            "epoch 67 | loss: 11084798497.0397|  0:22:50s\n",
            "epoch 70 | loss: 12853188283.61012|  0:21:47s\n",
            "epoch 71 | loss: 10898064823.91336|  0:21:58s\n",
            "epoch 82 | loss: 12594316873.47292|  0:24:00s\n",
            "epoch 82 | loss: 3115466648.95307|  0:24:22s\n",
            "epoch 73 | loss: 3047806695.97112|  0:22:04s\n",
            "epoch 68 | loss: 12158096699.61011|  0:22:10s\n",
            "epoch 52 | loss: 11335158302.96029|  0:18:56s\n",
            "epoch 49 | loss: 12784880660.79421|  0:18:09s\n",
            "epoch 88 | loss: 11121205028.50542|  0:25:27s\n",
            "epoch 71 | loss: 2746256196.15885|  0:22:28s\n",
            "epoch 68 | loss: 10967474970.33935|  0:23:10s\n",
            "epoch 83 | loss: 12654968084.56318|  0:24:18s\n",
            "epoch 52 | loss: 3553822469.31408|  0:18:39s\n",
            "epoch 71 | loss: 12804423299.00361|  0:22:06s\n",
            "epoch 72 | loss: 11058099811.81228|  0:22:18s\n",
            "epoch 83 | loss: 3535201171.40794|  0:24:41s\n",
            "epoch 74 | loss: 3118837075.63899|  0:22:24s\n",
            "epoch 69 | loss: 12051420238.32491|  0:22:30s\n",
            "epoch 89 | loss: 11045065187.81227|  0:25:45s\n",
            "epoch 72 | loss: 3182754720.11552|  0:22:48s\n",
            "epoch 84 | loss: 12599519735.45126|  0:24:36s\n",
            "epoch 53 | loss: 11326819330.31047|  0:19:19s\n",
            "epoch 50 | loss: 12729235120.2888|  0:18:33s\n",
            "epoch 72 | loss: 12685287269.66064|  0:22:25s\n",
            "epoch 73 | loss: 10590612897.27076|  0:22:37s\n",
            "epoch 69 | loss: 10869327287.91336|  0:23:32s\n",
            "epoch 53 | loss: 3425516928.92419|  0:19:01s\n",
            "epoch 84 | loss: 2906644818.7148|  0:25:00s\n",
            "epoch 75 | loss: 3253838664.31769|  0:22:43s\n",
            "epoch 70 | loss: 11718382393.76173|  0:22:51s\n",
            "epoch 90 | loss: 11063247658.97473|  0:26:03s\n",
            "epoch 73 | loss: 2692177569.27076|  0:23:07s\n",
            "epoch 85 | loss: 12729101543.50902|  0:24:55s\n",
            "epoch 73 | loss: 12631495198.0361|  0:22:45s\n",
            "epoch 74 | loss: 10841558106.5704|  0:22:57s\n",
            "epoch 54 | loss: 11226418327.10469|  0:19:42s\n",
            "epoch 51 | loss: 12757895288.1444|  0:18:56s\n",
            "epoch 85 | loss: 3177855904.80866|  0:25:18s\n",
            "epoch 70 | loss: 10772722684.99639|  0:23:54s\n",
            "epoch 54 | loss: 3575581397.48736|  0:19:23s\n",
            "epoch 76 | loss: 3194774308.50542|  0:23:02s\n",
            "epoch 91 | loss: 11085139187.06137|  0:26:20s\n",
            "epoch 71 | loss: 12082806543.2491|  0:23:12s\n",
            "epoch 86 | loss: 12704810413.2852|  0:25:13s\n",
            "epoch 74 | loss: 2655712308.44765|  0:23:27s\n",
            "epoch 74 | loss: 12546993200.28881|  0:23:04s\n",
            "epoch 75 | loss: 11090909000.31769|  0:23:17s\n",
            "epoch 86 | loss: 2958370189.63177|  0:25:37s\n",
            "epoch 55 | loss: 11178703449.41516|  0:20:05s\n",
            "epoch 77 | loss: 3276161734.46931|  0:23:21s\n",
            "epoch 71 | loss: 10666885790.4982|  0:24:16s\n",
            "epoch 52 | loss: 12711258417.90614|  0:19:19s\n",
            "epoch 55 | loss: 3338452015.36462|  0:19:45s\n",
            "epoch 92 | loss: 11235356109.16968|  0:26:38s\n",
            "epoch 87 | loss: 12780897355.09025|  0:25:31s\n",
            "epoch 72 | loss: 11774720748.12997|  0:23:32s\n",
            "epoch 75 | loss: 2828619769.06859|  0:23:47s\n",
            "epoch 75 | loss: 12672534064.98195|  0:23:23s\n",
            "epoch 76 | loss: 10718280620.82311|  0:23:36s\n",
            "epoch 87 | loss: 2887522072.02888|  0:25:55s\n",
            "epoch 78 | loss: 3233781686.29603|  0:23:39s\n",
            "epoch 93 | loss: 11087329369.64621|  0:26:56s\n",
            "epoch 72 | loss: 10583636270.67148|  0:24:37s\n",
            "epoch 56 | loss: 11137685344.34657|  0:20:27s\n",
            "epoch 53 | loss: 12760062890.28159|  0:19:43s\n",
            "epoch 56 | loss: 3341485610.97473|  0:20:07s\n",
            "epoch 88 | loss: 12769841189.8917|  0:25:49s\n",
            "epoch 73 | loss: 11599416381.92058|  0:23:52s\n",
            "epoch 76 | loss: 2830643686.35379|  0:24:06s\n",
            "epoch 76 | loss: 12518100652.361|  0:23:43s\n",
            "epoch 88 | loss: 3560996358.00722|  0:26:14s\n",
            "epoch 77 | loss: 10730841114.80144|  0:23:56s\n",
            "epoch 79 | loss: 3193190494.26715|  0:23:58s\n",
            "epoch 94 | loss: 11067280660.79422|  0:27:13s\n",
            "epoch 73 | loss: 10778024108.8231|  0:24:58s\n",
            "epoch 89 | loss: 3848834880.69314|  0:26:07s\n",
            "epoch 57 | loss: 11153598564.73646|  0:20:50s\n",
            "epoch 57 | loss: 3244767045.31408|  0:20:29s\n",
            "epoch 54 | loss: 12682412675.69675|  0:20:05s\n",
            "epoch 74 | loss: 11789528359.74008|  0:24:11s\n",
            "epoch 77 | loss: 2621829265.55957|  0:24:26s\n",
            "epoch 77 | loss: 12681559756.24548|  0:24:02s\n",
            "epoch 89 | loss: 3145703487.30686|  0:26:32s\n",
            "epoch 78 | loss: 11073218932.90975|  0:24:15s\n",
            "epoch 80 | loss: 3168318859.78339|  0:24:16s\n",
            "epoch 95 | loss: 11078029818.45488|  0:27:31s\n",
            "epoch 90 | loss: 12726759818.8592|  0:26:25s\n",
            "epoch 74 | loss: 10730323169.73285|  0:25:19s\n",
            "epoch 58 | loss: 11122160201.47292|  0:21:12s\n",
            "epoch 75 | loss: 12059470186.74369|  0:24:31s\n",
            "epoch 58 | loss: 3384291654.23827|  0:20:51s\n",
            "epoch 55 | loss: 12652841416.08664|  0:20:28s\n",
            "epoch 78 | loss: 2748897351.16246|  0:24:45s\n",
            "epoch 90 | loss: 2998707176.43321|  0:26:50s\n",
            "epoch 78 | loss: 12280015244.47654|  0:24:21s\n",
            "epoch 79 | loss: 10846328616.20216|  0:24:34s\n",
            "epoch 81 | loss: 3258859609.64621|  0:24:35s\n",
            "epoch 96 | loss: 11050015129.87726|  0:27:48s\n",
            "epoch 91 | loss: 12400144251.84115|  0:26:42s\n",
            "epoch 75 | loss: 10692198957.74729|  0:25:40s\n",
            "epoch 76 | loss: 11754999959.56678|  0:24:51s\n",
            "epoch 91 | loss: 3466166806.87365|  0:27:08s\n",
            "epoch 79 | loss: 2940881627.72563|  0:25:04s\n",
            "epoch 79 | loss: 12364623385.87725|  0:24:39s\n",
            "epoch 59 | loss: 11030560753.44404|  0:21:35s\n",
            "epoch 59 | loss: 3297498531.11913|  0:21:14s\n",
            "epoch 97 | loss: 11040812304.17329|  0:28:07s\n",
            "epoch 56 | loss: 12669662360.49098|  0:20:51s\n",
            "epoch 82 | loss: 3089267469.16968|  0:24:53s\n",
            "epoch 80 | loss: 10760372017.213|  0:24:54s\n",
            "epoch 92 | loss: 12463944955.37906|  0:27:00s\n",
            "epoch 76 | loss: 10783850251.09025|  0:26:01s\n",
            "epoch 92 | loss: 3702063968.57762|  0:27:26s\n",
            "epoch 77 | loss: 11487572267.66788|  0:25:11s\n",
            "epoch 80 | loss: 2718585197.74729|  0:25:23s\n",
            "epoch 80 | loss: 12244630520.83754|  0:24:59s\n",
            "epoch 98 | loss: 11062996923.14802|  0:28:25s\n",
            "epoch 60 | loss: 11032656402.94585|  0:21:56s\n",
            "epoch 83 | loss: 3112888182.06498|  0:25:12s\n",
            "epoch 81 | loss: 10781613073.32852|  0:25:13s\n",
            "epoch 60 | loss: 3238295261.80505|  0:21:35s\n",
            "epoch 93 | loss: 12381906856.20217|  0:27:18s\n",
            "epoch 57 | loss: 12441267961.53068|  0:21:14s\n",
            "epoch 93 | loss: 3718781692.99639|  0:27:44s\n",
            "epoch 77 | loss: 10557184108.36102|  0:26:22s\n",
            "epoch 81 | loss: 2629728744.20217|  0:25:43s\n",
            "epoch 78 | loss: 11691425339.61012|  0:25:32s\n",
            "epoch 99 | loss: 11224020439.79783|  0:28:43s\n",
            "epoch 81 | loss: 12017230323.98556|  0:25:18s\n",
            "epoch 84 | loss: 3214440429.05415|  0:25:31s\n",
            "epoch 82 | loss: 11059867554.65704|  0:25:32s\n",
            "epoch 94 | loss: 12287072676.04332|  0:27:36s\n",
            "epoch 61 | loss: 14473060459.66787|  0:22:19s\n",
            "epoch 61 | loss: 3259754993.213|  0:21:58s\n",
            "epoch 58 | loss: 12500979554.426|  0:21:37s\n",
            "epoch 94 | loss: 3623547881.3574|  0:28:03s\n",
            "epoch 82 | loss: 2819110726.46931|  0:26:03s\n",
            "epoch 78 | loss: 10670269020.18772|  0:26:44s\n",
            "epoch 82 | loss: 12042134684.41878|  0:25:39s\n",
            "epoch 79 | loss: 11715070974.61372|  0:25:53s\n",
            "epoch 85 | loss: 3228044249.18411|  0:25:52s\n",
            "epoch 83 | loss: 10815651836.30325|  0:25:54s\n",
            "epoch 95 | loss: 12247788134.58482|  0:27:56s\n",
            "epoch 62 | loss: 16738963594.62815|  0:22:44s\n",
            "epoch 62 | loss: 3289205262.09386|  0:22:23s\n",
            "epoch 59 | loss: 12570937847.22022|  0:22:02s\n",
            "epoch 95 | loss: 3653125435.61011|  0:28:24s\n",
            "epoch 83 | loss: 2797283561.81949|  0:26:26s\n",
            "epoch 83 | loss: 12493462682.1083|  0:26:01s\n",
            "epoch 86 | loss: 3049390894.44043|  0:26:13s\n",
            "epoch 79 | loss: 10743988177.09747|  0:27:08s\n",
            "epoch 80 | loss: 11794311621.77617|  0:26:16s\n",
            "epoch 96 | loss: 12285848474.33935|  0:28:16s\n",
            "[CV] END .....................................n_a=16, n_d=16; total time=29.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 84 | loss: 10794283325.22744|  0:26:16s\n",
            "epoch 63 | loss: 15679101189.08302|  0:23:07s\n",
            "epoch 96 | loss: 3492451049.58845|  0:28:42s\n",
            "epoch 63 | loss: 3301955029.25632|  0:22:45s\n",
            "epoch 60 | loss: 12750646887.97112|  0:22:24s\n",
            "epoch 84 | loss: 2687765646.55596|  0:26:45s\n",
            "epoch 97 | loss: 12263050531.11913|  0:28:33s\n",
            "epoch 87 | loss: 3138862150.23827|  0:26:31s\n",
            "epoch 84 | loss: 12145364159.76895|  0:26:20s\n",
            "epoch 81 | loss: 11524084913.90613|  0:26:36s\n",
            "epoch 80 | loss: 10409910527.5379|  0:27:28s\n",
            "epoch 85 | loss: 10983959038.38267|  0:26:35s\n",
            "epoch 0  | loss: 22322577870.09386|  0:00:24s\n",
            "epoch 97 | loss: 3216364904.89531|  0:28:59s\n",
            "epoch 64 | loss: 11464402055.3935|  0:23:29s\n",
            "epoch 64 | loss: 3179208626.83032|  0:23:07s\n",
            "epoch 61 | loss: 12702863997.22744|  0:22:46s\n",
            "epoch 98 | loss: 12729665842.36822|  0:28:51s\n",
            "epoch 88 | loss: 3105038030.787|  0:26:49s\n",
            "epoch 85 | loss: 2816807548.5343|  0:27:04s\n",
            "epoch 85 | loss: 12106024130.31047|  0:26:40s\n",
            "epoch 82 | loss: 11479298683.14802|  0:26:56s\n",
            "epoch 86 | loss: 11059545734.93141|  0:26:54s\n",
            "epoch 81 | loss: 10703306761.70397|  0:27:49s\n",
            "epoch 98 | loss: 3102276681.24188|  0:29:17s\n",
            "epoch 1  | loss: 20380521420.24548|  0:00:49s\n",
            "epoch 99 | loss: 12315097514.51263|  0:29:09s\n",
            "epoch 65 | loss: 11425289941.02527|  0:23:52s\n",
            "epoch 65 | loss: 3163122160.98195|  0:23:30s\n",
            "epoch 89 | loss: 3126157044.6787|  0:27:08s\n",
            "epoch 86 | loss: 2683303664.51986|  0:27:23s\n",
            "epoch 62 | loss: 12749191122.2527|  0:23:08s\n",
            "epoch 86 | loss: 11916644918.52707|  0:27:00s\n",
            "epoch 83 | loss: 11612663048.7798|  0:27:17s\n",
            "epoch 87 | loss: 10961942653.22744|  0:27:15s\n",
            "epoch 82 | loss: 10818154123.55235|  0:28:11s\n",
            "epoch 99 | loss: 3035917641.93502|  0:29:36s\n",
            "epoch 90 | loss: 3030585470.61372|  0:27:31s\n",
            "epoch 2  | loss: 18023089612.24548|  0:01:16s\n",
            "epoch 87 | loss: 2803554159.36462|  0:27:47s\n",
            "epoch 87 | loss: 12205779310.67147|  0:27:23s\n",
            "epoch 66 | loss: 3144074677.37184|  0:23:57s\n",
            "epoch 66 | loss: 11195019902.61372|  0:24:20s\n",
            "epoch 63 | loss: 12442511450.1083|  0:23:35s\n",
            "epoch 84 | loss: 11544005188.15884|  0:27:42s\n",
            "epoch 88 | loss: 10875581740.12996|  0:27:40s\n",
            "epoch 83 | loss: 10392135902.96029|  0:28:39s\n",
            "epoch 91 | loss: 2948377385.12635|  0:27:55s\n",
            "[CV] END .....................................n_a=16, n_d=16; total time=30.0min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 88 | loss: 2802279412.44765|  0:28:13s\n",
            "epoch 3  | loss: 16155873995.3213|  0:01:44s\n",
            "epoch 88 | loss: 12219524193.03971|  0:27:48s\n",
            "epoch 67 | loss: 3185633170.7148|  0:24:25s\n",
            "epoch 85 | loss: 11793339928.02888|  0:28:07s\n",
            "epoch 67 | loss: 11231107764.6787|  0:24:49s\n",
            "epoch 89 | loss: 10744828163.46571|  0:28:05s\n",
            "epoch 64 | loss: 12503839951.01806|  0:24:03s\n",
            "[CV] END .....................................n_a=16, n_d=16; total time=30.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 84 | loss: 10548677753.76173|  0:29:02s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 92 | loss: 2767922178.07942|  0:28:15s\n",
            "epoch 89 | loss: 2691022442.74368|  0:28:32s\n",
            "epoch 89 | loss: 12309395971.69676|  0:28:08s\n",
            "epoch 0  | loss: 14519083229.80505|  0:00:24s\n",
            "epoch 4  | loss: 14894406348.24549|  0:02:06s\n",
            "epoch 86 | loss: 11387691676.18772|  0:28:27s\n",
            "epoch 90 | loss: 10731106182.9314|  0:28:24s\n",
            "epoch 68 | loss: 3603337661.92057|  0:24:47s\n",
            "epoch 65 | loss: 12322482860.36101|  0:24:24s\n",
            "epoch 68 | loss: 10837730938.91697|  0:25:11s\n",
            "epoch 85 | loss: 10793810483.52347|  0:29:21s\n",
            "epoch 0  | loss: 24055495957.25632|  0:00:19s\n",
            "epoch 93 | loss: 2842637679.59567|  0:28:34s\n",
            "epoch 90 | loss: 3282305873.32852|  0:28:51s\n",
            "epoch 90 | loss: 11889896440.37545|  0:28:26s\n",
            "epoch 5  | loss: 13976317770.3971|  0:02:28s\n",
            "epoch 87 | loss: 10594023253.71841|  0:28:46s\n",
            "epoch 1  | loss: 12566370913.9639|  0:00:47s\n",
            "epoch 91 | loss: 10696142696.20217|  0:28:43s\n",
            "epoch 69 | loss: 3530326288.63538|  0:25:07s\n",
            "epoch 86 | loss: 10583217366.87365|  0:29:40s\n",
            "epoch 66 | loss: 12448811678.0361|  0:24:45s\n",
            "epoch 69 | loss: 10920683213.16967|  0:25:33s\n",
            "epoch 94 | loss: 2834322820.15885|  0:28:52s\n",
            "epoch 1  | loss: 22186987211.3213|  0:00:41s\n",
            "epoch 91 | loss: 3002037617.213|  0:29:10s\n",
            "epoch 91 | loss: 11843820422.70036|  0:28:45s\n",
            "epoch 92 | loss: 10656001185.9639|  0:29:02s\n",
            "epoch 88 | loss: 11491186928.7509|  0:29:06s\n",
            "epoch 6  | loss: 13461544093.11191|  0:02:50s\n",
            "epoch 87 | loss: 10399504289.03971|  0:30:00s\n",
            "epoch 2  | loss: 10166224088.25992|  0:01:10s\n",
            "epoch 70 | loss: 3488949519.71119|  0:25:29s\n",
            "epoch 67 | loss: 12286932405.60289|  0:25:07s\n",
            "epoch 95 | loss: 2832589896.31769|  0:29:10s\n",
            "epoch 70 | loss: 10973200459.32131|  0:25:55s\n",
            "epoch 92 | loss: 2759890893.16968|  0:29:29s\n",
            "epoch 2  | loss: 20149994229.83393|  0:01:02s\n",
            "epoch 92 | loss: 12191961908.44765|  0:29:04s\n",
            "epoch 93 | loss: 10596124454.58484|  0:29:21s\n",
            "epoch 89 | loss: 11656981752.6065|  0:29:26s\n",
            "epoch 88 | loss: 10836746002.02166|  0:30:19s\n",
            "epoch 7  | loss: 13081340925.22744|  0:03:13s\n",
            "epoch 71 | loss: 3805991188.10108|  0:25:50s\n",
            "epoch 96 | loss: 2968583898.5704|  0:29:29s\n",
            "epoch 68 | loss: 12318042913.73285|  0:25:27s\n",
            "epoch 3  | loss: 8354846409.47292|  0:01:33s\n",
            "epoch 71 | loss: 10870558667.3213|  0:26:16s\n",
            "epoch 93 | loss: 2705073175.56679|  0:29:48s\n",
            "epoch 93 | loss: 12039502982.93141|  0:29:22s\n",
            "epoch 3  | loss: 18334151120.86644|  0:01:24s\n",
            "epoch 94 | loss: 10590276142.90253|  0:29:40s\n",
            "epoch 90 | loss: 11996904324.15884|  0:29:45s\n",
            "epoch 89 | loss: 10400575125.94946|  0:30:39s\n",
            "epoch 97 | loss: 2831251487.42238|  0:29:47s\n",
            "epoch 72 | loss: 3664307227.26354|  0:26:11s\n",
            "epoch 69 | loss: 12482517265.09747|  0:25:48s\n",
            "epoch 8  | loss: 12862227045.19855|  0:03:36s\n",
            "epoch 94 | loss: 2612579846.46931|  0:30:07s\n",
            "epoch 94 | loss: 11946401497.18412|  0:29:41s\n",
            "epoch 4  | loss: 7058096261.08304|  0:01:56s\n",
            "epoch 72 | loss: 10970180754.02165|  0:26:38s\n",
            "epoch 4  | loss: 16945145875.40793|  0:01:45s\n",
            "epoch 95 | loss: 10440242706.7148|  0:29:59s\n",
            "epoch 91 | loss: 11726239467.20578|  0:30:05s\n",
            "epoch 90 | loss: 10463732228.62094|  0:30:58s\n",
            "epoch 98 | loss: 2898223450.80144|  0:30:05s\n",
            "epoch 73 | loss: 3605092386.65704|  0:26:32s\n",
            "epoch 95 | loss: 2653914145.27076|  0:30:26s\n",
            "epoch 95 | loss: 11855636157.45849|  0:30:00s\n",
            "epoch 70 | loss: 12445121877.25631|  0:26:09s\n",
            "epoch 9  | loss: 12745283223.10469|  0:03:59s\n",
            "epoch 73 | loss: 10802822441.12635|  0:26:59s\n",
            "epoch 5  | loss: 6156320613.19856|  0:02:19s\n",
            "epoch 96 | loss: 10394816197.08304|  0:30:18s\n",
            "epoch 5  | loss: 15908047587.35017|  0:02:06s\n",
            "epoch 92 | loss: 11609970673.6751|  0:30:25s\n",
            "epoch 99 | loss: 2917590799.71119|  0:30:23s\n",
            "epoch 91 | loss: 10592676610.54152|  0:31:18s\n",
            "epoch 96 | loss: 2741011177.12635|  0:30:44s\n",
            "epoch 96 | loss: 12253982479.01805|  0:30:19s\n",
            "epoch 71 | loss: 12421868043.09026|  0:26:30s\n",
            "epoch 74 | loss: 3626798785.61733|  0:26:54s\n",
            "epoch 74 | loss: 10951866240.69314|  0:27:21s\n",
            "epoch 10 | loss: 12658864390.46932|  0:04:22s\n",
            "epoch 97 | loss: 10738093183.76895|  0:30:38s\n",
            "epoch 6  | loss: 5614742861.63177|  0:02:43s\n",
            "epoch 6  | loss: 15193982371.11912|  0:02:29s\n",
            "epoch 93 | loss: 11675905035.09025|  0:30:45s\n",
            "epoch 92 | loss: 10334139821.05415|  0:31:39s\n",
            "epoch 97 | loss: 2794167772.64982|  0:31:04s\n",
            "epoch 97 | loss: 12070299787.3213|  0:30:38s\n",
            "epoch 75 | loss: 3504868083.06137|  0:27:16s\n",
            "epoch 72 | loss: 12278962375.16246|  0:26:52s\n",
            "epoch 98 | loss: 10708340439.56679|  0:30:57s\n",
            "epoch 75 | loss: 10753128071.16245|  0:27:41s\n",
            "epoch 11 | loss: 12598993550.78702|  0:04:46s\n",
            "epoch 94 | loss: 11577516066.19495|  0:31:05s\n",
            "epoch 7  | loss: 14750572876.70758|  0:02:51s\n",
            "epoch 7  | loss: 5274099490.65704|  0:03:08s\n",
            "epoch 93 | loss: 10774983366.23827|  0:31:59s\n",
            "[CV] END ......................................n_a=32, n_d=8; total time=31.1min\n",
            "epoch 98 | loss: 12013222695.04693|  0:30:57s\n",
            "epoch 98 | loss: 2640962009.18411|  0:31:23s\n",
            "epoch 76 | loss: 3466826146.42599|  0:27:35s\n",
            "epoch 73 | loss: 12379141110.29603|  0:27:12s\n",
            "epoch 99 | loss: 10730889928.77978|  0:31:14s\n",
            "epoch 76 | loss: 10716296732.64982|  0:28:00s\n",
            "epoch 95 | loss: 11543730057.01083|  0:31:22s\n",
            "epoch 12 | loss: 12680980576.11554|  0:05:07s\n",
            "epoch 94 | loss: 10390882871.22022|  0:32:17s\n",
            "epoch 8  | loss: 14614032085.48736|  0:03:11s\n",
            "epoch 99 | loss: 11880606938.80144|  0:31:14s\n",
            "epoch 99 | loss: 2802408953.06859|  0:31:40s\n",
            "epoch 8  | loss: 5030529132.12996|  0:03:30s\n",
            "epoch 77 | loss: 3464419790.32491|  0:27:53s\n",
            "epoch 74 | loss: 12325681574.12275|  0:27:32s\n",
            "epoch 77 | loss: 10658624023.56679|  0:28:20s\n",
            "epoch 96 | loss: 11314351614.84477|  0:31:43s\n",
            "epoch 95 | loss: 10382808204.01444|  0:32:39s\n",
            "epoch 13 | loss: 12502486134.29604|  0:05:33s\n",
            "epoch 9  | loss: 14378738903.33575|  0:03:36s\n",
            "epoch 78 | loss: 3457517238.52708|  0:28:16s\n",
            "epoch 9  | loss: 4945156171.3213|  0:04:01s\n",
            "epoch 75 | loss: 12263448193.38628|  0:27:56s\n",
            "epoch 78 | loss: 10596738944.0|  0:28:43s\n",
            "[CV] END ......................................n_a=32, n_d=8; total time=32.0min\n",
            "epoch 97 | loss: 11213216547.81227|  0:32:05s\n",
            "epoch 96 | loss: 10074964087.22022|  0:33:01s\n",
            "epoch 10 | loss: 14287417666.07941|  0:04:00s\n",
            "epoch 14 | loss: 12469664821.14079|  0:05:58s\n",
            "[CV] END ......................................n_a=32, n_d=8; total time=32.1min\n",
            "epoch 79 | loss: 3445224649.24188|  0:28:36s\n",
            "[CV] END .....................................n_a=16, n_d=32; total time=32.5min\n",
            "epoch 76 | loss: 12244752930.42599|  0:28:14s\n",
            "epoch 79 | loss: 10705695742.84476|  0:29:02s\n",
            "epoch 98 | loss: 10702817716.90975|  0:32:22s\n",
            "epoch 10 | loss: 4866912511.53791|  0:04:24s\n",
            "epoch 97 | loss: 10552823381.25632|  0:33:16s\n",
            "epoch 11 | loss: 14244211658.3971|  0:04:15s\n",
            "epoch 80 | loss: 3388551759.94224|  0:28:50s\n",
            "epoch 15 | loss: 12467234542.44043|  0:06:14s\n",
            "epoch 77 | loss: 12310618451.63898|  0:28:27s\n",
            "epoch 80 | loss: 10576512297.3574|  0:29:15s\n",
            "epoch 99 | loss: 10432633907.98556|  0:32:35s\n",
            "epoch 98 | loss: 10357636577.73285|  0:33:29s\n",
            "epoch 11 | loss: 4826005555.29242|  0:04:40s\n",
            "epoch 81 | loss: 3409452827.49458|  0:29:03s\n",
            "epoch 12 | loss: 14154018209.73285|  0:04:31s\n",
            "epoch 78 | loss: 12254760313.76174|  0:28:41s\n",
            "epoch 81 | loss: 10778047753.47292|  0:29:30s\n",
            "epoch 16 | loss: 12442194626.07942|  0:06:31s\n",
            "epoch 99 | loss: 10569785837.2852|  0:33:44s\n",
            "epoch 12 | loss: 4772772249.41516|  0:04:59s\n",
            "epoch 82 | loss: 3403632337.79061|  0:29:19s\n",
            "epoch 79 | loss: 12259248418.19495|  0:28:57s\n",
            "epoch 13 | loss: 14078747401.70398|  0:04:49s\n",
            "epoch 82 | loss: 10524067545.18412|  0:29:46s\n",
            "[CV] END .....................................n_a=16, n_d=32; total time=33.1min\n",
            "epoch 17 | loss: 12367427761.90614|  0:06:50s\n",
            "epoch 83 | loss: 3302490531.35018|  0:29:33s\n",
            "epoch 13 | loss: 4743726141.92058|  0:05:16s\n",
            "epoch 80 | loss: 12241435629.51624|  0:29:11s\n",
            "epoch 83 | loss: 10601980224.92418|  0:29:59s\n",
            "epoch 14 | loss: 14001069685.37184|  0:05:04s\n",
            "epoch 18 | loss: 12430527634.02166|  0:07:06s\n",
            "[CV] END .....................................n_a=16, n_d=32; total time=34.3min\n",
            "epoch 84 | loss: 3494036772.04332|  0:29:46s\n",
            "epoch 81 | loss: 12205250493.92058|  0:29:24s\n",
            "epoch 84 | loss: 10592410148.73646|  0:30:11s\n",
            "epoch 14 | loss: 4671583769.87726|  0:05:31s\n",
            "epoch 15 | loss: 13925125710.55596|  0:05:17s\n",
            "epoch 19 | loss: 12342767142.35379|  0:07:18s\n",
            "epoch 85 | loss: 3321324869.77617|  0:29:56s\n",
            "epoch 82 | loss: 12019984075.55235|  0:29:34s\n",
            "epoch 85 | loss: 10711784405.25632|  0:30:22s\n",
            "epoch 15 | loss: 4530667931.72563|  0:05:44s\n",
            "epoch 16 | loss: 13837986047.5379|  0:05:29s\n",
            "epoch 86 | loss: 3349493210.5704|  0:30:07s\n",
            "epoch 20 | loss: 12237657769.12636|  0:07:31s\n",
            "epoch 83 | loss: 12153347974.23826|  0:29:45s\n",
            "epoch 86 | loss: 10854001166.787|  0:30:32s\n",
            "epoch 16 | loss: 4605154496.23105|  0:05:56s\n",
            "epoch 17 | loss: 13857661415.97112|  0:05:41s\n",
            "epoch 87 | loss: 3396578221.2852|  0:30:18s\n",
            "epoch 84 | loss: 12268054042.5704|  0:29:56s\n",
            "epoch 21 | loss: 12177887310.09386|  0:07:44s\n",
            "epoch 87 | loss: 10788243004.0722|  0:30:43s\n",
            "epoch 17 | loss: 4618586060.70758|  0:06:08s\n",
            "epoch 18 | loss: 13741912294.58484|  0:05:53s\n",
            "epoch 88 | loss: 3228198185.3574|  0:30:28s\n",
            "epoch 85 | loss: 12282277021.34296|  0:30:06s\n",
            "epoch 88 | loss: 10797016018.7148|  0:30:54s\n",
            "epoch 22 | loss: 12128159648.34657|  0:07:56s\n",
            "epoch 18 | loss: 4547858515.63899|  0:06:21s\n",
            "epoch 19 | loss: 13778627196.76534|  0:06:04s\n",
            "epoch 89 | loss: 3362337736.77978|  0:30:39s\n",
            "epoch 86 | loss: 12276677645.86282|  0:30:17s\n",
            "epoch 89 | loss: 10716901386.16606|  0:31:05s\n",
            "epoch 23 | loss: 12101220578.426|  0:08:09s\n",
            "epoch 90 | loss: 3317352637.22744|  0:30:50s\n",
            "epoch 20 | loss: 13775100935.8556|  0:06:17s\n",
            "epoch 19 | loss: 4561158273.38628|  0:06:33s\n",
            "epoch 87 | loss: 12231296408.02888|  0:30:28s\n",
            "epoch 90 | loss: 10597201868.24549|  0:31:17s\n",
            "epoch 24 | loss: 12001000873.81949|  0:08:22s\n",
            "epoch 91 | loss: 3245264973.16968|  0:31:01s\n",
            "epoch 21 | loss: 13673963440.05776|  0:06:28s\n",
            "epoch 88 | loss: 12191183868.30325|  0:30:39s\n",
            "epoch 20 | loss: 4391486263.91336|  0:06:46s\n",
            "epoch 91 | loss: 10714657382.12274|  0:31:28s\n",
            "epoch 25 | loss: 12056998293.25632|  0:08:34s\n",
            "epoch 92 | loss: 3165972056.49097|  0:31:12s\n",
            "epoch 22 | loss: 13698932491.55234|  0:06:40s\n",
            "epoch 89 | loss: 12373089603.69674|  0:30:50s\n",
            "epoch 21 | loss: 4377623246.09386|  0:06:58s\n",
            "epoch 92 | loss: 10432980499.40794|  0:31:39s\n",
            "epoch 93 | loss: 3366735379.87004|  0:31:23s\n",
            "epoch 26 | loss: 11908587615.19134|  0:08:47s\n",
            "epoch 90 | loss: 12197756653.74729|  0:31:01s\n",
            "epoch 23 | loss: 13501380341.83393|  0:06:52s\n",
            "epoch 93 | loss: 10491045576.08664|  0:31:50s\n",
            "epoch 22 | loss: 4544630933.94946|  0:07:10s\n",
            "epoch 94 | loss: 3323455619.00361|  0:31:34s\n",
            "epoch 91 | loss: 12074671879.39349|  0:31:12s\n",
            "epoch 27 | loss: 11885341218.65704|  0:09:00s\n",
            "epoch 24 | loss: 13702392185.99278|  0:07:03s\n",
            "epoch 94 | loss: 10471381831.62455|  0:32:01s\n",
            "epoch 23 | loss: 4340601380.50541|  0:07:23s\n",
            "epoch 95 | loss: 3303113183.65343|  0:31:45s\n",
            "epoch 92 | loss: 12200957945.53069|  0:31:23s\n",
            "epoch 28 | loss: 11822594037.83393|  0:09:12s\n",
            "epoch 25 | loss: 13428158195.06138|  0:07:15s\n",
            "epoch 95 | loss: 10278045359.82672|  0:32:12s\n",
            "epoch 24 | loss: 4377584264.54873|  0:07:36s\n",
            "epoch 96 | loss: 3235529077.60289|  0:31:57s\n",
            "epoch 93 | loss: 12160356074.97472|  0:31:35s\n",
            "epoch 26 | loss: 13510951111.16246|  0:07:27s\n",
            "epoch 96 | loss: 10542108136.66426|  0:32:24s\n",
            "epoch 29 | loss: 11818905459.06136|  0:09:25s\n",
            "epoch 25 | loss: 4300474763.55235|  0:07:49s\n",
            "epoch 97 | loss: 3183575966.49819|  0:32:08s\n",
            "epoch 94 | loss: 12162848909.16968|  0:31:47s\n",
            "epoch 97 | loss: 10304091751.74007|  0:32:37s\n",
            "epoch 27 | loss: 13443561601.61733|  0:07:40s\n",
            "epoch 30 | loss: 11693227135.76895|  0:09:40s\n",
            "epoch 98 | loss: 2966824901.54513|  0:32:21s\n",
            "epoch 26 | loss: 4176341671.04693|  0:08:03s\n",
            "epoch 95 | loss: 12289594610.36822|  0:32:00s\n",
            "epoch 98 | loss: 10568508893.574|  0:32:50s\n",
            "epoch 28 | loss: 13295289281.61733|  0:07:53s\n",
            "epoch 31 | loss: 11652192071.62454|  0:09:55s\n",
            "epoch 99 | loss: 2914888194.07942|  0:32:33s\n",
            "epoch 27 | loss: 4311076358.46931|  0:08:17s\n",
            "epoch 96 | loss: 12088882677.37184|  0:32:13s\n",
            "epoch 99 | loss: 10648388352.69314|  0:33:03s\n",
            "epoch 29 | loss: 13283966807.79782|  0:08:07s\n",
            "epoch 32 | loss: 11688266458.80144|  0:10:10s\n",
            "epoch 97 | loss: 12133020241.79061|  0:32:27s\n",
            "epoch 28 | loss: 4178148907.89892|  0:08:33s\n",
            "epoch 30 | loss: 13183475048.20217|  0:08:21s\n",
            "[CV] END .....................................n_a=32, n_d=16; total time=33.0min\n",
            "epoch 33 | loss: 11707193767.27798|  0:10:27s\n",
            "epoch 98 | loss: 12265123230.03611|  0:32:41s\n",
            "epoch 29 | loss: 4261584843.78339|  0:08:49s\n",
            "[CV] END .....................................n_a=32, n_d=16; total time=33.5min\n",
            "epoch 31 | loss: 13106365274.1083|  0:08:35s\n",
            "epoch 99 | loss: 12376095893.94946|  0:32:51s\n",
            "epoch 34 | loss: 11470959269.8917|  0:10:38s\n",
            "epoch 30 | loss: 4138054189.74729|  0:09:01s\n",
            "epoch 32 | loss: 12930561194.74368|  0:08:45s\n",
            "epoch 35 | loss: 11532956982.98917|  0:10:50s\n",
            "epoch 31 | loss: 4161482014.49819|  0:09:12s\n",
            "epoch 33 | loss: 13079645555.52347|  0:08:56s\n",
            "[CV] END .....................................n_a=32, n_d=16; total time=33.2min\n",
            "epoch 36 | loss: 11464405756.76534|  0:11:02s\n",
            "epoch 34 | loss: 12890014136.37545|  0:09:06s\n",
            "epoch 32 | loss: 4140200940.12997|  0:09:23s\n",
            "epoch 37 | loss: 11377011409.55956|  0:11:11s\n",
            "epoch 35 | loss: 12897333650.25271|  0:09:15s\n",
            "epoch 33 | loss: 3982325035.43682|  0:09:33s\n",
            "epoch 38 | loss: 11384505516.36101|  0:11:21s\n",
            "epoch 36 | loss: 12886975003.72563|  0:09:24s\n",
            "epoch 34 | loss: 3854569195.89892|  0:09:42s\n",
            "epoch 39 | loss: 11326450105.29964|  0:11:30s\n",
            "epoch 37 | loss: 12717790557.80506|  0:09:33s\n",
            "epoch 35 | loss: 3835866515.63899|  0:09:52s\n",
            "epoch 38 | loss: 12973701645.40072|  0:09:42s\n",
            "epoch 40 | loss: 11327678495.42238|  0:11:40s\n",
            "epoch 36 | loss: 3858743157.60289|  0:10:02s\n",
            "epoch 39 | loss: 12628982358.1805|  0:09:51s\n",
            "epoch 41 | loss: 11173236851.98556|  0:11:50s\n",
            "epoch 37 | loss: 3768572628.10109|  0:10:11s\n",
            "epoch 40 | loss: 12569487469.51625|  0:10:00s\n",
            "epoch 42 | loss: 11131972574.0361|  0:12:00s\n",
            "epoch 38 | loss: 3662433299.87004|  0:10:21s\n",
            "epoch 41 | loss: 12523661389.40072|  0:10:09s\n",
            "epoch 43 | loss: 11158191552.69314|  0:12:09s\n",
            "epoch 39 | loss: 3662776199.3935|  0:10:31s\n",
            "epoch 42 | loss: 12434727126.41155|  0:10:18s\n",
            "epoch 44 | loss: 11174129997.16968|  0:12:19s\n",
            "epoch 40 | loss: 3541814871.1047|  0:10:41s\n",
            "epoch 43 | loss: 12492757901.86282|  0:10:27s\n",
            "epoch 45 | loss: 11092582592.0|  0:12:29s\n",
            "epoch 41 | loss: 3629544469.02527|  0:10:50s\n",
            "epoch 44 | loss: 12214407250.48376|  0:10:36s\n",
            "epoch 46 | loss: 11010988863.07581|  0:12:39s\n",
            "epoch 42 | loss: 3472477115.14801|  0:11:00s\n",
            "epoch 45 | loss: 12265098446.09386|  0:10:45s\n",
            "epoch 47 | loss: 11009587701.37185|  0:12:48s\n",
            "epoch 43 | loss: 3520612886.1805|  0:11:10s\n",
            "epoch 46 | loss: 12285298858.51264|  0:10:54s\n",
            "epoch 48 | loss: 10958600222.72924|  0:12:58s\n",
            "epoch 47 | loss: 12269952589.16967|  0:11:03s\n",
            "epoch 44 | loss: 3605840436.90975|  0:11:20s\n",
            "epoch 49 | loss: 10977931735.10469|  0:13:08s\n",
            "epoch 48 | loss: 12213695974.81589|  0:11:12s\n",
            "epoch 45 | loss: 3401483640.37545|  0:11:29s\n",
            "epoch 50 | loss: 11029803252.21661|  0:13:17s\n",
            "epoch 49 | loss: 12007562580.33213|  0:11:21s\n",
            "epoch 46 | loss: 3651671106.77256|  0:11:39s\n",
            "epoch 51 | loss: 10997752682.05054|  0:13:27s\n",
            "epoch 50 | loss: 11830134348.70758|  0:11:29s\n",
            "epoch 47 | loss: 3514815484.0722|  0:11:49s\n",
            "epoch 51 | loss: 12194118644.6787|  0:11:38s\n",
            "epoch 52 | loss: 11088360304.51985|  0:13:37s\n",
            "epoch 48 | loss: 3501532537.06859|  0:11:59s\n",
            "epoch 52 | loss: 12029248430.90253|  0:11:47s\n",
            "epoch 53 | loss: 10997670512.51985|  0:13:46s\n",
            "epoch 49 | loss: 3390342472.54874|  0:12:08s\n",
            "epoch 53 | loss: 11782429575.3935|  0:11:56s\n",
            "epoch 54 | loss: 10967204657.213|  0:13:56s\n",
            "epoch 50 | loss: 3167380673.84838|  0:12:18s\n",
            "epoch 54 | loss: 11808289718.52708|  0:12:05s\n",
            "epoch 55 | loss: 11068191150.90252|  0:14:05s\n",
            "epoch 51 | loss: 3341622363.03249|  0:12:27s\n",
            "epoch 55 | loss: 12373041827.81228|  0:12:13s\n",
            "epoch 56 | loss: 11115545696.11552|  0:14:14s\n",
            "epoch 52 | loss: 3250911068.64982|  0:12:36s\n",
            "epoch 56 | loss: 12094825347.4657|  0:12:22s\n",
            "epoch 57 | loss: 10834975308.01444|  0:14:23s\n",
            "epoch 53 | loss: 3252682366.61372|  0:12:45s\n",
            "epoch 57 | loss: 12252037104.05776|  0:12:31s\n",
            "epoch 58 | loss: 10705267839.76896|  0:14:32s\n",
            "epoch 54 | loss: 3187825583.13357|  0:12:54s\n",
            "epoch 58 | loss: 12098869492.90974|  0:12:39s\n",
            "epoch 59 | loss: 10685905090.07942|  0:14:41s\n",
            "epoch 55 | loss: 3158837854.72924|  0:13:04s\n",
            "epoch 59 | loss: 12010215423.53792|  0:12:48s\n",
            "epoch 60 | loss: 10635694113.03971|  0:14:50s\n",
            "epoch 60 | loss: 11821913782.75812|  0:12:56s\n",
            "epoch 56 | loss: 3134353079.91336|  0:13:13s\n",
            "epoch 61 | loss: 10554957053.92058|  0:14:59s\n",
            "epoch 61 | loss: 11735916451.81227|  0:13:05s\n",
            "epoch 57 | loss: 3188521941.25632|  0:13:22s\n",
            "epoch 62 | loss: 10674903366.70036|  0:15:09s\n",
            "epoch 62 | loss: 11696295504.63538|  0:13:14s\n",
            "epoch 58 | loss: 3215282867.75451|  0:13:31s\n",
            "epoch 63 | loss: 10609793858.54152|  0:15:18s\n",
            "epoch 63 | loss: 11945816398.787|  0:13:23s\n",
            "epoch 59 | loss: 3190929325.2852|  0:13:41s\n",
            "epoch 64 | loss: 10647920598.41155|  0:15:27s\n",
            "epoch 64 | loss: 11632765883.14802|  0:13:31s\n",
            "epoch 60 | loss: 3130809763.81228|  0:13:50s\n",
            "epoch 65 | loss: 10686869622.52708|  0:15:36s\n",
            "epoch 65 | loss: 11722091053.05416|  0:13:40s\n",
            "epoch 61 | loss: 3107851718.00722|  0:13:59s\n",
            "epoch 66 | loss: 10736846479.94224|  0:15:45s\n",
            "epoch 66 | loss: 11814148686.09386|  0:13:49s\n",
            "epoch 62 | loss: 3111276785.213|  0:14:08s\n",
            "epoch 67 | loss: 10667102253.74729|  0:15:54s\n",
            "epoch 67 | loss: 11711029935.13357|  0:13:58s\n",
            "epoch 63 | loss: 3031675900.30325|  0:14:17s\n",
            "epoch 68 | loss: 10590196702.4982|  0:16:04s\n",
            "epoch 68 | loss: 11550484577.73285|  0:14:07s\n",
            "epoch 64 | loss: 3025945787.37906|  0:14:27s\n",
            "epoch 69 | loss: 10682241006.90253|  0:16:13s\n",
            "epoch 69 | loss: 11928533947.37906|  0:14:15s\n",
            "epoch 65 | loss: 3041098108.53429|  0:14:36s\n",
            "epoch 70 | loss: 11772919168.69314|  0:14:24s\n",
            "epoch 70 | loss: 10898555283.63899|  0:16:22s\n",
            "epoch 66 | loss: 3067809944.25993|  0:14:45s\n",
            "epoch 71 | loss: 11505384511.5379|  0:14:33s\n",
            "epoch 71 | loss: 10596785270.29603|  0:16:31s\n",
            "epoch 67 | loss: 3195576166.12274|  0:14:54s\n",
            "epoch 72 | loss: 11361916476.30325|  0:14:42s\n",
            "epoch 72 | loss: 10587406802.7148|  0:16:40s\n",
            "epoch 68 | loss: 3038264290.65704|  0:15:03s\n",
            "epoch 73 | loss: 11380631171.00361|  0:14:50s\n",
            "epoch 73 | loss: 10558794181.31408|  0:16:49s\n",
            "epoch 69 | loss: 2994241280.92419|  0:15:13s\n",
            "epoch 74 | loss: 11515890944.92419|  0:14:59s\n",
            "epoch 74 | loss: 10485079099.14802|  0:16:59s\n",
            "epoch 70 | loss: 2942167841.03971|  0:15:22s\n",
            "epoch 75 | loss: 10960548483.4657|  0:15:08s\n",
            "epoch 75 | loss: 10538631965.34296|  0:17:08s\n",
            "epoch 71 | loss: 3028195262.61372|  0:15:31s\n",
            "epoch 76 | loss: 11481141483.43682|  0:15:17s\n",
            "epoch 76 | loss: 10327335215.82672|  0:17:18s\n",
            "epoch 72 | loss: 3123585744.63538|  0:15:41s\n",
            "epoch 77 | loss: 11692650170.22382|  0:15:26s\n",
            "epoch 77 | loss: 10533544557.05416|  0:17:27s\n",
            "epoch 73 | loss: 2936650784.34657|  0:15:50s\n",
            "epoch 78 | loss: 11142191228.53429|  0:15:35s\n",
            "epoch 78 | loss: 10504110832.05776|  0:17:36s\n",
            "epoch 74 | loss: 3074859370.51264|  0:15:59s\n",
            "epoch 79 | loss: 10997703756.01444|  0:15:44s\n",
            "epoch 79 | loss: 10446508937.24188|  0:17:45s\n",
            "epoch 75 | loss: 2917749933.2852|  0:16:08s\n",
            "epoch 80 | loss: 10978943610.91696|  0:15:52s\n",
            "epoch 80 | loss: 10451295254.18051|  0:17:54s\n",
            "epoch 81 | loss: 10847661080.02888|  0:16:01s\n",
            "epoch 76 | loss: 2986333538.65704|  0:16:17s\n",
            "epoch 81 | loss: 10545226981.66065|  0:18:03s\n",
            "epoch 82 | loss: 11738589161.3574|  0:16:10s\n",
            "epoch 77 | loss: 3114714436.38989|  0:16:27s\n",
            "epoch 82 | loss: 10519685655.56679|  0:18:13s\n",
            "epoch 83 | loss: 10705452111.48014|  0:16:19s\n",
            "epoch 78 | loss: 2926176771.9278|  0:16:36s\n",
            "epoch 83 | loss: 10450964310.41155|  0:18:22s\n",
            "epoch 84 | loss: 11406581548.82311|  0:16:27s\n",
            "epoch 79 | loss: 3833549559.22022|  0:16:45s\n",
            "epoch 84 | loss: 10368469990.12274|  0:18:31s\n",
            "epoch 85 | loss: 11619602901.71841|  0:16:36s\n",
            "epoch 80 | loss: 2980539409.55957|  0:16:55s\n",
            "epoch 85 | loss: 10348538899.1769|  0:18:40s\n",
            "epoch 86 | loss: 11104281223.3935|  0:16:45s\n",
            "epoch 81 | loss: 3146745046.6426|  0:17:04s\n",
            "epoch 86 | loss: 10490437038.20939|  0:18:49s\n",
            "epoch 87 | loss: 11503198620.64981|  0:16:54s\n",
            "epoch 82 | loss: 2944301392.86643|  0:17:13s\n",
            "epoch 87 | loss: 10493192557.97834|  0:18:59s\n",
            "epoch 88 | loss: 11006287768.49097|  0:17:03s\n",
            "epoch 83 | loss: 2881917552.7509|  0:17:22s\n",
            "epoch 88 | loss: 10216698057.70397|  0:19:08s\n",
            "epoch 89 | loss: 10806031297.84837|  0:17:11s\n",
            "epoch 84 | loss: 2908703537.44404|  0:17:31s\n",
            "epoch 89 | loss: 10221320829.68953|  0:19:18s\n",
            "epoch 90 | loss: 10511000205.16967|  0:17:21s\n",
            "epoch 85 | loss: 2759458344.89531|  0:17:41s\n",
            "epoch 90 | loss: 10343379098.1083|  0:19:27s\n",
            "epoch 91 | loss: 10665703901.11191|  0:17:30s\n",
            "epoch 86 | loss: 2855188273.90614|  0:17:50s\n",
            "epoch 91 | loss: 10340427576.6065|  0:19:36s\n",
            "epoch 92 | loss: 10504160015.94223|  0:17:39s\n",
            "epoch 87 | loss: 2710285851.03249|  0:18:00s\n",
            "epoch 93 | loss: 11467073045.94945|  0:17:47s\n",
            "epoch 92 | loss: 10172863092.6787|  0:19:45s\n",
            "epoch 88 | loss: 2851790805.02527|  0:18:09s\n",
            "epoch 94 | loss: 10870216393.01083|  0:17:56s\n",
            "epoch 93 | loss: 10343720042.28159|  0:19:54s\n",
            "epoch 89 | loss: 2782925465.64621|  0:18:18s\n",
            "epoch 95 | loss: 11212776411.49458|  0:18:05s\n",
            "epoch 94 | loss: 10523632700.5343|  0:20:04s\n",
            "epoch 90 | loss: 3261372836.27437|  0:18:27s\n",
            "epoch 96 | loss: 11183292355.4657|  0:18:14s\n",
            "epoch 95 | loss: 10315870820.50542|  0:20:13s\n",
            "epoch 91 | loss: 2842558946.88809|  0:18:36s\n",
            "epoch 97 | loss: 11170914931.75451|  0:18:22s\n",
            "epoch 96 | loss: 10329385877.02528|  0:20:22s\n",
            "epoch 92 | loss: 2726097806.09386|  0:18:45s\n",
            "epoch 98 | loss: 10721070248.66426|  0:18:31s\n",
            "epoch 97 | loss: 10179920317.92058|  0:20:31s\n",
            "epoch 93 | loss: 2824699210.62816|  0:18:54s\n",
            "epoch 99 | loss: 10783884994.77257|  0:18:40s\n",
            "epoch 98 | loss: 10412387174.81588|  0:20:41s\n",
            "epoch 94 | loss: 2785323192.83754|  0:19:04s\n",
            "epoch 99 | loss: 10254028976.98195|  0:20:51s\n",
            "epoch 95 | loss: 2680955153.32852|  0:19:14s\n",
            "[CV] END .....................................n_a=32, n_d=32; total time=19.1min\n",
            "epoch 96 | loss: 2703860019.52347|  0:19:24s\n",
            "[CV] END .....................................n_a=32, n_d=32; total time=21.2min\n",
            "epoch 97 | loss: 2790834745.06859|  0:19:33s\n",
            "epoch 98 | loss: 2827048124.76534|  0:19:41s\n",
            "epoch 99 | loss: 3123226803.52347|  0:19:48s\n",
            "[CV] END .....................................n_a=32, n_d=32; total time=20.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19820568640.1542|  0:00:20s\n",
            "epoch 1  | loss: 16241483879.63374|  0:00:41s\n",
            "epoch 2  | loss: 13343661688.90602|  0:01:02s\n",
            "epoch 3  | loss: 11734186776.98314|  0:01:23s\n",
            "epoch 4  | loss: 11111544325.24339|  0:01:44s\n",
            "epoch 5  | loss: 10945840894.76625|  0:02:05s\n",
            "epoch 6  | loss: 10825096565.51324|  0:02:26s\n",
            "epoch 7  | loss: 10810686125.95663|  0:02:48s\n",
            "epoch 8  | loss: 10695388129.15662|  0:03:09s\n",
            "epoch 9  | loss: 10674908346.60241|  0:03:30s\n",
            "epoch 10 | loss: 10679847414.13012|  0:03:51s\n",
            "epoch 11 | loss: 10550010714.67952|  0:04:12s\n",
            "epoch 12 | loss: 10477058194.81446|  0:04:33s\n",
            "epoch 13 | loss: 10418448725.43614|  0:04:54s\n",
            "epoch 14 | loss: 10368084292.16384|  0:05:15s\n",
            "epoch 15 | loss: 10309924791.51806|  0:05:36s\n",
            "epoch 16 | loss: 10343394457.59999|  0:05:57s\n",
            "epoch 17 | loss: 10290882369.38794|  0:06:18s\n",
            "epoch 18 | loss: 10270283683.46988|  0:06:39s\n",
            "epoch 19 | loss: 10386261066.33253|  0:06:59s\n",
            "epoch 20 | loss: 10239995017.56144|  0:07:20s\n",
            "epoch 21 | loss: 10240650845.76385|  0:07:41s\n",
            "epoch 22 | loss: 10438177845.66747|  0:08:02s\n",
            "epoch 23 | loss: 10314739700.58796|  0:08:22s\n",
            "epoch 24 | loss: 10154422892.7229|  0:08:43s\n",
            "epoch 25 | loss: 10148371868.68433|  0:09:04s\n",
            "epoch 26 | loss: 10055819230.38072|  0:09:25s\n",
            "epoch 27 | loss: 10000767825.73494|  0:09:45s\n",
            "epoch 28 | loss: 9986026241.85061|  0:10:06s\n",
            "epoch 29 | loss: 9942628621.87953|  0:10:27s\n",
            "epoch 30 | loss: 9942452461.80241|  0:10:48s\n",
            "epoch 31 | loss: 9826146922.40964|  0:11:09s\n",
            "epoch 32 | loss: 9784030648.75181|  0:11:30s\n",
            "epoch 33 | loss: 9705017477.86024|  0:11:51s\n",
            "epoch 34 | loss: 9574975789.33976|  0:12:12s\n",
            "epoch 35 | loss: 9445082618.29398|  0:12:33s\n",
            "epoch 36 | loss: 9489546936.44337|  0:12:53s\n",
            "epoch 37 | loss: 9466923022.80482|  0:13:14s\n",
            "epoch 38 | loss: 9386440285.14698|  0:13:35s\n",
            "epoch 39 | loss: 9331093798.55422|  0:13:56s\n",
            "epoch 40 | loss: 9332363813.93735|  0:14:17s\n",
            "epoch 41 | loss: 9344382845.53252|  0:14:38s\n",
            "epoch 42 | loss: 9184986541.03132|  0:14:59s\n",
            "epoch 43 | loss: 9264807978.56386|  0:15:20s\n",
            "epoch 44 | loss: 9148794167.98072|  0:15:41s\n",
            "epoch 45 | loss: 9127244612.6265|  0:16:02s\n",
            "epoch 46 | loss: 9147454623.76867|  0:16:24s\n",
            "epoch 47 | loss: 8955427961.21446|  0:16:45s\n",
            "epoch 48 | loss: 8962193668.4723|  0:17:06s\n",
            "epoch 49 | loss: 9072252229.86024|  0:17:27s\n",
            "epoch 50 | loss: 9116561660.2988|  0:17:48s\n",
            "epoch 51 | loss: 8993314944.61687|  0:18:08s\n",
            "epoch 52 | loss: 8772617094.32288|  0:18:29s\n",
            "epoch 53 | loss: 8898937352.94458|  0:18:50s\n",
            "epoch 54 | loss: 8710224453.24337|  0:19:11s\n",
            "epoch 55 | loss: 8797481842.12048|  0:19:32s\n",
            "epoch 56 | loss: 8693864740.08674|  0:19:53s\n",
            "epoch 57 | loss: 8773434316.18314|  0:20:14s\n",
            "epoch 58 | loss: 8861944829.68675|  0:20:35s\n",
            "epoch 59 | loss: 8819138956.33735|  0:20:56s\n",
            "epoch 60 | loss: 8894536653.57108|  0:21:16s\n",
            "epoch 61 | loss: 8764269396.51084|  0:21:37s\n",
            "epoch 62 | loss: 8928099502.41928|  0:21:58s\n",
            "epoch 63 | loss: 8799078715.06506|  0:22:19s\n",
            "epoch 64 | loss: 8755803029.89879|  0:22:40s\n",
            "epoch 65 | loss: 8613584423.32531|  0:23:00s\n",
            "epoch 66 | loss: 8687079903.46024|  0:23:21s\n",
            "epoch 67 | loss: 8856332361.71566|  0:23:42s\n",
            "epoch 68 | loss: 8796859350.20723|  0:24:03s\n",
            "epoch 69 | loss: 8661717923.16144|  0:24:24s\n",
            "epoch 70 | loss: 8810684639.61447|  0:24:45s\n",
            "epoch 71 | loss: 8631594289.81206|  0:25:06s\n",
            "epoch 72 | loss: 8630494389.66747|  0:25:27s\n",
            "epoch 73 | loss: 8858412698.06266|  0:25:48s\n",
            "epoch 74 | loss: 8688189854.99758|  0:26:08s\n",
            "epoch 75 | loss: 8584499704.75181|  0:26:30s\n",
            "epoch 76 | loss: 8632620890.52529|  0:26:50s\n",
            "epoch 77 | loss: 8552737608.17349|  0:27:11s\n",
            "epoch 78 | loss: 8550992236.26024|  0:27:32s\n",
            "epoch 79 | loss: 7983814304.23132|  0:27:53s\n",
            "epoch 80 | loss: 8528016030.53495|  0:28:15s\n",
            "epoch 81 | loss: 8570490030.11084|  0:28:35s\n",
            "epoch 82 | loss: 8551364284.45301|  0:28:57s\n",
            "epoch 83 | loss: 8610422792.79035|  0:29:17s\n",
            "epoch 84 | loss: 8495970900.04818|  0:29:38s\n",
            "epoch 85 | loss: 8536939549.91807|  0:30:00s\n",
            "epoch 86 | loss: 8522346889.0988|  0:30:21s\n",
            "epoch 87 | loss: 8482350807.59518|  0:30:42s\n",
            "epoch 88 | loss: 8473630873.13734|  0:31:03s\n",
            "epoch 89 | loss: 8476403045.16627|  0:31:24s\n",
            "epoch 90 | loss: 8780618580.51083|  0:31:46s\n",
            "epoch 91 | loss: 8786894860.02891|  0:32:06s\n",
            "epoch 92 | loss: 8555555332.31807|  0:32:27s\n",
            "epoch 93 | loss: 8487915415.59519|  0:32:48s\n",
            "epoch 94 | loss: 8427007953.58072|  0:33:09s\n",
            "epoch 95 | loss: 8470882702.95903|  0:33:31s\n",
            "epoch 96 | loss: 8399289531.68192|  0:33:51s\n",
            "epoch 97 | loss: 8689455116.49157|  0:34:12s\n",
            "epoch 98 | loss: 8465197219.31567|  0:34:34s\n",
            "epoch 99 | loss: 8331150159.5759|  0:34:55s\n",
            "Лучшие параметры: {'n_a': 16, 'n_d': 32}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_d': [8, 16, 32],\n",
        "    'n_a': [8, 16, 32],\n",
        "}\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_d=8, n_a=8, n_steps=3, gamma=1.3, lambda_sparse=1e-3):\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.lambda_sparse = lambda_sparse\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = TabNetRegressor(\n",
        "            n_d=self.n_d,\n",
        "            n_a=self.n_a,\n",
        "            n_steps=self.n_steps,\n",
        "            gamma=self.gamma,\n",
        "            lambda_sparse=self.lambda_sparse\n",
        "        )\n",
        "        self.model.fit(X, y.reshape(-1, 1))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "model = TabNetWrapper()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Лучшие параметры: {best_params}')\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Лучшие параметры: {'n_a': 16, 'n_d': 32}**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19820567183.3192| train_rmse: 135170.19315| train_mae: 77867.30842| train_smape: 154.20288| val_rmse: 107906.39375| val_mae: 77731.56598| val_smape: 154.34046|  0:00:35s\n",
            "epoch 10 | loss: 10496793579.30539| train_rmse: 104344.39755| train_mae: 33103.92994| train_smape: 36.18144| val_rmse: 66377.65427| val_mae: 33287.79646| val_smape: 36.37324|  0:06:20s\n",
            "epoch 20 | loss: 10003760335.19862| train_rmse: 97519.3647| train_mae: 26248.48871| train_smape: 29.30686| val_rmse: 56525.99217| val_mae: 26885.14425| val_smape: 29.73279|  0:12:07s\n",
            "epoch 30 | loss: 9397602219.5805| train_rmse: 95882.75162| train_mae: 25912.13837| train_smape: 29.05449| val_rmse: 56032.58119| val_mae: 26569.36553| val_smape: 29.50505|  0:17:57s\n",
            "epoch 40 | loss: 9488302470.75909| train_rmse: 99105.53911| train_mae: 24811.23621| train_smape: 27.64644| val_rmse: 63068.17146| val_mae: 25691.85036| val_smape: 28.25153|  0:24:00s\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 40 and best_val_smape = 28.25153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Корень из среднеквадратичной ошибки (RMSE): 52115.99526369916\n",
            "R² Score: 0.4808516580807556\n",
            "Средняя абсолютная ошибка (MAE): 25400.790932474767\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 28.22%\n",
            "Медианная абсолютная ошибка (MedAE): 15666.015625\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.to_numpy()\n",
        "X_val = X_val.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "\n",
        "y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "y_val = y_val.to_numpy().reshape(-1, 1)\n",
        "y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "class SMAPE(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"smape\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        return 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tabnet_params = {\n",
        "    \"n_d\": 32,\n",
        "    \"n_a\": 16,\n",
        "    \"n_steps\": 3,\n",
        "    \"gamma\": 1.3,\n",
        "    \"lambda_sparse\": 1e-3,\n",
        "    \"optimizer_fn\": torch.optim.Adam,\n",
        "    \"optimizer_params\": dict(lr=2e-2),\n",
        "    \"mask_type\": \"sparsemax\",\n",
        "    \"scheduler_params\": dict(\n",
        "        mode=\"min\",\n",
        "        patience=5,\n",
        "        min_lr=1e-5,\n",
        "        factor=0.9,\n",
        "    ),\n",
        "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    \"seed\": 42,\n",
        "    \"verbose\": 10\n",
        "}\n",
        "\n",
        "model = TabNetRegressor(**tabnet_params, device_name=device)\n",
        "\n",
        "model.fit(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['rmse', 'mae', SMAPE],\n",
        "    max_epochs=50,\n",
        "    patience=20,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    loss_fn=torch.nn.functional.mse_loss,\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**n_steps**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 22307453353.12635|  0:00:12s\n",
            "epoch 0  | loss: 14545542853.77618|  0:00:12s\n",
            "epoch 0  | loss: 24063471752.77978|  0:00:12s\n",
            "epoch 0  | loss: 14211333236.44765|  0:00:19s\n",
            "epoch 0  | loss: 23716392074.62816|  0:00:19s\n",
            "epoch 0  | loss: 22035906833.55956|  0:00:19s\n",
            "epoch 1  | loss: 20336620939.55234|  0:00:25s\n",
            "epoch 1  | loss: 12534460543.53791|  0:00:25s\n",
            "epoch 1  | loss: 22058236759.79783|  0:00:25s\n",
            "epoch 0  | loss: 13843569699.11914|  0:00:28s\n",
            "epoch 0  | loss: 23365600200.54874|  0:00:28s\n",
            "epoch 0  | loss: 21634232000.23104|  0:00:28s\n",
            "epoch 2  | loss: 18283962499.23466|  0:00:38s\n",
            "epoch 2  | loss: 19692934515.52346|  0:00:38s\n",
            "epoch 2  | loss: 10076036471.22022|  0:00:38s\n",
            "epoch 1  | loss: 20159978052.38989|  0:00:39s\n",
            "epoch 1  | loss: 18783244204.82311|  0:00:40s\n",
            "epoch 1  | loss: 11116918460.5343|  0:00:40s\n",
            "epoch 3  | loss: 17789606642.13718|  0:00:51s\n",
            "epoch 3  | loss: 16454063958.87365|  0:00:51s\n",
            "epoch 3  | loss: 8059575203.58123|  0:00:51s\n",
            "epoch 1  | loss: 9643488258.77256|  0:00:57s\n",
            "epoch 1  | loss: 17076684194.65704|  0:00:57s\n",
            "epoch 1  | loss: 18758376502.52709|  0:00:58s\n",
            "epoch 2  | loss: 17189577006.2094|  0:00:59s\n",
            "epoch 2  | loss: 15806499206.93142|  0:01:00s\n",
            "epoch 2  | loss: 8250744877.2852|  0:01:01s\n",
            "epoch 4  | loss: 15010046738.48376|  0:01:03s\n",
            "epoch 4  | loss: 6660595047.50902|  0:01:04s\n",
            "epoch 4  | loss: 16551009645.05416|  0:01:04s\n",
            "epoch 5  | loss: 14048071196.18773|  0:01:16s\n",
            "epoch 5  | loss: 5855028008.20216|  0:01:16s\n",
            "epoch 5  | loss: 15745201019.37904|  0:01:17s\n",
            "epoch 3  | loss: 15729566002.36822|  0:01:19s\n",
            "epoch 3  | loss: 6583094663.3935|  0:01:22s\n",
            "epoch 3  | loss: 14177514072.72203|  0:01:22s\n",
            "epoch 2  | loss: 14423552815.13357|  0:01:27s\n",
            "epoch 2  | loss: 6713247443.63899|  0:01:27s\n",
            "epoch 2  | loss: 15925517196.01445|  0:01:27s\n",
            "epoch 6  | loss: 13408261840.40435|  0:01:29s\n",
            "epoch 6  | loss: 5394726979.9278|  0:01:29s\n",
            "epoch 6  | loss: 15251380841.3574|  0:01:30s\n",
            "epoch 4  | loss: 15214767288.83755|  0:01:39s\n",
            "epoch 7  | loss: 13094407846.81589|  0:01:42s\n",
            "epoch 7  | loss: 5239422587.84116|  0:01:42s\n",
            "epoch 4  | loss: 5752812269.97834|  0:01:43s\n",
            "epoch 7  | loss: 14899844281.76173|  0:01:43s\n",
            "epoch 4  | loss: 13390987427.58123|  0:01:43s\n",
            "epoch 8  | loss: 12888706968.49098|  0:01:55s\n",
            "epoch 8  | loss: 5120351879.3935|  0:01:55s\n",
            "epoch 3  | loss: 13708299117.97834|  0:01:55s\n",
            "epoch 3  | loss: 5984314619.37906|  0:01:56s\n",
            "epoch 8  | loss: 14671656036.27438|  0:01:56s\n",
            "epoch 3  | loss: 15516255883.09024|  0:01:57s\n",
            "epoch 5  | loss: 15032560179.29242|  0:01:59s\n",
            "epoch 5  | loss: 5514570024.66426|  0:02:03s\n",
            "epoch 5  | loss: 13117865794.54151|  0:02:04s\n",
            "epoch 9  | loss: 12793103444.10108|  0:02:08s\n",
            "epoch 9  | loss: 5087772681.24188|  0:02:08s\n",
            "epoch 9  | loss: 14558887286.75812|  0:02:09s\n",
            "epoch 6  | loss: 14896189238.52709|  0:02:20s\n",
            "epoch 10 | loss: 5018488874.97473|  0:02:21s\n",
            "epoch 10 | loss: 12673374826.74369|  0:02:21s\n",
            "epoch 10 | loss: 14405743633.55957|  0:02:22s\n",
            "epoch 6  | loss: 5407119975.97112|  0:02:24s\n",
            "epoch 6  | loss: 13000948111.2491|  0:02:25s\n",
            "epoch 4  | loss: 5808085683.75451|  0:02:26s\n",
            "epoch 4  | loss: 13473428226.31046|  0:02:26s\n",
            "epoch 4  | loss: 15309631266.19495|  0:02:26s\n",
            "epoch 11 | loss: 4973970993.44404|  0:02:34s\n",
            "epoch 11 | loss: 12636257483.3213|  0:02:34s\n",
            "epoch 11 | loss: 14380242550.75812|  0:02:35s\n",
            "epoch 7  | loss: 14867008326.23827|  0:02:40s\n",
            "epoch 7  | loss: 5330951568.17329|  0:02:46s\n",
            "epoch 7  | loss: 12947456962.54152|  0:02:46s\n",
            "epoch 12 | loss: 4961723915.55235|  0:02:47s\n",
            "epoch 12 | loss: 12628434808.1444|  0:02:47s\n",
            "epoch 12 | loss: 14344029404.88086|  0:02:48s\n",
            "epoch 5  | loss: 13421929662.38267|  0:02:55s\n",
            "epoch 5  | loss: 5705375942.70036|  0:02:56s\n",
            "epoch 5  | loss: 15196644928.23105|  0:02:56s\n",
            "epoch 13 | loss: 4919065314.42599|  0:03:00s\n",
            "epoch 13 | loss: 12571602953.24188|  0:03:01s\n",
            "epoch 8  | loss: 14818050158.44044|  0:03:01s\n",
            "epoch 13 | loss: 14312770492.53429|  0:03:02s\n",
            "epoch 8  | loss: 5267332783.13358|  0:03:07s\n",
            "epoch 8  | loss: 12908639513.41515|  0:03:07s\n",
            "epoch 14 | loss: 4934870548.33213|  0:03:13s\n",
            "epoch 14 | loss: 12530832328.54874|  0:03:13s\n",
            "epoch 14 | loss: 14310702454.29602|  0:03:15s\n",
            "epoch 9  | loss: 14805900818.94586|  0:03:21s\n",
            "epoch 6  | loss: 5610131853.40072|  0:03:25s\n",
            "epoch 6  | loss: 13303075791.01806|  0:03:25s\n",
            "epoch 6  | loss: 15093486498.19494|  0:03:26s\n",
            "epoch 15 | loss: 4824665270.98917|  0:03:26s\n",
            "epoch 15 | loss: 12451270930.48375|  0:03:26s\n",
            "epoch 15 | loss: 14269075888.51985|  0:03:28s\n",
            "epoch 9  | loss: 5228012678.46931|  0:03:28s\n",
            "epoch 9  | loss: 12848199866.22382|  0:03:29s\n",
            "epoch 16 | loss: 4794896874.28159|  0:03:38s\n",
            "epoch 16 | loss: 12517414713.76173|  0:03:39s\n",
            "epoch 16 | loss: 14267803396.15884|  0:03:41s\n",
            "epoch 10 | loss: 14736928400.63538|  0:03:42s\n",
            "epoch 10 | loss: 5142439553.38628|  0:03:49s\n",
            "epoch 10 | loss: 12788773610.74368|  0:03:50s\n",
            "epoch 17 | loss: 4797079036.76534|  0:03:52s\n",
            "epoch 17 | loss: 12475100544.0|  0:03:53s\n",
            "epoch 17 | loss: 14161621423.13357|  0:03:56s\n",
            "epoch 7  | loss: 14982561863.16247|  0:03:56s\n",
            "epoch 7  | loss: 5500188378.1083|  0:03:57s\n",
            "epoch 7  | loss: 13354583123.63899|  0:03:58s\n",
            "epoch 11 | loss: 14682205699.23466|  0:04:05s\n",
            "epoch 18 | loss: 4672646165.25632|  0:04:07s\n",
            "epoch 18 | loss: 12338105002.05054|  0:04:09s\n",
            "epoch 18 | loss: 14139774935.79784|  0:04:11s\n",
            "epoch 11 | loss: 5114547229.574|  0:04:15s\n",
            "epoch 11 | loss: 12799364796.0722|  0:04:16s\n",
            "epoch 19 | loss: 4616164836.73646|  0:04:22s\n",
            "epoch 19 | loss: 12371782910.61372|  0:04:23s\n",
            "epoch 19 | loss: 14008000125.68951|  0:04:26s\n",
            "epoch 12 | loss: 14619225144.37545|  0:04:29s\n",
            "epoch 8  | loss: 14911281737.93501|  0:04:31s\n",
            "epoch 8  | loss: 5407525851.49459|  0:04:31s\n",
            "epoch 8  | loss: 13282582109.80505|  0:04:33s\n",
            "epoch 20 | loss: 4635171347.87004|  0:04:36s\n",
            "epoch 20 | loss: 12376956025.0686|  0:04:37s\n",
            "epoch 12 | loss: 12727948383.19134|  0:04:39s\n",
            "epoch 12 | loss: 5069991635.17689|  0:04:39s\n",
            "epoch 20 | loss: 14052989997.74729|  0:04:40s\n",
            "epoch 21 | loss: 4616771238.81588|  0:04:50s\n",
            "epoch 13 | loss: 14634139404.47652|  0:04:50s\n",
            "epoch 21 | loss: 12227914791.74007|  0:04:51s\n",
            "epoch 21 | loss: 13841204736.00001|  0:04:53s\n",
            "epoch 13 | loss: 12712547108.50542|  0:05:01s\n",
            "epoch 13 | loss: 4971256677.66065|  0:05:01s\n",
            "epoch 9  | loss: 5574055758.09386|  0:05:02s\n",
            "epoch 9  | loss: 14742109743.59567|  0:05:02s\n",
            "epoch 22 | loss: 4575240361.58845|  0:05:03s\n",
            "epoch 22 | loss: 12237489190.81588|  0:05:04s\n",
            "epoch 9  | loss: 13259216256.92419|  0:05:04s\n",
            "epoch 22 | loss: 13917010818.31046|  0:05:06s\n",
            "epoch 14 | loss: 14597784897.61733|  0:05:11s\n",
            "epoch 23 | loss: 4567088513.15523|  0:05:15s\n",
            "epoch 23 | loss: 12182395518.61371|  0:05:16s\n",
            "epoch 23 | loss: 13930255694.55595|  0:05:19s\n",
            "epoch 14 | loss: 12627676806.46932|  0:05:21s\n",
            "epoch 14 | loss: 4975050298.22383|  0:05:21s\n",
            "epoch 24 | loss: 4505406561.5018|  0:05:28s\n",
            "epoch 24 | loss: 12272507947.89892|  0:05:29s\n",
            "epoch 15 | loss: 14604578295.22022|  0:05:30s\n",
            "epoch 10 | loss: 5567628886.41155|  0:05:31s\n",
            "epoch 10 | loss: 14635463460.50541|  0:05:31s\n",
            "epoch 24 | loss: 13963789889.61734|  0:05:32s\n",
            "epoch 10 | loss: 13370944505.99279|  0:05:32s\n",
            "epoch 25 | loss: 4438205324.01444|  0:05:41s\n",
            "epoch 25 | loss: 12158221253.77617|  0:05:42s\n",
            "epoch 15 | loss: 12623541719.33574|  0:05:42s\n",
            "epoch 15 | loss: 4947531952.98195|  0:05:42s\n",
            "epoch 25 | loss: 13817706886.00722|  0:05:45s\n",
            "epoch 16 | loss: 14581838586.45488|  0:05:50s\n",
            "epoch 26 | loss: 4353919737.53068|  0:05:53s\n",
            "epoch 26 | loss: 12196510091.09025|  0:05:54s\n",
            "epoch 26 | loss: 13789844030.38267|  0:05:57s\n",
            "epoch 11 | loss: 14583965594.80144|  0:06:00s\n",
            "epoch 11 | loss: 5573302399.53791|  0:06:01s\n",
            "epoch 11 | loss: 13342995144.54872|  0:06:02s\n",
            "epoch 16 | loss: 12562809536.23104|  0:06:02s\n",
            "epoch 16 | loss: 4913502055.04693|  0:06:03s\n",
            "epoch 27 | loss: 4370483308.12997|  0:06:06s\n",
            "epoch 27 | loss: 12055216811.89892|  0:06:07s\n",
            "epoch 17 | loss: 14551075971.69675|  0:06:10s\n",
            "epoch 27 | loss: 13701352712.31769|  0:06:10s\n",
            "epoch 28 | loss: 4323618278.58484|  0:06:18s\n",
            "epoch 28 | loss: 12017694406.70036|  0:06:20s\n",
            "epoch 28 | loss: 13733212175.71119|  0:06:23s\n",
            "epoch 17 | loss: 12568628545.15523|  0:06:23s\n",
            "epoch 17 | loss: 4844345468.76534|  0:06:23s\n",
            "epoch 12 | loss: 14537699828.44764|  0:06:54s\n",
            "epoch 18 | loss: 14460724311.79783|  0:06:55s\n",
            "epoch 12 | loss: 5570325749.37184|  0:06:56s\n",
            "epoch 12 | loss: 13367551297.15524|  0:06:56s\n",
            "epoch 29 | loss: 4549184384.46209|  0:06:56s\n",
            "epoch 29 | loss: 12014554062.787|  0:06:58s\n",
            "epoch 29 | loss: 13713641141.60288|  0:07:03s\n",
            "epoch 18 | loss: 12576036561.32852|  0:07:11s\n",
            "epoch 30 | loss: 4433587756.36101|  0:07:11s\n",
            "epoch 18 | loss: 4804396719.13357|  0:07:11s\n",
            "epoch 30 | loss: 12027829978.1083|  0:07:13s\n",
            "epoch 30 | loss: 13989809473.15524|  0:07:15s\n",
            "epoch 19 | loss: 14415215137.27076|  0:07:16s\n",
            "epoch 31 | loss: 4322947293.34296|  0:07:23s\n",
            "epoch 31 | loss: 11925588182.87364|  0:07:25s\n",
            "epoch 13 | loss: 14443667671.79784|  0:07:26s\n",
            "epoch 13 | loss: 13388465748.56317|  0:07:27s\n",
            "epoch 13 | loss: 5573520113.21299|  0:07:27s\n",
            "epoch 31 | loss: 13882327736.83755|  0:07:28s\n",
            "epoch 19 | loss: 12437917763.46571|  0:07:31s\n",
            "epoch 19 | loss: 4758248253.45848|  0:07:31s\n",
            "epoch 20 | loss: 14265078820.50541|  0:07:35s\n",
            "epoch 32 | loss: 4278577407.5379|  0:07:36s\n",
            "epoch 32 | loss: 11936384371.06137|  0:07:38s\n",
            "epoch 32 | loss: 13666691686.58484|  0:23:06s\n",
            "epoch 33 | loss: 4117192518.23827|  0:23:13s\n",
            "epoch 33 | loss: 11809738377.93503|  0:23:16s\n",
            "epoch 20 | loss: 12421681772.59206|  0:23:16s\n",
            "epoch 20 | loss: 4853815806.15162|  0:23:17s\n",
            "epoch 33 | loss: 13685273654.98917|  0:23:18s\n",
            "epoch 14 | loss: 14420405571.4657|  0:23:19s\n",
            "epoch 21 | loss: 14261133848.02887|  0:23:20s\n",
            "epoch 14 | loss: 5575520951.91336|  0:23:21s\n",
            "epoch 14 | loss: 13222634808.37545|  0:23:22s\n",
            "epoch 34 | loss: 4205785524.21661|  0:23:26s\n",
            "epoch 34 | loss: 11706515480.49098|  0:23:28s\n",
            "epoch 34 | loss: 13559598483.87004|  0:23:31s\n",
            "epoch 21 | loss: 12391939059.06138|  0:23:36s\n",
            "epoch 21 | loss: 5211563069.92058|  0:23:37s\n",
            "epoch 35 | loss: 4079152192.69314|  0:23:38s\n",
            "epoch 22 | loss: 14236148535.45126|  0:23:40s\n",
            "epoch 35 | loss: 11650626769.32852|  0:23:40s\n",
            "epoch 35 | loss: 13392460721.90614|  0:23:43s\n",
            "epoch 15 | loss: 14411904682.97473|  0:23:47s\n",
            "epoch 15 | loss: 5582327092.6787|  0:23:49s\n",
            "epoch 36 | loss: 3949973243.37906|  0:23:51s\n",
            "epoch 15 | loss: 13032768676.50542|  0:23:51s\n",
            "epoch 36 | loss: 11596533845.48736|  0:23:53s\n",
            "epoch 36 | loss: 13191504360.20217|  0:23:55s\n",
            "epoch 22 | loss: 5175624710.93141|  0:23:56s\n",
            "epoch 22 | loss: 12380329689.18412|  0:23:56s\n",
            "epoch 23 | loss: 14325273519.59567|  0:23:59s\n",
            "epoch 37 | loss: 3815934496.34657|  0:24:03s\n",
            "epoch 37 | loss: 11595115525.54512|  0:24:05s\n",
            "epoch 37 | loss: 13125132464.51986|  0:39:33s\n",
            "epoch 23 | loss: 5255994481.213|  0:39:41s\n",
            "epoch 38 | loss: 3794628051.17689|  0:39:41s\n",
            "epoch 16 | loss: 14330990813.34295|  0:39:41s\n",
            "epoch 23 | loss: 12343289960.89532|  0:39:41s\n",
            "epoch 38 | loss: 11531430865.79062|  0:39:43s\n",
            "epoch 16 | loss: 5588185174.41155|  0:39:44s\n",
            "epoch 24 | loss: 14267570724.9675|  0:39:44s\n",
            "epoch 16 | loss: 12967971357.57401|  0:39:45s\n",
            "epoch 38 | loss: 13255959853.97832|  0:39:46s\n",
            "epoch 39 | loss: 3855522613.60289|  0:39:54s\n",
            "epoch 39 | loss: 11580617364.79422|  0:39:55s\n",
            "epoch 39 | loss: 13060813907.1769|  0:39:58s\n",
            "epoch 24 | loss: 5469105270.29603|  0:40:01s\n",
            "epoch 24 | loss: 12260949177.0686|  0:40:02s\n",
            "epoch 25 | loss: 14312624545.73286|  0:40:04s\n",
            "epoch 40 | loss: 3962300913.21299|  0:40:07s\n",
            "epoch 40 | loss: 11414442554.45488|  0:40:08s\n",
            "epoch 17 | loss: 14320121623.56678|  0:40:11s\n",
            "epoch 40 | loss: 13366616112.51986|  0:40:11s\n",
            "epoch 17 | loss: 5579486616.49097|  0:40:13s\n",
            "epoch 17 | loss: 12891766533.54512|  0:40:15s\n",
            "epoch 41 | loss: 3577879097.53068|  0:40:19s\n",
            "epoch 41 | loss: 11368050379.3213|  0:55:46s\n",
            "epoch 25 | loss: 5562729813.48736|  0:55:46s\n",
            "epoch 25 | loss: 12295975959.56678|  0:55:47s\n",
            "epoch 26 | loss: 14233645013.94946|  0:55:49s\n",
            "epoch 41 | loss: 13303740526.44044|  0:55:49s\n",
            "epoch 42 | loss: 3606517637.54513|  0:55:57s\n",
            "epoch 42 | loss: 11206964776.43321|  0:55:58s\n",
            "epoch 42 | loss: 13261208076.93863|  0:56:01s\n",
            "epoch 18 | loss: 14267954986.51264|  0:56:04s\n",
            "epoch 26 | loss: 4957117275.03249|  0:56:06s\n",
            "epoch 26 | loss: 12235452966.81589|  0:56:07s\n",
            "epoch 18 | loss: 5585245677.05415|  0:56:07s\n",
            "epoch 27 | loss: 14147531952.98194|  0:56:08s\n",
            "epoch 43 | loss: 3774607268.04332|  0:56:09s\n",
            "epoch 18 | loss: 12827293827.23466|  0:56:09s\n",
            "epoch 43 | loss: 11409778133.94946|  0:56:10s\n",
            "epoch 43 | loss: 13146115718.46931|  0:56:14s\n",
            "epoch 44 | loss: 3544469008.17328|  0:56:22s\n",
            "epoch 44 | loss: 11006653992.20216|  0:56:23s\n",
            "epoch 44 | loss: 13032270693.66065|  0:56:26s\n",
            "epoch 27 | loss: 5618016566.52708|  0:56:26s\n",
            "epoch 27 | loss: 12181861092.73646|  0:56:27s\n",
            "epoch 28 | loss: 14133082418.83032|  0:56:27s\n",
            "epoch 19 | loss: 14299360082.2527|  1:11:58s\n",
            "epoch 45 | loss: 3685865209.99278|  1:12:00s\n",
            "epoch 45 | loss: 11502295724.8231|  1:12:00s\n",
            "epoch 19 | loss: 5597788478.84477|  1:12:02s\n",
            "epoch 19 | loss: 12722507034.80144|  1:12:03s\n",
            "epoch 45 | loss: 12999369774.20939|  1:12:04s\n",
            "epoch 28 | loss: 5918407285.83393|  1:12:12s\n",
            "epoch 29 | loss: 14085843411.63899|  1:12:12s\n",
            "epoch 46 | loss: 3519836947.87004|  1:12:12s\n",
            "epoch 28 | loss: 12163743720.8953|  1:12:13s\n",
            "epoch 46 | loss: 11012049899.43682|  1:12:13s\n",
            "epoch 46 | loss: 13040541020.88087|  1:12:16s\n",
            "epoch 47 | loss: 3446183108.38989|  1:12:25s\n",
            "epoch 47 | loss: 11178896966.00722|  1:12:25s\n",
            "epoch 20 | loss: 14162724476.30325|  1:12:28s\n",
            "epoch 47 | loss: 13273170217.12636|  1:12:29s\n",
            "epoch 29 | loss: 6038786575.2491|  1:12:31s\n",
            "epoch 30 | loss: 14067323689.58844|  1:12:32s\n",
            "epoch 20 | loss: 5601105434.33935|  1:12:32s\n",
            "epoch 20 | loss: 12715803960.37546|  1:12:32s\n",
            "epoch 29 | loss: 12350661172.21661|  1:12:33s\n",
            "epoch 48 | loss: 3498154368.46209|  1:12:38s\n",
            "epoch 48 | loss: 11083638412.01444|  1:12:38s\n",
            "epoch 48 | loss: 12861255166.61372|  1:12:41s\n",
            "epoch 49 | loss: 11062457512.20217|  1:12:50s\n",
            "epoch 49 | loss: 3473264465.79061|  1:12:51s\n",
            "epoch 31 | loss: 14030789499.37906|  1:12:51s\n",
            "epoch 30 | loss: 6115491966.61372|  1:12:51s\n",
            "epoch 30 | loss: 12243502775.91336|  1:12:53s\n",
            "epoch 49 | loss: 12714791755.78339|  1:12:54s\n",
            "epoch 21 | loss: 14106342005.37184|  1:12:58s\n",
            "epoch 21 | loss: 5595077975.33574|  1:13:02s\n",
            "epoch 21 | loss: 12655970887.62455|  1:13:02s\n",
            "epoch 50 | loss: 11012497546.16607|  1:13:03s\n",
            "epoch 50 | loss: 3503891872.80866|  1:13:03s\n",
            "epoch 50 | loss: 12786217221.54513|  1:13:06s\n",
            "epoch 32 | loss: 13953734360.72202|  1:13:11s\n",
            "epoch 31 | loss: 6214327130.5704|  1:13:11s\n",
            "epoch 31 | loss: 12183711276.36101|  1:13:13s\n",
            "epoch 51 | loss: 11194304413.11192|  1:13:15s\n",
            "epoch 51 | loss: 3340986620.76534|  1:13:16s\n",
            "epoch 51 | loss: 12954016250.91696|  1:13:19s\n",
            "epoch 22 | loss: 14082650990.90254|  1:13:28s\n",
            "epoch 52 | loss: 11292681286.23827|  1:13:28s\n",
            "epoch 52 | loss: 3489798649.06859|  1:13:29s\n",
            "epoch 33 | loss: 13950948839.04692|  1:13:31s\n",
            "epoch 22 | loss: 5590799045.31408|  1:13:31s\n",
            "epoch 52 | loss: 12594749868.59205|  1:13:31s\n",
            "epoch 22 | loss: 12605604955.49458|  1:13:31s\n",
            "epoch 32 | loss: 6233737752.95307|  1:13:32s\n",
            "epoch 32 | loss: 12043764371.87004|  1:13:33s\n",
            "epoch 53 | loss: 11050357495.45127|  1:13:41s\n",
            "epoch 53 | loss: 3597409209.29964|  1:13:42s\n",
            "epoch 53 | loss: 12685415463.27796|  1:13:44s\n",
            "epoch 34 | loss: 13870863068.18772|  1:13:51s\n",
            "epoch 33 | loss: 6235702219.3213|  1:13:52s\n",
            "epoch 54 | loss: 11164228890.33935|  1:13:53s\n",
            "epoch 33 | loss: 12033113189.66065|  1:13:54s\n",
            "epoch 54 | loss: 3701321568.57762|  1:13:55s\n",
            "epoch 54 | loss: 12424167243.3213|  1:13:57s\n",
            "epoch 23 | loss: 14004598332.0722|  1:13:57s\n",
            "epoch 23 | loss: 12529834686.38268|  1:14:01s\n",
            "epoch 23 | loss: 5600019516.5343|  1:14:01s\n",
            "epoch 55 | loss: 10972225172.79422|  1:14:06s\n",
            "epoch 55 | loss: 3147697345.15523|  1:14:08s\n",
            "epoch 55 | loss: 12544585100.01444|  1:14:09s\n",
            "epoch 35 | loss: 13800823809.84836|  1:14:11s\n",
            "epoch 34 | loss: 6196515672.72202|  1:14:13s\n",
            "epoch 34 | loss: 11945005590.6426|  1:14:14s\n",
            "epoch 56 | loss: 10867142387.98556|  1:14:19s\n",
            "epoch 56 | loss: 3354825802.85921|  1:14:21s\n",
            "epoch 56 | loss: 12482566443.89892|  1:14:22s\n",
            "epoch 24 | loss: 13973361376.57762|  1:14:27s\n",
            "epoch 24 | loss: 12498881226.3971|  1:14:31s\n",
            "epoch 36 | loss: 13741694589.22744|  1:14:31s\n",
            "epoch 57 | loss: 10712553940.10109|  1:14:32s\n",
            "epoch 24 | loss: 5595715829.37184|  1:14:32s\n",
            "epoch 35 | loss: 6213644108.70758|  1:14:34s\n",
            "epoch 57 | loss: 3735159648.80866|  1:14:34s\n",
            "epoch 57 | loss: 12473823718.81588|  1:14:35s\n",
            "epoch 35 | loss: 12032288501.83393|  1:14:35s\n",
            "epoch 58 | loss: 11128706307.69675|  1:14:45s\n",
            "epoch 58 | loss: 3215304585.47292|  1:14:47s\n",
            "epoch 58 | loss: 12510592242.59928|  1:14:48s\n",
            "epoch 37 | loss: 13689806172.88087|  1:14:52s\n",
            "epoch 36 | loss: 6254640281.41516|  1:14:55s\n",
            "epoch 36 | loss: 11861520261.08304|  1:14:56s\n",
            "epoch 25 | loss: 13922818721.27076|  1:14:57s\n",
            "epoch 59 | loss: 10811989291.43682|  1:14:58s\n",
            "epoch 59 | loss: 3159237120.4621|  1:15:01s\n",
            "epoch 59 | loss: 12556022071.91336|  1:15:01s\n",
            "epoch 25 | loss: 12478717051.84116|  1:15:01s\n",
            "epoch 25 | loss: 5588177246.26715|  1:15:02s\n",
            "epoch 60 | loss: 11123635602.02167|  1:15:11s\n",
            "epoch 38 | loss: 13658209292.01445|  1:15:13s\n",
            "epoch 60 | loss: 3325301193.47292|  1:15:14s\n",
            "epoch 60 | loss: 12555926925.40072|  1:15:14s\n",
            "epoch 37 | loss: 6251080525.63177|  1:15:16s\n",
            "epoch 37 | loss: 11853394156.12996|  1:15:18s\n",
            "epoch 61 | loss: 10786477891.23466|  1:15:24s\n",
            "epoch 61 | loss: 3205033013.1408|  1:15:27s\n",
            "epoch 26 | loss: 13806287370.62816|  1:15:28s\n",
            "epoch 61 | loss: 12525298581.71841|  1:15:28s\n",
            "epoch 26 | loss: 12472390274.77256|  1:15:32s\n",
            "epoch 26 | loss: 5600909895.62455|  1:15:33s\n",
            "epoch 39 | loss: 13638096251.84116|  1:15:34s\n",
            "epoch 38 | loss: 6240185510.35379|  1:15:38s\n",
            "epoch 62 | loss: 10600204081.44405|  1:15:38s\n",
            "epoch 38 | loss: 12015106872.83755|  1:15:40s\n",
            "epoch 62 | loss: 3123059258.91697|  1:15:41s\n",
            "epoch 62 | loss: 12475411261.45848|  1:15:41s\n",
            "epoch 63 | loss: 10913737750.41155|  1:15:51s\n",
            "epoch 63 | loss: 2935376070.23827|  1:15:55s\n",
            "epoch 63 | loss: 12531708251.95668|  1:15:55s\n",
            "epoch 40 | loss: 13660639321.6462|  1:15:56s\n",
            "epoch 27 | loss: 13794692208.2888|  1:16:00s\n",
            "epoch 39 | loss: 6293876138.05054|  1:16:00s\n",
            "epoch 39 | loss: 11977763767.45126|  1:16:01s\n",
            "epoch 27 | loss: 12412599898.1083|  1:16:04s\n",
            "epoch 64 | loss: 10752876419.23465|  1:16:05s\n",
            "epoch 27 | loss: 5565015289.06859|  1:16:06s\n",
            "epoch 64 | loss: 3190340812.01444|  1:16:09s\n",
            "epoch 64 | loss: 12637221110.29603|  1:16:09s\n",
            "epoch 41 | loss: 13509587686.58483|  1:16:18s\n",
            "epoch 65 | loss: 10786154237.22743|  1:16:19s\n",
            "epoch 40 | loss: 6223578093.51625|  1:16:22s\n",
            "epoch 65 | loss: 2949584346.5704|  1:16:23s\n",
            "epoch 65 | loss: 12441996759.33574|  1:16:23s\n",
            "epoch 40 | loss: 11939612548.15884|  1:16:24s\n",
            "epoch 28 | loss: 13705760810.05054|  1:16:32s\n",
            "epoch 66 | loss: 10811649459.29242|  1:16:33s\n",
            "epoch 28 | loss: 12339418465.03972|  1:16:36s\n",
            "epoch 66 | loss: 3077911433.93502|  1:16:37s\n",
            "epoch 66 | loss: 12478662056.66426|  1:16:37s\n",
            "epoch 28 | loss: 5618069262.32491|  1:16:39s\n",
            "epoch 42 | loss: 13403586936.83754|  1:16:41s\n",
            "epoch 41 | loss: 6247056996.73646|  1:16:45s\n",
            "epoch 67 | loss: 10718304384.46209|  1:16:47s\n",
            "epoch 41 | loss: 11851231149.74729|  1:16:47s\n",
            "epoch 67 | loss: 13253579530.16607|  1:16:51s\n",
            "epoch 67 | loss: 2882851725.86282|  1:16:52s\n",
            "epoch 68 | loss: 10777437284.27437|  1:17:01s\n",
            "epoch 43 | loss: 13486675253.1408|  1:17:03s\n",
            "epoch 68 | loss: 12530736289.27076|  1:17:05s\n",
            "epoch 29 | loss: 13613122717.57401|  1:17:05s\n",
            "epoch 68 | loss: 3061184593.55957|  1:17:06s\n",
            "epoch 42 | loss: 6234853106.13718|  1:17:08s\n",
            "epoch 29 | loss: 12258666360.1444|  1:17:09s\n",
            "epoch 42 | loss: 11727985299.87003|  1:17:11s\n",
            "epoch 29 | loss: 5601060264.66426|  1:17:13s\n",
            "epoch 69 | loss: 10763349264.86643|  1:17:16s\n",
            "epoch 69 | loss: 12401476167.62455|  1:17:20s\n",
            "epoch 69 | loss: 2864416085.02527|  1:17:21s\n",
            "epoch 44 | loss: 13292172519.04694|  1:17:26s\n",
            "epoch 70 | loss: 10656825300.56317|  1:17:30s\n",
            "epoch 43 | loss: 6210323374.67148|  1:17:31s\n",
            "epoch 43 | loss: 11769229417.3574|  1:17:34s\n",
            "epoch 70 | loss: 12438555085.16967|  1:17:34s\n",
            "epoch 70 | loss: 2741849316.96751|  1:17:35s\n",
            "epoch 30 | loss: 13576046572.12996|  1:17:39s\n",
            "epoch 30 | loss: 12322095113.24188|  1:17:44s\n",
            "epoch 71 | loss: 10557178366.84477|  1:17:44s\n",
            "epoch 30 | loss: 5604531990.6426|  1:17:47s\n",
            "epoch 71 | loss: 12226467023.94224|  1:17:49s\n",
            "epoch 45 | loss: 13446226103.91336|  1:17:49s\n",
            "epoch 71 | loss: 2850784383.76895|  1:17:50s\n",
            "epoch 44 | loss: 6243732964.73646|  1:17:55s\n",
            "epoch 44 | loss: 11690607222.75812|  1:17:58s\n",
            "epoch 72 | loss: 10728668552.54874|  1:17:59s\n",
            "epoch 72 | loss: 12259488524.93863|  1:18:04s\n",
            "epoch 72 | loss: 2935983414.75812|  1:18:05s\n",
            "epoch 46 | loss: 13306575107.23466|  1:18:13s\n",
            "epoch 31 | loss: 13579690391.56678|  1:18:13s\n",
            "epoch 73 | loss: 10645577158.70036|  1:18:14s\n",
            "epoch 73 | loss: 12270532039.62455|  1:18:18s\n",
            "epoch 31 | loss: 12356970776.49098|  1:18:19s\n",
            "epoch 45 | loss: 6260269157.66065|  1:18:19s\n",
            "epoch 73 | loss: 3009707303.74007|  1:18:20s\n",
            "epoch 31 | loss: 5614942343.85559|  1:18:21s\n",
            "epoch 45 | loss: 11665844118.6426|  1:18:23s\n",
            "epoch 74 | loss: 10848582037.02527|  1:18:29s\n",
            "epoch 74 | loss: 12322236416.4621|  1:18:33s\n",
            "epoch 74 | loss: 3293512639.53791|  1:18:35s\n",
            "epoch 47 | loss: 13270435008.69314|  1:18:37s\n",
            "epoch 46 | loss: 6243019265.84838|  1:18:43s\n",
            "epoch 75 | loss: 10555589934.20938|  1:18:43s\n",
            "epoch 46 | loss: 11681065131.89892|  1:18:47s\n",
            "epoch 75 | loss: 12219912399.48015|  1:18:48s\n",
            "epoch 32 | loss: 13683720599.10469|  1:18:48s\n",
            "epoch 75 | loss: 2792229333.71841|  1:18:51s\n",
            "epoch 32 | loss: 12276126948.27437|  1:18:55s\n",
            "epoch 32 | loss: 5611712009.70397|  1:18:57s\n",
            "epoch 76 | loss: 10812685899.09025|  1:18:59s\n",
            "epoch 48 | loss: 13171899478.41156|  1:19:02s\n",
            "epoch 76 | loss: 12451972601.99278|  1:19:03s\n",
            "epoch 76 | loss: 2857617115.03249|  1:19:07s\n",
            "epoch 47 | loss: 6284843142.00722|  1:19:09s\n",
            "epoch 47 | loss: 11546282825.93501|  1:19:14s\n",
            "epoch 77 | loss: 10643579477.02527|  1:19:19s\n",
            "epoch 77 | loss: 12274499335.8556|  1:19:31s\n",
            "epoch 77 | loss: 2696544146.25271|  1:19:41s\n",
            "epoch 33 | loss: 13496932918.98918|  1:19:47s\n",
            "epoch 49 | loss: 13262766012.53429|  1:19:49s\n",
            "epoch 78 | loss: 10598521447.27798|  1:19:53s\n",
            "epoch 33 | loss: 12257342349.40073|  1:19:55s\n",
            "epoch 48 | loss: 6239154172.30325|  1:19:58s\n",
            "epoch 33 | loss: 5609382047.88448|  1:19:58s\n",
            "epoch 78 | loss: 12023437767.16246|  1:19:58s\n",
            "epoch 78 | loss: 3035750429.34296|  1:20:03s\n",
            "epoch 48 | loss: 11656652013.97833|  1:20:03s\n",
            "epoch 79 | loss: 10872393148.76534|  1:20:12s\n",
            "epoch 79 | loss: 12126984549.66065|  1:20:16s\n",
            "epoch 50 | loss: 12992396452.27438|  1:20:18s\n",
            "epoch 79 | loss: 2971493431.91336|  1:20:21s\n",
            "epoch 49 | loss: 6290081880.72202|  1:20:27s\n",
            "epoch 80 | loss: 10604850983.97111|  1:20:30s\n",
            "epoch 34 | loss: 13468644465.6751|  1:20:30s\n",
            "epoch 49 | loss: 11343946119.8556|  1:20:33s\n",
            "epoch 80 | loss: 12107186235.14802|  1:20:34s\n",
            "epoch 34 | loss: 12179918323.98556|  1:20:38s\n",
            "epoch 80 | loss: 2760867997.57401|  1:20:39s\n",
            "epoch 34 | loss: 5619967155.75452|  1:20:41s\n",
            "epoch 51 | loss: 13085349807.13357|  1:20:46s\n",
            "epoch 81 | loss: 10882897393.67509|  1:20:47s\n",
            "epoch 81 | loss: 12216527495.3935|  1:20:51s\n",
            "epoch 50 | loss: 6253463629.63177|  1:20:55s\n",
            "epoch 81 | loss: 2758601056.11552|  1:20:56s\n",
            "epoch 50 | loss: 11330275123.75452|  1:21:01s\n",
            "epoch 82 | loss: 10665200912.17328|  1:21:04s\n",
            "epoch 82 | loss: 11794731312.05776|  1:21:09s\n",
            "epoch 35 | loss: 13412865928.08663|  1:21:12s\n",
            "epoch 82 | loss: 3144723822.90253|  1:21:14s\n",
            "epoch 52 | loss: 12955402964.33213|  1:21:14s\n",
            "epoch 35 | loss: 12093614622.49819|  1:21:21s\n",
            "epoch 83 | loss: 10476351698.25271|  1:21:23s\n",
            "epoch 35 | loss: 5624406588.99639|  1:21:23s\n",
            "epoch 51 | loss: 6267751085.74729|  1:21:25s\n",
            "epoch 83 | loss: 12214993438.0361|  1:21:27s\n",
            "epoch 51 | loss: 11553639047.8556|  1:21:32s\n",
            "epoch 83 | loss: 2757827629.2852|  1:21:33s\n",
            "epoch 84 | loss: 10722941454.09386|  1:21:42s\n",
            "epoch 53 | loss: 12691968341.02528|  1:21:44s\n",
            "epoch 84 | loss: 11960911435.3213|  1:21:46s\n",
            "epoch 84 | loss: 3467521052.88087|  1:21:52s\n",
            "epoch 52 | loss: 6257183968.57762|  1:21:55s\n",
            "epoch 36 | loss: 13481850081.9639|  1:21:57s\n",
            "epoch 85 | loss: 10901085794.88809|  1:22:01s\n",
            "epoch 52 | loss: 11295354670.67148|  1:22:03s\n",
            "epoch 85 | loss: 12007367631.94224|  1:22:05s\n",
            "epoch 36 | loss: 12052649038.55595|  1:22:06s\n",
            "epoch 36 | loss: 5616007937.38628|  1:22:09s\n",
            "epoch 85 | loss: 2999099933.57401|  1:22:11s\n",
            "epoch 54 | loss: 12940734817.03971|  1:22:15s\n",
            "epoch 86 | loss: 10849193760.34657|  1:22:21s\n",
            "epoch 86 | loss: 11699387776.92419|  1:22:24s\n",
            "epoch 53 | loss: 6243319643.49458|  1:22:51s\n",
            "epoch 86 | loss: 3070535820.01444|  1:22:55s\n",
            "epoch 53 | loss: 11270460119.33574|  1:22:59s\n",
            "epoch 87 | loss: 10229820244.10108|  1:23:01s\n",
            "epoch 37 | loss: 13314930977.27076|  1:23:02s\n",
            "epoch 87 | loss: 12060049018.45488|  1:23:03s\n",
            "epoch 55 | loss: 12991950055.04693|  1:23:05s\n",
            "epoch 87 | loss: 2743471174.93141|  1:23:08s\n",
            "epoch 37 | loss: 12110279309.86282|  1:23:08s\n",
            "epoch 37 | loss: 5597230622.0361|  1:23:10s\n",
            "epoch 54 | loss: 6274941527.79784|  1:23:12s\n",
            "epoch 88 | loss: 10239440448.92418|  1:23:14s\n",
            "epoch 88 | loss: 12440346919.74008|  1:23:16s\n",
            "epoch 54 | loss: 11431210520.49097|  1:23:19s\n",
            "epoch 88 | loss: 2645447005.57401|  1:23:20s\n",
            "epoch 56 | loss: 12708327087.59567|  1:23:25s\n",
            "epoch 89 | loss: 10591524947.87004|  1:23:26s\n",
            "epoch 89 | loss: 12046507514.91697|  1:23:28s\n",
            "epoch 38 | loss: 13221946863.82672|  1:23:31s\n",
            "epoch 55 | loss: 6299603449.53069|  1:23:33s\n",
            "epoch 89 | loss: 2811862078.61372|  1:23:33s\n",
            "epoch 38 | loss: 12002218378.62816|  1:23:37s\n",
            "epoch 90 | loss: 10287241874.94585|  1:38:57s\n",
            "epoch 55 | loss: 11495061249.38628|  1:38:59s\n",
            "epoch 38 | loss: 5595843283.17689|  1:38:59s\n",
            "epoch 90 | loss: 12083562533.8917|  1:39:00s\n",
            "epoch 57 | loss: 12720281109.71841|  1:39:03s\n",
            "epoch 90 | loss: 3031430726.23827|  1:39:05s\n",
            "epoch 91 | loss: 10594043285.94946|  1:39:10s\n",
            "epoch 56 | loss: 6274980869.54512|  1:39:12s\n",
            "epoch 91 | loss: 12421504132.15884|  1:39:12s\n",
            "epoch 91 | loss: 2785808665.87726|  1:39:17s\n",
            "epoch 39 | loss: 13207782073.29964|  1:39:18s\n",
            "epoch 56 | loss: 11549729133.05414|  1:39:19s\n",
            "epoch 92 | loss: 11258456510.15162|  1:39:22s\n",
            "epoch 58 | loss: 12593345251.11913|  1:39:23s\n",
            "epoch 92 | loss: 11399214483.40794|  1:39:24s\n",
            "epoch 39 | loss: 11969379142.70037|  1:39:25s\n",
            "epoch 39 | loss: 5600389184.23105|  1:39:28s\n",
            "epoch 92 | loss: 2755745483.09025|  1:39:30s\n",
            "epoch 57 | loss: 6276135226.22383|  1:39:32s\n",
            "epoch 93 | loss: 10994393090.77256|  1:39:34s\n",
            "epoch 93 | loss: 11795158028.93863|  1:39:37s\n",
            "epoch 57 | loss: 11906894716.5343|  1:39:39s\n",
            "epoch 93 | loss: 2643835471.01805|  1:39:42s\n",
            "epoch 59 | loss: 12608091425.50181|  1:39:43s\n",
            "epoch 94 | loss: 10547580208.51986|  1:55:12s\n",
            "epoch 40 | loss: 13010517865.8195|  1:55:12s\n",
            "epoch 94 | loss: 11120049131.66787|  1:55:14s\n",
            "epoch 58 | loss: 6291928934.58484|  1:55:17s\n",
            "epoch 40 | loss: 11893788905.35741|  1:55:19s\n",
            "epoch 94 | loss: 2754632940.8231|  1:55:20s\n",
            "epoch 40 | loss: 5603392953.76173|  1:55:23s\n",
            "epoch 95 | loss: 9762978759.3935|  1:55:24s\n",
            "epoch 58 | loss: 11740862793.93502|  1:55:25s\n",
            "epoch 95 | loss: 10990987781.77617|  1:55:27s\n",
            "epoch 60 | loss: 12767768512.92418|  1:55:28s\n",
            "epoch 95 | loss: 2644224195.00361|  1:55:32s\n",
            "epoch 96 | loss: 10444023555.69675|  1:55:36s\n",
            "epoch 59 | loss: 6294200303.36462|  1:55:37s\n",
            "epoch 96 | loss: 11934770666.74368|  1:55:39s\n",
            "epoch 41 | loss: 13029037111.91335|  1:55:41s\n",
            "epoch 96 | loss: 2828527408.28881|  1:55:45s\n",
            "epoch 59 | loss: 11592657031.16246|  1:55:46s\n",
            "epoch 61 | loss: 12815133325.40072|  1:55:48s\n",
            "epoch 97 | loss: 10294115565.28519|  1:55:48s\n",
            "epoch 41 | loss: 11914687130.80144|  1:55:48s\n",
            "epoch 97 | loss: 11516106261.25632|  1:55:51s\n",
            "epoch 41 | loss: 5582959512.49097|  1:55:52s\n",
            "epoch 60 | loss: 6294047804.99639|  1:55:57s\n",
            "epoch 97 | loss: 2560266041.06859|  1:55:57s\n",
            "epoch 98 | loss: 10593025267.52347|  1:56:00s\n",
            "epoch 98 | loss: 10976559462.58484|  1:56:04s\n",
            "epoch 60 | loss: 11548353562.80144|  1:56:06s\n",
            "epoch 62 | loss: 12524048381.22744|  1:56:07s\n",
            "epoch 98 | loss: 2656086058.28159|  1:56:10s\n",
            "epoch 42 | loss: 13025533210.80145|  1:56:10s\n",
            "epoch 99 | loss: 10674942709.83394|  1:56:12s\n",
            "epoch 99 | loss: 11457770379.55235|  1:56:17s\n",
            "epoch 61 | loss: 6300574387.29242|  1:56:17s\n",
            "epoch 42 | loss: 11868269172.44765|  1:56:18s\n",
            "epoch 42 | loss: 5587389851.26354|  1:56:21s\n",
            "epoch 99 | loss: 2571327313.79061|  1:56:24s\n",
            "epoch 61 | loss: 11506359702.18051|  1:56:29s\n",
            "epoch 63 | loss: 12465296680.66426|  1:56:30s\n",
            "epoch 62 | loss: 6279121421.86282|  1:56:42s\n",
            "epoch 43 | loss: 13014861719.56679|  1:56:44s\n",
            "epoch 43 | loss: 11819068741.08303|  1:56:55s\n",
            "epoch 64 | loss: 12511497016.83754|  1:56:56s\n",
            "epoch 62 | loss: 11637555177.8195|  1:56:56s\n",
            "epoch 43 | loss: 5585256128.23105|  1:56:57s\n",
            "[CV] END .........................................n_steps=3; total time=117.0min\n",
            "[CV] END .........................................n_steps=3; total time=117.1min\n",
            "epoch 63 | loss: 6275955548.41877|  1:57:06s\n",
            "[CV] END .........................................n_steps=3; total time=117.2min\n",
            "epoch 44 | loss: 12981243809.27076|  1:57:13s\n",
            "epoch 65 | loss: 12711130479.36462|  1:57:13s\n",
            "epoch 63 | loss: 11404022224.86643|  1:57:14s\n",
            "epoch 44 | loss: 11716162251.78339|  1:57:18s\n",
            "epoch 44 | loss: 5581412442.1083|  1:57:19s\n",
            "epoch 64 | loss: 6319800087.10469|  1:57:19s\n",
            "epoch 66 | loss: 12431927758.32491|  1:57:26s\n",
            "epoch 64 | loss: 11376645650.94586|  1:57:27s\n",
            "epoch 45 | loss: 12919583541.60288|  1:57:31s\n",
            "epoch 65 | loss: 6283899024.17328|  1:57:33s\n",
            "epoch 45 | loss: 11785792802.19495|  2:06:01s\n",
            "epoch 45 | loss: 5590610503.62455|  2:06:02s\n",
            "epoch 67 | loss: 12617855253.02527|  2:06:03s\n",
            "epoch 65 | loss: 11569115170.19494|  2:06:05s\n",
            "epoch 66 | loss: 6283330656.11552|  2:06:10s\n",
            "epoch 46 | loss: 12988085493.83393|  2:06:13s\n",
            "epoch 68 | loss: 12284961663.53791|  2:06:16s\n",
            "epoch 66 | loss: 11157799527.50902|  2:06:19s\n",
            "epoch 46 | loss: 11644394875.37906|  2:06:19s\n",
            "epoch 46 | loss: 5594423599.59567|  2:06:20s\n",
            "epoch 67 | loss: 6295657609.70397|  2:06:23s\n",
            "epoch 69 | loss: 12823044158.38267|  2:06:29s\n",
            "epoch 47 | loss: 12834066659.35018|  2:06:31s\n",
            "epoch 67 | loss: 11116378080.34657|  2:06:32s\n",
            "epoch 68 | loss: 6167635575.68231|  2:06:37s\n",
            "epoch 47 | loss: 11542220688.40433|  2:06:38s\n",
            "epoch 47 | loss: 5594462486.6426|  2:06:39s\n",
            "epoch 70 | loss: 12230319613.22744|  2:06:43s\n",
            "epoch 68 | loss: 11248524595.75451|  2:21:53s\n",
            "epoch 48 | loss: 12582208349.574|  2:21:56s\n",
            "epoch 69 | loss: 5134902433.73285|  2:21:58s\n",
            "epoch 71 | loss: 11982083611.72562|  2:22:03s\n",
            "epoch 48 | loss: 11761582868.79422|  2:22:03s\n",
            "epoch 48 | loss: 5598303631.71119|  2:22:05s\n",
            "epoch 69 | loss: 11084100730.91696|  2:22:07s\n",
            "epoch 70 | loss: 5022178094.20939|  2:22:11s\n",
            "epoch 49 | loss: 12646085205.94946|  2:22:14s\n",
            "epoch 72 | loss: 12307249909.83394|  2:22:17s\n",
            "epoch 70 | loss: 11331987328.92418|  2:22:20s\n",
            "epoch 49 | loss: 11619350414.32491|  2:22:22s\n",
            "epoch 49 | loss: 5594077593.87725|  2:22:23s\n",
            "epoch 71 | loss: 4924737384.43321|  2:22:24s\n",
            "epoch 73 | loss: 11761455671.91336|  2:22:30s\n",
            "epoch 50 | loss: 12613860996.62094|  2:22:32s\n",
            "epoch 71 | loss: 11257802181.31408|  2:22:33s\n",
            "epoch 72 | loss: 4837435928.49097|  2:22:38s\n",
            "epoch 50 | loss: 11426863749.54513|  2:22:40s\n",
            "epoch 50 | loss: 5594971380.90975|  2:22:41s\n",
            "epoch 74 | loss: 12505223433.93502|  2:22:43s\n",
            "epoch 72 | loss: 11317732056.49098|  2:22:47s\n",
            "epoch 51 | loss: 12591029350.35379|  2:22:50s\n",
            "epoch 73 | loss: 4760205582.78701|  2:22:51s\n",
            "epoch 75 | loss: 11941361189.8917|  2:38:21s\n",
            "epoch 51 | loss: 11533330531.81227|  2:38:24s\n",
            "epoch 51 | loss: 5602485597.80506|  2:38:25s\n",
            "epoch 73 | loss: 11205800940.59207|  2:38:26s\n",
            "epoch 74 | loss: 4754090013.11191|  2:38:30s\n",
            "epoch 52 | loss: 12598630956.8231|  2:38:34s\n",
            "epoch 76 | loss: 12281915087.71119|  2:38:34s\n",
            "epoch 74 | loss: 11222605705.24188|  2:38:39s\n",
            "epoch 52 | loss: 11453363394.07943|  2:38:43s\n",
            "epoch 75 | loss: 4669905773.51625|  2:38:44s\n",
            "epoch 52 | loss: 5612582042.33935|  2:38:44s\n",
            "epoch 77 | loss: 12226499745.73285|  2:38:48s\n",
            "epoch 53 | loss: 12891769889.27076|  2:38:52s\n",
            "epoch 75 | loss: 11227244188.64982|  2:38:53s\n",
            "epoch 76 | loss: 4654608010.62816|  2:38:57s\n",
            "epoch 78 | loss: 11964775324.64982|  2:39:01s\n",
            "epoch 53 | loss: 11533936070.00722|  2:39:01s\n",
            "epoch 53 | loss: 5590954203.95668|  2:39:02s\n",
            "epoch 76 | loss: 10985439453.80505|  2:39:06s\n",
            "epoch 54 | loss: 13329961644.12997|  2:54:35s\n",
            "epoch 77 | loss: 4572718528.69314|  2:54:36s\n",
            "epoch 79 | loss: 11788801173.48736|  2:54:39s\n",
            "epoch 77 | loss: 11110025941.02527|  2:54:45s\n",
            "epoch 54 | loss: 11444275918.09387|  2:54:45s\n",
            "epoch 54 | loss: 5605345290.16606|  2:54:46s\n",
            "epoch 78 | loss: 4567501269.94946|  2:54:50s\n",
            "epoch 80 | loss: 11922625183.88448|  2:54:53s\n",
            "epoch 55 | loss: 13206049993.93502|  2:54:54s\n",
            "epoch 78 | loss: 11019532458.51264|  2:54:59s\n",
            "epoch 79 | loss: 4485509237.37184|  2:55:03s\n",
            "epoch 55 | loss: 11551436627.63899|  2:55:04s\n",
            "epoch 55 | loss: 5625063866.68592|  2:55:05s\n",
            "epoch 81 | loss: 11629676655.13357|  2:55:06s\n",
            "epoch 56 | loss: 13206160844.70758|  2:55:12s\n",
            "epoch 79 | loss: 11088146703.48015|  2:55:12s\n",
            "epoch 80 | loss: 4522256332.01444|  2:55:17s\n",
            "epoch 82 | loss: 12539645306.22383|  2:55:19s\n",
            "epoch 56 | loss: 11516255106.07942|  2:55:22s\n",
            "epoch 56 | loss: 5638225109.02527|  2:55:24s\n",
            "epoch 80 | loss: 10907388781.51624|  2:55:25s\n",
            "epoch 57 | loss: 13011035470.09386|  2:55:30s\n",
            "epoch 81 | loss: 4390348229.77617|  2:55:31s\n",
            "epoch 83 | loss: 11834625880.95307|  2:55:33s\n",
            "epoch 81 | loss: 10998189569.84837|  2:55:39s\n",
            "epoch 57 | loss: 11373241191.50903|  2:55:40s\n",
            "epoch 57 | loss: 5628875859.1769|  2:55:42s\n",
            "epoch 82 | loss: 4408084479.07581|  2:55:44s\n",
            "epoch 84 | loss: 12066235101.574|  2:55:46s\n",
            "epoch 58 | loss: 12883315064.1444|  2:55:48s\n",
            "epoch 82 | loss: 10939670251.43682|  2:55:52s\n",
            "epoch 83 | loss: 4428188342.98917|  2:55:57s\n",
            "epoch 58 | loss: 11169026977.27076|  2:55:59s\n",
            "epoch 85 | loss: 12075742341.54513|  2:55:59s\n",
            "epoch 58 | loss: 5590810256.63538|  2:56:01s\n",
            "epoch 83 | loss: 10796172244.10108|  2:56:05s\n",
            "epoch 59 | loss: 12894259447.22022|  2:56:06s\n",
            "epoch 84 | loss: 4345503262.96029|  2:56:11s\n",
            "epoch 86 | loss: 12219429163.66788|  2:56:12s\n",
            "epoch 59 | loss: 11459310501.4296|  2:56:17s\n",
            "epoch 84 | loss: 11049766066.36823|  2:56:19s\n",
            "epoch 59 | loss: 5587644733.45849|  2:56:19s\n",
            "epoch 85 | loss: 4242028348.0722|  2:56:24s\n",
            "epoch 60 | loss: 12664910242.65704|  2:56:24s\n",
            "epoch 87 | loss: 12461827024.40433|  2:56:25s\n",
            "epoch 85 | loss: 10676896451.9278|  2:56:33s\n",
            "epoch 60 | loss: 11141057887.19133|  2:56:35s\n",
            "epoch 86 | loss: 4167617859.4657|  2:56:38s\n",
            "epoch 60 | loss: 5588756412.5343|  2:56:38s\n",
            "epoch 88 | loss: 12216464886.06498|  2:56:39s\n",
            "epoch 61 | loss: 12432239481.29964|  2:56:43s\n",
            "epoch 86 | loss: 10825448799.65343|  2:56:46s\n",
            "epoch 87 | loss: 4848558796.24548|  2:56:51s\n",
            "epoch 89 | loss: 12000338636.47654|  2:56:52s\n",
            "epoch 61 | loss: 11037107718.93142|  2:56:54s\n",
            "epoch 61 | loss: 5594614637.97834|  3:06:58s\n",
            "epoch 87 | loss: 10708866788.27436|  3:07:01s\n",
            "epoch 62 | loss: 12757578505.70398|  3:07:02s\n",
            "epoch 88 | loss: 4914828369.32852|  3:07:06s\n",
            "epoch 90 | loss: 11695623059.63899|  3:07:06s\n",
            "epoch 62 | loss: 11202975925.1408|  3:07:14s\n",
            "epoch 88 | loss: 10758334994.02166|  3:07:15s\n",
            "epoch 62 | loss: 5582809124.96751|  3:07:17s\n",
            "epoch 89 | loss: 4447263172.85199|  3:07:19s\n",
            "epoch 91 | loss: 11923317032.66426|  3:07:20s\n",
            "epoch 63 | loss: 12316521775.59567|  3:07:21s\n",
            "epoch 89 | loss: 10604534571.66787|  3:07:28s\n",
            "epoch 90 | loss: 4722185277.45848|  3:07:32s\n",
            "epoch 63 | loss: 11363061524.33213|  3:07:32s\n",
            "epoch 92 | loss: 12094074279.50902|  3:07:33s\n",
            "epoch 63 | loss: 5586825022.38267|  3:07:35s\n",
            "epoch 64 | loss: 12443366274.31046|  3:07:38s\n",
            "epoch 90 | loss: 10600559489.38628|  3:07:42s\n",
            "epoch 91 | loss: 4434872818.59928|  3:07:45s\n",
            "epoch 93 | loss: 11821171912.54874|  3:07:46s\n",
            "epoch 64 | loss: 11304649017.76174|  3:07:51s\n",
            "epoch 64 | loss: 5573592476.64982|  3:07:54s\n",
            "epoch 91 | loss: 10554675648.0|  3:07:55s\n",
            "epoch 65 | loss: 12717105794.31047|  3:07:57s\n",
            "epoch 92 | loss: 4170643327.53791|  3:07:59s\n",
            "epoch 94 | loss: 11828032943.59567|  3:07:59s\n",
            "epoch 92 | loss: 11003119295.07581|  3:08:09s\n",
            "epoch 65 | loss: 11260316097.61732|  3:08:10s\n",
            "epoch 93 | loss: 4189717631.30686|  3:08:12s\n",
            "epoch 95 | loss: 11988848892.30326|  3:08:13s\n",
            "epoch 65 | loss: 5585126468.85198|  3:08:13s\n",
            "epoch 66 | loss: 12262844562.94585|  3:08:15s\n",
            "epoch 93 | loss: 10706421458.48376|  3:08:22s\n",
            "epoch 94 | loss: 4303134242.19495|  3:08:25s\n",
            "epoch 96 | loss: 11850398955.66787|  3:08:26s\n",
            "epoch 66 | loss: 11153640107.66787|  3:08:28s\n",
            "epoch 66 | loss: 5575588385.27076|  3:08:31s\n",
            "epoch 67 | loss: 12422406604.01444|  3:08:33s\n",
            "epoch 94 | loss: 10687057588.6787|  3:08:36s\n",
            "epoch 95 | loss: 4221111807.53791|  3:08:39s\n",
            "epoch 97 | loss: 11681128852.56318|  3:08:39s\n",
            "epoch 67 | loss: 11043850775.56679|  3:08:46s\n",
            "epoch 95 | loss: 10969465609.93502|  3:08:49s\n",
            "epoch 67 | loss: 5582581848.72202|  3:08:50s\n",
            "epoch 68 | loss: 12300203719.62455|  3:08:51s\n",
            "epoch 96 | loss: 4278114852.50542|  3:08:52s\n",
            "epoch 98 | loss: 12446090902.87365|  3:08:52s\n",
            "epoch 96 | loss: 10774901130.85921|  3:09:03s\n",
            "epoch 68 | loss: 10968160596.56318|  3:09:05s\n",
            "epoch 97 | loss: 4198550172.18772|  3:09:05s\n",
            "epoch 99 | loss: 11726357637.54513|  3:09:06s\n",
            "epoch 68 | loss: 5577575961.87726|  3:09:08s\n",
            "epoch 69 | loss: 12219525061.31408|  3:09:10s\n",
            "epoch 97 | loss: 10850136460.24549|  3:09:17s\n",
            "epoch 98 | loss: 4405534753.73286|  3:09:20s\n",
            "epoch 69 | loss: 11082893960.31769|  3:10:49s\n",
            "epoch 69 | loss: 5588060168.31769|  3:10:54s\n",
            "epoch 70 | loss: 12206632288.57762|  3:10:55s\n",
            "epoch 98 | loss: 10505702667.3213|  3:10:56s\n",
            "epoch 99 | loss: 4187856649.01083|  3:10:59s\n",
            "[CV] END .........................................n_steps=5; total time=191.1min\n",
            "epoch 99 | loss: 10661974197.37184|  3:11:12s\n",
            "epoch 70 | loss: 10976438553.41516|  3:11:12s\n",
            "epoch 70 | loss: 5573263673.29964|  3:11:15s\n",
            "epoch 71 | loss: 12099490143.42238|  3:11:16s\n",
            "epoch 71 | loss: 11081389435.84116|  3:27:04s\n",
            "epoch 71 | loss: 5568461270.41155|  3:27:07s\n",
            "[CV] END .........................................n_steps=5; total time=207.2min\n",
            "epoch 72 | loss: 12144047227.84116|  3:27:08s\n",
            "[CV] END .........................................n_steps=5; total time=207.3min\n",
            "epoch 72 | loss: 11055010425.06859|  3:27:23s\n",
            "epoch 72 | loss: 5569863144.89531|  3:27:25s\n",
            "epoch 73 | loss: 12105609685.94946|  3:27:25s\n",
            "epoch 73 | loss: 10906541525.94946|  3:27:38s\n",
            "epoch 74 | loss: 12203508190.26715|  3:27:40s\n",
            "epoch 73 | loss: 5575168240.28881|  3:27:40s\n",
            "epoch 74 | loss: 10823528150.6426|  3:27:54s\n",
            "epoch 75 | loss: 11939125886.15163|  3:27:55s\n",
            "epoch 74 | loss: 5570236724.2166|  3:27:56s\n",
            "epoch 75 | loss: 11070985596.0722|  3:28:10s\n",
            "epoch 76 | loss: 12056291168.34657|  3:28:10s\n",
            "epoch 75 | loss: 5580261454.55596|  3:28:12s\n",
            "epoch 76 | loss: 10802849795.69676|  3:28:25s\n",
            "epoch 77 | loss: 11948430409.47292|  3:28:26s\n",
            "epoch 76 | loss: 5575197455.71119|  3:28:28s\n",
            "epoch 77 | loss: 10799080944.51985|  3:28:41s\n",
            "epoch 78 | loss: 11907185667.69675|  3:28:41s\n",
            "epoch 77 | loss: 5570096528.63538|  3:28:43s\n",
            "epoch 79 | loss: 11982992492.12996|  3:28:56s\n",
            "epoch 78 | loss: 10911958716.5343|  3:28:57s\n",
            "epoch 78 | loss: 5566400698.68592|  3:29:00s\n",
            "epoch 80 | loss: 11925788345.29964|  3:29:12s\n",
            "epoch 79 | loss: 11031637086.72924|  3:29:12s\n",
            "epoch 79 | loss: 5560155718.23827|  3:29:15s\n",
            "epoch 81 | loss: 11908529741.16968|  3:29:27s\n",
            "epoch 80 | loss: 10992870326.06498|  3:29:28s\n",
            "epoch 80 | loss: 5552625145.53069|  3:29:31s\n",
            "epoch 82 | loss: 12003901346.65704|  3:29:43s\n",
            "epoch 81 | loss: 10959845224.43321|  3:29:43s\n",
            "epoch 81 | loss: 5544214394.45488|  3:29:47s\n",
            "epoch 83 | loss: 11883042688.0|  3:29:58s\n",
            "epoch 82 | loss: 10878592287.42238|  3:29:59s\n",
            "epoch 82 | loss: 5532551940.62094|  3:30:03s\n",
            "epoch 84 | loss: 11855764661.60289|  3:30:14s\n",
            "epoch 83 | loss: 10948583969.50181|  3:30:14s\n",
            "epoch 83 | loss: 5476137788.0722|  3:30:18s\n",
            "epoch 85 | loss: 11721861608.43321|  3:30:29s\n",
            "epoch 84 | loss: 10854937997.16967|  3:30:30s\n",
            "epoch 84 | loss: 5523492440.72202|  3:30:34s\n",
            "epoch 86 | loss: 11689237176.6065|  3:30:44s\n",
            "epoch 85 | loss: 10699632899.69675|  3:30:45s\n",
            "epoch 85 | loss: 5507225419.3213|  3:30:50s\n",
            "epoch 87 | loss: 11942432379.6101|  3:31:00s\n",
            "epoch 86 | loss: 10923970592.80866|  3:31:01s\n",
            "epoch 86 | loss: 5499594786.19495|  3:31:05s\n",
            "epoch 88 | loss: 11656101179.14802|  3:31:15s\n",
            "epoch 87 | loss: 10919968077.86282|  3:31:17s\n",
            "epoch 87 | loss: 5489185018.45487|  3:31:22s\n",
            "epoch 89 | loss: 11647274818.07942|  3:31:30s\n",
            "epoch 88 | loss: 11015774282.62816|  3:31:33s\n",
            "epoch 88 | loss: 5490898494.38268|  3:31:37s\n",
            "epoch 90 | loss: 11748834768.86643|  3:47:11s\n",
            "epoch 89 | loss: 10741235502.67148|  3:47:14s\n",
            "epoch 89 | loss: 5482486196.6787|  3:47:18s\n",
            "epoch 91 | loss: 11748126378.51264|  3:47:26s\n",
            "epoch 90 | loss: 10931859335.62455|  3:47:29s\n",
            "epoch 90 | loss: 5468718492.18773|  3:47:34s\n",
            "epoch 92 | loss: 11721027614.26715|  3:47:42s\n",
            "epoch 91 | loss: 10870351503.2491|  3:47:45s\n",
            "epoch 91 | loss: 5493946146.65704|  3:47:50s\n",
            "epoch 93 | loss: 11621436013.74729|  3:47:57s\n",
            "epoch 92 | loss: 10840530725.66065|  3:48:00s\n",
            "epoch 92 | loss: 5469086460.76534|  3:48:05s\n",
            "epoch 94 | loss: 11670222160.17329|  3:48:12s\n",
            "epoch 93 | loss: 10779385938.25271|  3:48:16s\n",
            "epoch 93 | loss: 5455302066.36823|  3:48:21s\n",
            "epoch 95 | loss: 11758701289.3574|  3:48:27s\n",
            "epoch 94 | loss: 10547032412.88087|  3:48:31s\n",
            "epoch 94 | loss: 5450076036.15884|  3:48:37s\n",
            "epoch 96 | loss: 11811505500.88087|  3:48:43s\n",
            "epoch 95 | loss: 10706242573.40072|  3:48:46s\n",
            "epoch 95 | loss: 5449196410.91697|  3:48:52s\n",
            "epoch 97 | loss: 11635339774.61372|  3:48:58s\n",
            "epoch 96 | loss: 10742212735.76896|  3:49:01s\n",
            "epoch 96 | loss: 5442460247.33574|  3:49:08s\n",
            "epoch 98 | loss: 11748656514.54152|  3:49:13s\n",
            "epoch 97 | loss: 10737468343.22022|  3:49:16s\n",
            "epoch 97 | loss: 5432658140.88087|  3:49:24s\n",
            "epoch 99 | loss: 11764142020.15884|  4:04:41s\n",
            "epoch 98 | loss: 10825058453.71841|  4:04:45s\n",
            "epoch 98 | loss: 5428002116.38989|  4:04:53s\n",
            "epoch 99 | loss: 10729825809.79062|  4:05:01s\n",
            "epoch 99 | loss: 5435001000.20217|  4:05:10s\n",
            "[CV] END .........................................n_steps=7; total time=245.5min\n",
            "[CV] END .........................................n_steps=7; total time=245.9min\n",
            "[CV] END .........................................n_steps=7; total time=246.0min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19798510200.90601|  0:00:20s\n",
            "epoch 1  | loss: 16434878344.32771|  0:00:40s\n",
            "epoch 2  | loss: 13642607870.14939|  0:01:00s\n",
            "epoch 3  | loss: 11952457842.42892|  0:01:20s\n",
            "epoch 4  | loss: 11151475562.40964|  0:01:41s\n",
            "epoch 5  | loss: 10784836736.30843|  0:02:01s\n",
            "epoch 6  | loss: 10717388125.76386|  0:02:21s\n",
            "epoch 7  | loss: 10654315685.32049|  0:02:41s\n",
            "epoch 8  | loss: 10573024017.27229|  0:03:01s\n",
            "epoch 9  | loss: 10489241668.47227|  0:18:47s\n",
            "epoch 10 | loss: 10482920371.81687|  0:19:06s\n",
            "epoch 11 | loss: 10426711410.12049|  0:19:26s\n",
            "epoch 12 | loss: 10326472952.28914|  0:19:46s\n",
            "epoch 13 | loss: 10295719259.91325|  0:20:06s\n",
            "epoch 14 | loss: 10236787039.61446|  0:20:27s\n",
            "epoch 15 | loss: 10175074291.97108|  0:20:46s\n",
            "epoch 16 | loss: 10176022440.09637|  0:21:06s\n",
            "epoch 17 | loss: 10184252299.41205|  0:36:32s\n",
            "epoch 18 | loss: 10052009060.5494|  0:36:52s\n",
            "epoch 19 | loss: 10160187771.99037|  0:37:12s\n",
            "epoch 20 | loss: 10134898314.48675|  0:37:32s\n",
            "epoch 21 | loss: 10027762167.82651|  0:37:52s\n",
            "epoch 22 | loss: 9926371616.69398|  0:38:12s\n",
            "epoch 23 | loss: 9863883693.64819|  0:38:31s\n",
            "epoch 24 | loss: 9738997890.15906|  0:38:51s\n",
            "epoch 25 | loss: 9679775394.08192|  0:54:37s\n",
            "epoch 26 | loss: 9540063615.0747|  0:54:57s\n",
            "epoch 27 | loss: 9644471421.53252|  0:55:17s\n",
            "epoch 28 | loss: 9480322761.0988|  0:55:36s\n",
            "epoch 29 | loss: 9460005656.52048|  0:55:56s\n",
            "epoch 30 | loss: 9431813618.12049|  0:56:16s\n",
            "epoch 31 | loss: 9753502583.67229|  1:02:06s\n",
            "epoch 32 | loss: 9638201784.7518|  1:02:26s\n",
            "epoch 33 | loss: 9572854148.31807|  1:02:46s\n",
            "epoch 34 | loss: 9478326272.30843|  1:03:05s\n",
            "epoch 35 | loss: 9285852777.02169|  1:03:25s\n",
            "epoch 36 | loss: 9173844818.35181|  1:03:45s\n",
            "epoch 37 | loss: 9199988496.19277|  1:04:05s\n",
            "epoch 38 | loss: 9286520216.98314|  1:04:25s\n",
            "epoch 39 | loss: 9204195803.45061|  1:20:10s\n",
            "epoch 40 | loss: 9184023564.33736|  1:20:30s\n",
            "epoch 41 | loss: 9159192585.56145|  1:20:50s\n",
            "epoch 42 | loss: 9080433389.33976|  1:21:10s\n",
            "epoch 43 | loss: 9067730903.44097|  1:21:31s\n",
            "epoch 44 | loss: 9035920408.05783|  1:21:50s\n",
            "epoch 45 | loss: 8937232598.8241|  1:22:10s\n",
            "epoch 46 | loss: 9005951677.84096|  1:37:56s\n",
            "epoch 47 | loss: 9090510261.66747|  1:38:16s\n",
            "epoch 48 | loss: 9017839389.91807|  1:38:36s\n",
            "epoch 49 | loss: 8982295419.06506|  1:38:56s\n",
            "epoch 50 | loss: 8923559345.5036|  1:39:16s\n",
            "epoch 51 | loss: 9060450572.02892|  1:39:36s\n",
            "epoch 52 | loss: 8887710006.74699|  1:55:21s\n",
            "epoch 53 | loss: 8857241805.87951|  1:55:41s\n",
            "epoch 54 | loss: 8937068854.43854|  1:56:01s\n",
            "epoch 55 | loss: 8980377445.78313|  1:56:21s\n",
            "epoch 56 | loss: 8994242470.09155|  1:56:41s\n",
            "epoch 57 | loss: 8929452335.49878|  1:57:00s\n",
            "epoch 58 | loss: 8891413759.84578|  1:57:20s\n",
            "epoch 59 | loss: 8828178100.89638|  2:03:09s\n",
            "epoch 60 | loss: 8827194572.8|  2:03:29s\n",
            "epoch 61 | loss: 8812853004.8|  2:03:49s\n",
            "epoch 62 | loss: 8792934514.73735|  2:04:08s\n",
            "epoch 63 | loss: 8727173103.65301|  2:04:28s\n",
            "epoch 64 | loss: 8742444060.53013|  2:04:48s\n",
            "epoch 65 | loss: 8939301875.04579|  2:05:07s\n",
            "epoch 66 | loss: 8712104989.76385|  2:05:27s\n",
            "epoch 67 | loss: 8749849598.30361|  2:20:49s\n",
            "epoch 68 | loss: 8828970118.32289|  2:21:09s\n",
            "epoch 69 | loss: 8696661264.19278|  2:21:29s\n",
            "epoch 70 | loss: 8926383318.36145|  2:21:49s\n",
            "epoch 71 | loss: 8786388215.98074|  2:22:09s\n",
            "epoch 72 | loss: 8728810306.15903|  2:22:29s\n",
            "epoch 73 | loss: 8668374551.44097|  2:22:49s\n",
            "epoch 74 | loss: 8683622250.25542|  2:38:34s\n",
            "epoch 75 | loss: 8767096919.59518|  2:38:54s\n",
            "epoch 76 | loss: 8445529630.53493|  2:39:14s\n",
            "epoch 77 | loss: 8657315181.6482|  2:54:50s\n",
            "epoch 78 | loss: 8405124576.69398|  2:55:10s\n",
            "epoch 79 | loss: 7765762217.1759|  2:55:30s\n",
            "epoch 80 | loss: 8613315676.83855|  2:55:50s\n",
            "epoch 81 | loss: 8716666135.13253|  2:56:09s\n",
            "epoch 82 | loss: 8566035706.91085|  2:56:29s\n",
            "epoch 83 | loss: 8646712483.77831|  2:56:49s\n",
            "epoch 84 | loss: 8597866854.4|  2:57:09s\n",
            "epoch 85 | loss: 8543564185.75421|  2:57:28s\n",
            "epoch 86 | loss: 8633826035.97108|  2:57:48s\n",
            "epoch 87 | loss: 8432218493.06988|  2:58:08s\n",
            "epoch 88 | loss: 8684424068.16386|  2:58:27s\n",
            "epoch 89 | loss: 8005171561.48432|  2:58:47s\n",
            "epoch 90 | loss: 8682835718.47712|  3:04:09s\n",
            "epoch 91 | loss: 8618166065.96627|  3:04:30s\n",
            "epoch 92 | loss: 8694288496.11566|  3:04:49s\n",
            "epoch 93 | loss: 8420307505.96626|  3:05:09s\n",
            "epoch 94 | loss: 8667309859.31566|  3:05:29s\n",
            "epoch 95 | loss: 8581632277.12772|  3:05:49s\n",
            "epoch 96 | loss: 8195766483.89398|  3:06:09s\n",
            "epoch 97 | loss: 8646435558.24578|  3:21:51s\n",
            "epoch 98 | loss: 8298142531.54699|  3:22:10s\n",
            "epoch 99 | loss: 8403538454.20723|  3:22:30s\n",
            "Лучшие параметры: {'n_steps': 3}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_steps': [3, 5, 7],\n",
        "}\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_d=32, n_a=16, n_steps=3, gamma=1.3, lambda_sparse=1e-3):\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.lambda_sparse = lambda_sparse\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = TabNetRegressor(\n",
        "            n_d=self.n_d,\n",
        "            n_a=self.n_a,\n",
        "            n_steps=self.n_steps,\n",
        "            gamma=self.gamma,\n",
        "            lambda_sparse=self.lambda_sparse\n",
        "        )\n",
        "        self.model.fit(X, y.reshape(-1, 1))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "model = TabNetWrapper()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Лучшие параметры: {best_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**gamma**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 22346778790.3538|  0:00:11s\n",
            "epoch 0  | loss: 14545542853.77618|  0:00:11s\n",
            "epoch 0  | loss: 22307453353.12635|  0:00:11s\n",
            "epoch 0  | loss: 14527079076.50542|  0:00:11s\n",
            "epoch 0  | loss: 24063471752.77978|  0:00:11s\n",
            "epoch 0  | loss: 24076429478.35379|  0:00:11s\n",
            "epoch 0  | loss: 22334245503.53791|  0:00:11s\n",
            "epoch 0  | loss: 24048653016.25993|  0:00:12s\n",
            "epoch 0  | loss: 14537697997.16968|  0:00:12s\n",
            "epoch 1  | loss: 12534460543.53791|  0:00:23s\n",
            "epoch 1  | loss: 20354248996.04333|  0:00:23s\n",
            "epoch 1  | loss: 22058236759.79783|  0:00:24s\n",
            "epoch 1  | loss: 20336620939.55234|  0:00:24s\n",
            "epoch 1  | loss: 12469965500.5343|  0:00:24s\n",
            "epoch 1  | loss: 21975119554.07942|  0:00:24s\n",
            "epoch 1  | loss: 20373384800.11552|  0:00:24s\n",
            "epoch 1  | loss: 21936093749.60288|  0:00:24s\n",
            "epoch 1  | loss: 12550505634.65704|  0:00:24s\n",
            "epoch 2  | loss: 10076036471.22022|  0:16:01s\n",
            "epoch 2  | loss: 17874883112.66425|  0:16:01s\n",
            "epoch 2  | loss: 19692934515.52346|  0:16:01s\n",
            "epoch 2  | loss: 19569905519.82671|  0:16:01s\n",
            "epoch 2  | loss: 19716876424.77978|  0:16:01s\n",
            "epoch 2  | loss: 10069984217.18411|  0:16:01s\n",
            "epoch 2  | loss: 18052203091.1769|  0:16:01s\n",
            "epoch 2  | loss: 18283962499.23466|  0:16:01s\n",
            "epoch 2  | loss: 10081134998.64259|  0:16:02s\n",
            "epoch 3  | loss: 8059575203.58123|  0:16:13s\n",
            "epoch 3  | loss: 15980507447.45126|  0:16:13s\n",
            "epoch 3  | loss: 17913513205.83394|  0:16:13s\n",
            "epoch 3  | loss: 16067706873.5307|  0:16:13s\n",
            "epoch 3  | loss: 17789606642.13718|  0:16:13s\n",
            "epoch 3  | loss: 17784577579.43683|  0:16:13s\n",
            "epoch 3  | loss: 8316637140.56317|  0:16:13s\n",
            "epoch 3  | loss: 16454063958.87365|  0:16:13s\n",
            "epoch 3  | loss: 8062221383.16246|  0:16:14s\n",
            "epoch 4  | loss: 6660595047.50902|  0:16:25s\n",
            "epoch 4  | loss: 14771463941.54514|  0:16:25s\n",
            "epoch 4  | loss: 16639803577.76174|  0:16:25s\n",
            "epoch 4  | loss: 16555584596.10108|  0:16:25s\n",
            "epoch 4  | loss: 14708493690.91697|  0:16:25s\n",
            "epoch 4  | loss: 16551009645.05416|  0:16:26s\n",
            "epoch 4  | loss: 15010046738.48376|  0:16:26s\n",
            "epoch 4  | loss: 7052126701.51625|  0:16:26s\n",
            "epoch 4  | loss: 6672894163.63899|  0:16:26s\n",
            "epoch 5  | loss: 5855028008.20216|  0:16:37s\n",
            "epoch 5  | loss: 14014179968.0|  0:16:37s\n",
            "epoch 5  | loss: 15745843579.84114|  0:16:37s\n",
            "epoch 5  | loss: 15665515440.51986|  0:16:37s\n",
            "epoch 5  | loss: 13891789838.787|  0:16:38s\n",
            "epoch 5  | loss: 15745201019.37904|  0:16:38s\n",
            "epoch 5  | loss: 14048071196.18773|  0:16:38s\n",
            "epoch 5  | loss: 6167362128.86643|  0:16:38s\n",
            "epoch 5  | loss: 5849266001.79061|  0:16:39s\n",
            "epoch 6  | loss: 5394726979.9278|  0:16:49s\n",
            "epoch 6  | loss: 13453907272.54872|  0:16:49s\n",
            "epoch 6  | loss: 15201613529.64622|  0:16:50s\n",
            "epoch 6  | loss: 15131961007.13359|  0:16:50s\n",
            "epoch 6  | loss: 13324223934.84477|  0:16:50s\n",
            "epoch 6  | loss: 15251380841.3574|  0:16:50s\n",
            "epoch 6  | loss: 13408261840.40435|  0:16:50s\n",
            "epoch 6  | loss: 5611039512.95307|  0:16:51s\n",
            "epoch 6  | loss: 5405125311.76895|  0:16:51s\n",
            "epoch 7  | loss: 5239422587.84116|  0:17:02s\n",
            "epoch 7  | loss: 13081952877.51625|  0:17:02s\n",
            "epoch 7  | loss: 14835846846.84476|  0:17:02s\n",
            "epoch 7  | loss: 14810712416.57762|  0:17:02s\n",
            "epoch 7  | loss: 13002983823.2491|  0:17:02s\n",
            "epoch 7  | loss: 14899844281.76173|  0:17:03s\n",
            "epoch 7  | loss: 13094407846.81589|  0:17:03s\n",
            "epoch 7  | loss: 5305019343.48014|  0:17:03s\n",
            "epoch 7  | loss: 5159443057.213|  0:17:03s\n",
            "epoch 8  | loss: 5120351879.3935|  0:17:14s\n",
            "epoch 8  | loss: 12905342793.47292|  0:17:14s\n",
            "epoch 8  | loss: 14572958951.97111|  0:17:14s\n",
            "epoch 8  | loss: 14559148956.18773|  0:17:14s\n",
            "epoch 8  | loss: 12887138948.15883|  0:17:15s\n",
            "epoch 8  | loss: 14671656036.27438|  0:17:15s\n",
            "epoch 8  | loss: 12888706968.49098|  0:17:15s\n",
            "epoch 8  | loss: 5165179243.20578|  0:17:16s\n",
            "epoch 8  | loss: 5057812528.05776|  0:17:16s\n",
            "epoch 9  | loss: 5087772681.24188|  0:17:26s\n",
            "epoch 9  | loss: 12867790376.20217|  0:17:26s\n",
            "epoch 9  | loss: 14418169163.78338|  0:17:27s\n",
            "epoch 9  | loss: 14414905311.19133|  0:17:27s\n",
            "epoch 9  | loss: 12778028169.24186|  0:17:27s\n",
            "epoch 9  | loss: 14558887286.75812|  0:17:27s\n",
            "epoch 9  | loss: 12793103444.10108|  0:17:27s\n",
            "epoch 9  | loss: 5023673940.56318|  0:17:28s\n",
            "epoch 9  | loss: 5033542064.51985|  0:17:28s\n",
            "epoch 10 | loss: 5018488874.97473|  0:17:38s\n",
            "epoch 10 | loss: 12810883578.91697|  0:17:38s\n",
            "epoch 10 | loss: 14418147424.57761|  0:17:39s\n",
            "epoch 10 | loss: 14292680341.25632|  0:17:39s\n",
            "epoch 10 | loss: 12673770032.05776|  0:17:39s\n",
            "epoch 10 | loss: 14405743633.55957|  0:17:40s\n",
            "epoch 10 | loss: 12673374826.74369|  0:17:40s\n",
            "epoch 10 | loss: 4921962344.43321|  0:17:40s\n",
            "epoch 10 | loss: 4997444239.2491|  0:17:40s\n",
            "epoch 11 | loss: 4973970993.44404|  0:17:50s\n",
            "epoch 11 | loss: 12733168280.02889|  0:17:50s\n",
            "epoch 11 | loss: 14313581784.25992|  0:17:51s\n",
            "epoch 11 | loss: 14326458142.96028|  0:17:51s\n",
            "epoch 11 | loss: 12684023070.0361|  0:17:51s\n",
            "epoch 11 | loss: 14380242550.75812|  0:17:52s\n",
            "epoch 11 | loss: 12636257483.3213|  0:17:52s\n",
            "epoch 11 | loss: 4867906483.29242|  0:17:52s\n",
            "epoch 11 | loss: 4987069081.41516|  0:17:53s\n",
            "epoch 12 | loss: 4961723915.55235|  0:18:02s\n",
            "epoch 12 | loss: 12678126734.78701|  0:18:03s\n",
            "epoch 12 | loss: 14286383593.3574|  0:18:03s\n",
            "epoch 12 | loss: 14303599818.39711|  0:18:04s\n",
            "epoch 12 | loss: 12598961810.02165|  0:18:04s\n",
            "epoch 12 | loss: 14344029404.88086|  0:18:04s\n",
            "epoch 12 | loss: 4778755415.33574|  0:18:05s\n",
            "epoch 12 | loss: 12628434808.1444|  0:18:05s\n",
            "epoch 12 | loss: 4878087869.45848|  0:18:05s\n",
            "epoch 13 | loss: 4919065314.42599|  0:18:14s\n",
            "epoch 13 | loss: 12650384558.67148|  0:18:15s\n",
            "epoch 13 | loss: 14254724305.79062|  0:18:16s\n",
            "epoch 13 | loss: 14283779907.4657|  0:18:16s\n",
            "epoch 13 | loss: 12559460535.45126|  0:18:16s\n",
            "epoch 13 | loss: 4745084455.74007|  0:18:17s\n",
            "epoch 13 | loss: 14312770492.53429|  0:18:17s\n",
            "epoch 13 | loss: 12571602953.24188|  0:18:17s\n",
            "epoch 13 | loss: 4807602922.28159|  0:33:20s\n",
            "epoch 14 | loss: 4934870548.33213|  0:33:29s\n",
            "epoch 14 | loss: 12596543089.213|  0:33:29s\n",
            "epoch 14 | loss: 14250369690.80144|  0:33:30s\n",
            "epoch 14 | loss: 14313788574.4982|  0:33:31s\n",
            "epoch 14 | loss: 12490822498.42598|  0:33:31s\n",
            "epoch 14 | loss: 4719055363.69675|  0:33:31s\n",
            "epoch 14 | loss: 12530832328.54874|  0:33:31s\n",
            "epoch 14 | loss: 14310702454.29602|  0:33:31s\n",
            "epoch 14 | loss: 4794926256.51986|  0:33:32s\n",
            "epoch 15 | loss: 4824665270.98917|  0:33:41s\n",
            "epoch 15 | loss: 12562069537.73286|  0:33:41s\n",
            "epoch 15 | loss: 14224754588.64982|  0:33:42s\n",
            "epoch 15 | loss: 14184116860.76535|  0:33:43s\n",
            "epoch 15 | loss: 12403057389.51624|  0:33:43s\n",
            "epoch 15 | loss: 4631848370.83032|  0:33:43s\n",
            "epoch 15 | loss: 12451270930.48375|  0:33:43s\n",
            "epoch 15 | loss: 14269075888.51985|  0:33:44s\n",
            "epoch 15 | loss: 4781615086.44043|  0:33:45s\n",
            "epoch 16 | loss: 4794896874.28159|  0:33:53s\n",
            "epoch 16 | loss: 12656329034.39712|  0:33:54s\n",
            "epoch 16 | loss: 14374258535.97111|  0:33:55s\n",
            "epoch 16 | loss: 4729677886.84477|  0:33:55s\n",
            "epoch 16 | loss: 14123179230.26716|  0:33:55s\n",
            "epoch 16 | loss: 12448210115.00362|  0:33:55s\n",
            "epoch 16 | loss: 12517414713.76173|  0:33:56s\n",
            "epoch 16 | loss: 14267803396.15884|  0:33:56s\n",
            "epoch 16 | loss: 4768152629.14079|  0:33:57s\n",
            "epoch 17 | loss: 4797079036.76534|  0:34:05s\n",
            "epoch 17 | loss: 12548453817.29964|  0:34:06s\n",
            "epoch 17 | loss: 14188243385.76173|  0:34:07s\n",
            "epoch 17 | loss: 4605597290.74368|  0:34:07s\n",
            "epoch 17 | loss: 12391474660.27437|  0:34:08s\n",
            "epoch 17 | loss: 14059770600.43322|  0:34:08s\n",
            "epoch 17 | loss: 12475100544.0|  0:34:08s\n",
            "epoch 17 | loss: 14161621423.13357|  0:34:08s\n",
            "epoch 17 | loss: 4712422355.63899|  0:34:10s\n",
            "epoch 18 | loss: 4672646165.25632|  0:34:17s\n",
            "epoch 18 | loss: 12512086363.49458|  0:34:18s\n",
            "epoch 18 | loss: 14205126867.639|  0:34:19s\n",
            "epoch 18 | loss: 4545936179.75451|  0:34:19s\n",
            "epoch 18 | loss: 12299281053.11191|  0:34:20s\n",
            "epoch 18 | loss: 14064935967.88448|  0:34:20s\n",
            "epoch 18 | loss: 12338105002.05054|  0:34:20s\n",
            "epoch 18 | loss: 14139774935.79784|  0:34:21s\n",
            "epoch 18 | loss: 4652881408.92419|  0:34:22s\n",
            "epoch 19 | loss: 4616164836.73646|  0:34:29s\n",
            "epoch 19 | loss: 12483632743.50902|  0:34:30s\n",
            "epoch 19 | loss: 14254430830.90252|  0:34:31s\n",
            "epoch 19 | loss: 4534640779.09025|  0:34:32s\n",
            "epoch 19 | loss: 12277632668.18773|  0:34:32s\n",
            "epoch 19 | loss: 13984706526.72923|  0:34:32s\n",
            "epoch 19 | loss: 12371782910.61372|  0:34:33s\n",
            "epoch 19 | loss: 14008000125.68951|  0:34:33s\n",
            "epoch 19 | loss: 4620795728.86643|  0:34:35s\n",
            "epoch 20 | loss: 4635171347.87004|  0:34:41s\n",
            "epoch 20 | loss: 12447918044.88087|  0:34:42s\n",
            "epoch 20 | loss: 14234359125.94946|  0:34:43s\n",
            "epoch 20 | loss: 4507997866.05054|  0:34:44s\n",
            "epoch 20 | loss: 12299076343.22022|  0:34:44s\n",
            "epoch 20 | loss: 13965392727.33574|  0:34:45s\n",
            "epoch 20 | loss: 12376956025.0686|  0:34:45s\n",
            "epoch 20 | loss: 14052989997.74729|  0:34:45s\n",
            "epoch 20 | loss: 4646675221.71841|  0:34:47s\n",
            "epoch 21 | loss: 4616771238.81588|  0:34:54s\n",
            "epoch 21 | loss: 12395487692.24549|  0:34:55s\n",
            "epoch 21 | loss: 14193313714.36822|  0:34:55s\n",
            "epoch 21 | loss: 4403786376.08664|  0:34:56s\n",
            "epoch 21 | loss: 12281643535.71119|  0:34:56s\n",
            "epoch 21 | loss: 12227914791.74007|  0:34:57s\n",
            "epoch 21 | loss: 13888477524.10108|  0:34:57s\n",
            "epoch 21 | loss: 13841204736.00001|  0:34:58s\n",
            "epoch 21 | loss: 4546066088.20217|  0:35:00s\n",
            "epoch 22 | loss: 4575240361.58845|  0:35:06s\n",
            "epoch 22 | loss: 12342615552.92419|  0:35:07s\n",
            "epoch 22 | loss: 14157442818.31047|  0:35:08s\n",
            "epoch 22 | loss: 4330410241.38628|  0:35:08s\n",
            "epoch 22 | loss: 12178908176.17328|  0:35:09s\n",
            "epoch 22 | loss: 12237489190.81588|  0:35:09s\n",
            "epoch 22 | loss: 13784648274.2527|  0:35:09s\n",
            "epoch 22 | loss: 13917010818.31046|  0:35:10s\n",
            "epoch 22 | loss: 4480718942.72924|  0:35:12s\n",
            "epoch 23 | loss: 4567088513.15523|  0:35:18s\n",
            "epoch 23 | loss: 12325582303.65342|  0:35:19s\n",
            "epoch 23 | loss: 14136734987.09025|  0:35:20s\n",
            "epoch 23 | loss: 4244277589.02527|  0:35:20s\n",
            "epoch 23 | loss: 12147791830.87365|  0:35:21s\n",
            "epoch 23 | loss: 12182395518.61371|  0:35:22s\n",
            "epoch 23 | loss: 13835018279.50902|  0:35:22s\n",
            "epoch 23 | loss: 13930255694.55595|  0:35:22s\n",
            "epoch 23 | loss: 4432560012.47653|  0:35:25s\n",
            "epoch 24 | loss: 4505406561.5018|  0:35:31s\n",
            "epoch 24 | loss: 12323086559.19134|  0:35:32s\n",
            "epoch 24 | loss: 14155482916.50543|  0:35:32s\n",
            "epoch 24 | loss: 4291918365.11191|  0:35:33s\n",
            "epoch 24 | loss: 12106976920.25993|  0:35:34s\n",
            "epoch 24 | loss: 12272507947.89892|  0:35:34s\n",
            "epoch 24 | loss: 13701988162.07942|  0:35:35s\n",
            "epoch 24 | loss: 13963789889.61734|  0:35:35s\n",
            "epoch 24 | loss: 4437527200.57762|  0:35:38s\n",
            "epoch 25 | loss: 4438205324.01444|  0:35:43s\n",
            "epoch 25 | loss: 12303310899.75451|  0:35:44s\n",
            "epoch 25 | loss: 14062116544.69314|  0:35:45s\n",
            "epoch 25 | loss: 4271111193.18411|  0:35:45s\n",
            "epoch 25 | loss: 12042657863.16246|  0:35:46s\n",
            "epoch 25 | loss: 12158221253.77617|  0:35:47s\n",
            "epoch 25 | loss: 13817706886.00722|  0:35:47s\n",
            "epoch 25 | loss: 13713666399.19134|  0:35:47s\n",
            "epoch 25 | loss: 4365333607.74007|  0:35:51s\n",
            "epoch 26 | loss: 4353919737.53068|  0:41:52s\n",
            "epoch 26 | loss: 14002959299.9278|  0:41:53s\n",
            "epoch 26 | loss: 12321560332.93863|  0:41:53s\n",
            "epoch 26 | loss: 4215286206.84476|  0:41:54s\n",
            "epoch 26 | loss: 12032306239.53791|  0:41:55s\n",
            "epoch 26 | loss: 12196510091.09025|  0:41:56s\n",
            "epoch 26 | loss: 13789844030.38267|  0:41:56s\n",
            "epoch 26 | loss: 13606974425.64621|  0:41:56s\n",
            "epoch 26 | loss: 4284209508.73646|  0:41:59s\n",
            "epoch 27 | loss: 4370483308.12997|  0:42:04s\n",
            "epoch 27 | loss: 13933040255.0758|  0:42:06s\n",
            "epoch 27 | loss: 12217867083.7834|  0:42:06s\n",
            "epoch 27 | loss: 4101950979.23466|  0:42:06s\n",
            "epoch 27 | loss: 12128457563.72564|  0:42:07s\n",
            "epoch 27 | loss: 12055216811.89892|  0:42:08s\n",
            "epoch 27 | loss: 13701352712.31769|  0:42:08s\n",
            "epoch 27 | loss: 13688076751.71118|  0:42:09s\n",
            "epoch 27 | loss: 4332287797.60288|  0:42:12s\n",
            "epoch 28 | loss: 4323618278.58484|  0:42:16s\n",
            "epoch 28 | loss: 14034502730.39712|  0:42:18s\n",
            "epoch 28 | loss: 12164917742.44043|  0:42:18s\n",
            "epoch 28 | loss: 4042945291.09025|  0:42:18s\n",
            "epoch 28 | loss: 12042773133.40073|  0:42:20s\n",
            "epoch 28 | loss: 12017694406.70036|  0:42:20s\n",
            "epoch 28 | loss: 13733212175.71119|  0:42:21s\n",
            "epoch 28 | loss: 13616007270.12275|  0:42:21s\n",
            "epoch 28 | loss: 4287588417.61733|  0:42:24s\n",
            "epoch 29 | loss: 4549184384.46209|  0:42:28s\n",
            "epoch 29 | loss: 13989750495.19135|  0:42:30s\n",
            "epoch 29 | loss: 12123567220.90975|  0:42:30s\n",
            "epoch 29 | loss: 4097414937.41516|  0:42:30s\n",
            "epoch 29 | loss: 12015095042.07942|  0:42:32s\n",
            "epoch 29 | loss: 12014554062.787|  0:42:33s\n",
            "epoch 29 | loss: 13713641141.60288|  0:42:33s\n",
            "epoch 29 | loss: 13545196421.54512|  0:42:34s\n",
            "epoch 29 | loss: 4293881070.44043|  0:42:37s\n",
            "epoch 30 | loss: 4433587756.36101|  0:42:40s\n",
            "epoch 30 | loss: 13922171998.72924|  0:42:42s\n",
            "epoch 30 | loss: 12123138534.58484|  0:42:43s\n",
            "epoch 30 | loss: 4040726203.61011|  0:42:43s\n",
            "epoch 30 | loss: 11883204096.46209|  0:42:44s\n",
            "epoch 30 | loss: 13989809473.15524|  0:42:45s\n",
            "epoch 30 | loss: 12027829978.1083|  0:42:45s\n",
            "epoch 30 | loss: 13448397227.89892|  0:42:46s\n",
            "epoch 30 | loss: 4159852752.40433|  0:42:49s\n",
            "epoch 31 | loss: 4322947293.34296|  0:42:52s\n",
            "epoch 31 | loss: 13885668649.58846|  0:42:54s\n",
            "epoch 31 | loss: 12051689137.44404|  0:42:55s\n",
            "epoch 31 | loss: 3995316716.59206|  0:42:55s\n",
            "epoch 31 | loss: 11840777423.48014|  0:42:57s\n",
            "epoch 31 | loss: 11925588182.87364|  0:42:57s\n",
            "epoch 31 | loss: 13882327736.83755|  0:42:57s\n",
            "epoch 31 | loss: 13424763014.9314|  0:42:58s\n",
            "epoch 31 | loss: 4169488717.63177|  0:43:01s\n",
            "epoch 32 | loss: 4278577407.5379|  0:43:04s\n",
            "epoch 32 | loss: 13816954087.50902|  0:43:07s\n",
            "epoch 32 | loss: 4058465267.52346|  0:43:07s\n",
            "epoch 32 | loss: 12046629507.69674|  0:43:07s\n",
            "epoch 32 | loss: 11814860605.45848|  0:43:09s\n",
            "epoch 32 | loss: 13666691686.58484|  0:43:09s\n",
            "epoch 32 | loss: 11936384371.06137|  0:43:09s\n",
            "epoch 32 | loss: 13457134712.6065|  0:43:11s\n",
            "epoch 32 | loss: 4198028268.59205|  0:43:14s\n",
            "epoch 33 | loss: 4117192518.23827|  0:43:16s\n",
            "epoch 33 | loss: 13806165557.60289|  0:43:19s\n",
            "epoch 33 | loss: 12039665548.01444|  0:43:19s\n",
            "epoch 33 | loss: 3910686254.20939|  0:43:20s\n",
            "epoch 33 | loss: 13685273654.98917|  0:43:21s\n",
            "epoch 33 | loss: 11809738377.93503|  0:43:21s\n",
            "epoch 33 | loss: 11940351201.27076|  0:43:21s\n",
            "epoch 33 | loss: 13403015351.45126|  0:43:23s\n",
            "epoch 33 | loss: 4134384371.98556|  0:43:26s\n",
            "epoch 34 | loss: 4205785524.21661|  0:43:29s\n",
            "epoch 34 | loss: 13748263730.83032|  0:43:31s\n",
            "epoch 34 | loss: 11952744329.70397|  0:43:32s\n",
            "epoch 34 | loss: 3899401554.48375|  0:43:32s\n",
            "epoch 34 | loss: 13559598483.87004|  0:43:33s\n",
            "epoch 34 | loss: 11706515480.49098|  0:43:34s\n",
            "epoch 34 | loss: 11939711629.40073|  0:43:34s\n",
            "epoch 34 | loss: 13378490763.09026|  0:43:36s\n",
            "epoch 34 | loss: 4032296475.72563|  0:43:39s\n",
            "epoch 35 | loss: 4079152192.69314|  0:43:41s\n",
            "epoch 35 | loss: 13700266595.81228|  0:43:44s\n",
            "epoch 35 | loss: 3651520073.93502|  0:43:44s\n",
            "epoch 35 | loss: 11919505132.12996|  0:43:45s\n",
            "epoch 35 | loss: 13392460721.90614|  0:43:46s\n",
            "epoch 35 | loss: 11650626769.32852|  0:43:46s\n",
            "epoch 35 | loss: 11941376779.3213|  0:43:46s\n",
            "epoch 35 | loss: 13528094314.28158|  0:43:49s\n",
            "epoch 35 | loss: 4045059373.05415|  0:43:52s\n",
            "epoch 36 | loss: 3949973243.37906|  0:43:54s\n",
            "epoch 36 | loss: 13754698130.94585|  0:43:57s\n",
            "epoch 36 | loss: 3703706403.81227|  0:43:57s\n",
            "epoch 36 | loss: 11973260695.10469|  0:43:57s\n",
            "epoch 36 | loss: 13191504360.20217|  0:43:58s\n",
            "epoch 36 | loss: 11596533845.48736|  0:43:59s\n",
            "epoch 36 | loss: 11942120125.45848|  0:43:59s\n",
            "epoch 36 | loss: 13487468508.41877|  0:44:01s\n",
            "epoch 36 | loss: 3921579126.29603|  0:44:05s\n",
            "epoch 37 | loss: 3815934496.34657|  0:44:07s\n",
            "epoch 37 | loss: 13548137674.85921|  0:59:35s\n",
            "epoch 37 | loss: 3621881003.43682|  0:59:35s\n",
            "epoch 37 | loss: 11936238651.14802|  0:59:35s\n",
            "epoch 37 | loss: 13125132464.51986|  0:59:36s\n",
            "epoch 37 | loss: 11595115525.54512|  0:59:36s\n",
            "epoch 37 | loss: 11886182566.81588|  0:59:37s\n",
            "epoch 37 | loss: 13414659490.65704|  0:59:39s\n",
            "epoch 37 | loss: 3890206094.55596|  0:59:43s\n",
            "epoch 38 | loss: 3794628051.17689|  0:59:44s\n",
            "epoch 38 | loss: 13542518288.1733|  0:59:47s\n",
            "epoch 38 | loss: 3489054516.21661|  0:59:47s\n",
            "epoch 38 | loss: 11805671588.50542|  0:59:48s\n",
            "epoch 38 | loss: 13255959853.97832|  0:59:48s\n",
            "epoch 38 | loss: 11531430865.79062|  0:59:49s\n",
            "epoch 38 | loss: 11871659214.55596|  0:59:50s\n",
            "epoch 38 | loss: 13288321266.13718|  0:59:52s\n",
            "epoch 38 | loss: 3856540911.82672|  0:59:55s\n",
            "epoch 39 | loss: 3855522613.60289|  0:59:57s\n",
            "epoch 39 | loss: 13317957203.17688|  0:59:59s\n",
            "epoch 39 | loss: 3534100644.96751|  0:59:59s\n",
            "epoch 39 | loss: 11815476716.59206|  1:00:00s\n",
            "epoch 39 | loss: 13060813907.1769|  1:00:00s\n",
            "epoch 39 | loss: 11580617364.79422|  1:00:01s\n",
            "epoch 39 | loss: 11902785784.6065|  1:00:02s\n",
            "epoch 39 | loss: 13351337229.63178|  1:00:04s\n",
            "epoch 39 | loss: 3799382843.37906|  1:00:07s\n",
            "epoch 40 | loss: 3962300913.21299|  1:00:09s\n",
            "epoch 40 | loss: 3622781299.52347|  1:00:11s\n",
            "epoch 40 | loss: 13379929537.61733|  1:00:11s\n",
            "epoch 40 | loss: 11724572495.48014|  1:00:12s\n",
            "epoch 40 | loss: 13366616112.51986|  1:00:12s\n",
            "epoch 40 | loss: 11414442554.45488|  1:00:13s\n",
            "epoch 40 | loss: 11716125287.04693|  1:00:14s\n",
            "epoch 40 | loss: 13274616538.5704|  1:00:16s\n",
            "epoch 40 | loss: 3825376365.51625|  1:00:20s\n",
            "epoch 41 | loss: 3577879097.53068|  1:00:21s\n",
            "epoch 41 | loss: 3381424418.65704|  1:00:23s\n",
            "epoch 41 | loss: 13391700213.83394|  1:00:24s\n",
            "epoch 41 | loss: 11732977144.6065|  1:00:25s\n",
            "epoch 41 | loss: 13303740526.44044|  1:00:25s\n",
            "epoch 41 | loss: 11368050379.3213|  1:00:25s\n",
            "epoch 41 | loss: 11630742514.59928|  1:00:26s\n",
            "epoch 41 | loss: 13211207173.08303|  1:00:29s\n",
            "epoch 41 | loss: 3842433067.20578|  1:00:32s\n",
            "epoch 42 | loss: 3606517637.54513|  1:00:33s\n",
            "epoch 42 | loss: 3238078226.94585|  1:00:36s\n",
            "epoch 42 | loss: 13385419306.05054|  1:00:36s\n",
            "epoch 42 | loss: 13261208076.93863|  1:00:37s\n",
            "epoch 42 | loss: 11625221112.1444|  1:00:37s\n",
            "epoch 42 | loss: 11206964776.43321|  1:00:37s\n",
            "epoch 42 | loss: 11575135742.61372|  1:00:39s\n",
            "epoch 42 | loss: 12980567576.95307|  1:00:41s\n",
            "epoch 42 | loss: 3892219321.76174|  1:00:45s\n",
            "epoch 43 | loss: 3774607268.04332|  1:00:46s\n",
            "epoch 43 | loss: 3357010583.33574|  1:00:48s\n",
            "epoch 43 | loss: 13098831018.05056|  1:00:49s\n",
            "epoch 43 | loss: 13146115718.46931|  1:00:49s\n",
            "epoch 43 | loss: 11703924652.36101|  1:00:49s\n",
            "epoch 43 | loss: 11409778133.94946|  1:00:49s\n",
            "epoch 43 | loss: 11564823131.49458|  1:00:51s\n",
            "epoch 43 | loss: 12832519285.37186|  1:00:54s\n",
            "epoch 43 | loss: 3879715827.52346|  1:00:58s\n",
            "epoch 44 | loss: 3544469008.17328|  1:00:58s\n",
            "epoch 44 | loss: 3242743274.74368|  1:01:00s\n",
            "epoch 44 | loss: 13260473713.6751|  1:01:01s\n",
            "epoch 44 | loss: 13032270693.66065|  1:01:01s\n",
            "epoch 44 | loss: 11724156121.18411|  1:01:02s\n",
            "epoch 44 | loss: 11006653992.20216|  1:01:02s\n",
            "epoch 44 | loss: 11516550468.15884|  1:01:04s\n",
            "epoch 44 | loss: 12831205754.91697|  1:01:06s\n",
            "epoch 44 | loss: 3823324755.63899|  1:01:10s\n",
            "epoch 45 | loss: 3685865209.99278|  1:01:10s\n",
            "epoch 45 | loss: 3458078579.29242|  1:01:13s\n",
            "epoch 45 | loss: 12999369774.20939|  1:01:13s\n",
            "epoch 45 | loss: 13047450901.71841|  1:01:13s\n",
            "epoch 45 | loss: 11788215305.93501|  1:01:14s\n",
            "epoch 45 | loss: 11502295724.8231|  1:01:14s\n",
            "epoch 45 | loss: 11665059741.80505|  1:01:16s\n",
            "epoch 45 | loss: 12876144921.41516|  1:01:18s\n",
            "epoch 45 | loss: 3829466149.8917|  1:01:23s\n",
            "epoch 46 | loss: 3519836947.87004|  1:01:23s\n",
            "epoch 46 | loss: 3638052352.46209|  1:01:25s\n",
            "epoch 46 | loss: 13040541020.88087|  1:01:26s\n",
            "epoch 46 | loss: 13068216516.85199|  1:01:26s\n",
            "epoch 46 | loss: 11622272820.21661|  1:01:26s\n",
            "epoch 46 | loss: 11012049899.43682|  1:01:26s\n",
            "epoch 46 | loss: 11615182225.09748|  1:01:29s\n",
            "epoch 46 | loss: 12656789147.0325|  1:01:31s\n",
            "epoch 47 | loss: 3446183108.38989|  1:01:35s\n",
            "epoch 46 | loss: 3833807282.83032|  1:01:36s\n",
            "epoch 47 | loss: 3346769258.97473|  1:01:37s\n",
            "epoch 47 | loss: 13273170217.12636|  1:01:38s\n",
            "epoch 47 | loss: 11178896966.00722|  1:01:39s\n",
            "epoch 47 | loss: 12946462730.62816|  1:01:39s\n",
            "epoch 47 | loss: 11628221862.35379|  1:01:39s\n",
            "epoch 47 | loss: 11519536814.67149|  1:01:41s\n",
            "epoch 47 | loss: 12622662856.31768|  1:01:44s\n",
            "epoch 48 | loss: 3498154368.46209|  1:01:48s\n",
            "epoch 47 | loss: 3735536562.36823|  1:01:49s\n",
            "epoch 48 | loss: 3217989961.01083|  1:17:02s\n",
            "epoch 48 | loss: 12861255166.61372|  1:17:03s\n",
            "epoch 48 | loss: 11083638412.01444|  1:17:04s\n",
            "epoch 48 | loss: 11546387924.56318|  1:17:04s\n",
            "epoch 48 | loss: 12750013007.94224|  1:17:04s\n",
            "epoch 48 | loss: 11499150212.62094|  1:17:07s\n",
            "epoch 48 | loss: 12575470158.32491|  1:17:09s\n",
            "epoch 49 | loss: 3473264465.79061|  1:17:13s\n",
            "epoch 48 | loss: 3758527207.50903|  1:17:14s\n",
            "epoch 49 | loss: 3462822707.29242|  1:17:15s\n",
            "epoch 49 | loss: 12714791755.78339|  1:17:15s\n",
            "epoch 49 | loss: 11062457512.20217|  1:17:16s\n",
            "epoch 49 | loss: 11535678177.03971|  1:17:16s\n",
            "epoch 49 | loss: 12977147207.62456|  1:17:16s\n",
            "epoch 49 | loss: 11551170899.17689|  1:17:19s\n",
            "epoch 49 | loss: 12490002535.97112|  1:17:21s\n",
            "epoch 50 | loss: 3503891872.80866|  1:17:25s\n",
            "epoch 49 | loss: 3760621009.55957|  1:17:26s\n",
            "epoch 50 | loss: 3020597419.89892|  1:17:27s\n",
            "epoch 50 | loss: 12786217221.54513|  1:17:27s\n",
            "epoch 50 | loss: 11012497546.16607|  1:17:28s\n",
            "epoch 50 | loss: 11428741167.36462|  1:17:28s\n",
            "epoch 50 | loss: 12792569816.72202|  1:17:29s\n",
            "epoch 50 | loss: 11487003230.26715|  1:17:31s\n",
            "epoch 50 | loss: 12627956504.02888|  1:17:33s\n",
            "epoch 51 | loss: 3340986620.76534|  1:17:38s\n",
            "epoch 50 | loss: 3596488784.86643|  1:17:39s\n",
            "epoch 51 | loss: 3306432071.3935|  1:17:39s\n",
            "epoch 51 | loss: 12954016250.91696|  1:17:39s\n",
            "epoch 51 | loss: 11194304413.11192|  1:17:40s\n",
            "epoch 51 | loss: 11388311204.96751|  1:17:40s\n",
            "epoch 51 | loss: 12875183678.84476|  1:17:41s\n",
            "epoch 51 | loss: 11528750725.31408|  1:17:44s\n",
            "epoch 51 | loss: 12518287213.2852|  1:17:46s\n",
            "epoch 52 | loss: 3489798649.06859|  1:17:50s\n",
            "epoch 52 | loss: 3151497914.68592|  1:17:51s\n",
            "epoch 51 | loss: 3579891876.73646|  1:17:51s\n",
            "epoch 52 | loss: 12594749868.59205|  1:17:51s\n",
            "epoch 52 | loss: 11292681286.23827|  1:17:52s\n",
            "epoch 52 | loss: 11375930914.19495|  1:17:52s\n",
            "epoch 52 | loss: 12859396729.99277|  1:17:53s\n",
            "epoch 52 | loss: 11390788510.0361|  1:17:56s\n",
            "epoch 52 | loss: 12376927545.76174|  1:17:58s\n",
            "epoch 53 | loss: 3597409209.29964|  1:18:03s\n",
            "epoch 53 | loss: 2994189059.69675|  1:18:03s\n",
            "epoch 53 | loss: 12685415463.27796|  1:18:04s\n",
            "epoch 52 | loss: 3592184886.75812|  1:18:04s\n",
            "epoch 53 | loss: 11050357495.45127|  1:18:04s\n",
            "epoch 53 | loss: 11318794780.18773|  1:18:05s\n",
            "epoch 53 | loss: 12781928429.97834|  1:18:06s\n",
            "epoch 53 | loss: 11492397714.48375|  1:18:08s\n",
            "epoch 53 | loss: 12241970265.64621|  1:18:10s\n",
            "epoch 54 | loss: 3701321568.57762|  1:18:15s\n",
            "epoch 54 | loss: 3045723753.3574|  1:18:16s\n",
            "epoch 54 | loss: 12424167243.3213|  1:18:16s\n",
            "epoch 53 | loss: 3510063479.68231|  1:18:16s\n",
            "epoch 54 | loss: 11164228890.33935|  1:18:17s\n",
            "epoch 54 | loss: 11336084410.22382|  1:18:17s\n",
            "epoch 54 | loss: 12643858396.88086|  1:18:18s\n",
            "epoch 54 | loss: 11401491768.37545|  1:18:21s\n",
            "epoch 54 | loss: 12182615632.40434|  1:18:23s\n",
            "epoch 55 | loss: 3147697345.15523|  1:18:27s\n",
            "epoch 55 | loss: 3232589647.2491|  1:18:28s\n",
            "epoch 55 | loss: 12544585100.01444|  1:18:28s\n",
            "epoch 55 | loss: 10972225172.79422|  1:18:29s\n",
            "epoch 54 | loss: 3473237104.98195|  1:18:29s\n",
            "epoch 55 | loss: 11395067669.71841|  1:18:29s\n",
            "epoch 55 | loss: 12296598426.80144|  1:18:30s\n",
            "epoch 55 | loss: 11472059860.33213|  1:18:33s\n",
            "epoch 55 | loss: 12662746712.49098|  1:18:35s\n",
            "epoch 56 | loss: 3354825802.85921|  1:18:40s\n",
            "epoch 56 | loss: 3104189965.40072|  1:18:40s\n",
            "epoch 56 | loss: 12482566443.89892|  1:18:40s\n",
            "epoch 56 | loss: 10867142387.98556|  1:18:41s\n",
            "epoch 55 | loss: 3536204288.69314|  1:18:41s\n",
            "epoch 56 | loss: 11256607465.58845|  1:18:42s\n",
            "epoch 56 | loss: 12594037475.35018|  1:18:43s\n",
            "epoch 56 | loss: 11334623005.57401|  1:18:46s\n",
            "epoch 56 | loss: 12240465781.37184|  1:18:48s\n",
            "epoch 57 | loss: 3735159648.80866|  1:18:52s\n",
            "epoch 57 | loss: 3310830251.20578|  1:18:52s\n",
            "epoch 57 | loss: 12473823718.81588|  1:18:53s\n",
            "epoch 57 | loss: 10712553940.10109|  1:18:53s\n",
            "epoch 56 | loss: 3453741698.54151|  1:18:54s\n",
            "epoch 57 | loss: 11277458870.98917|  1:18:54s\n",
            "epoch 57 | loss: 12589947480.25992|  1:18:55s\n",
            "epoch 57 | loss: 11335282811.84115|  1:18:58s\n",
            "epoch 57 | loss: 12164144662.87364|  1:19:00s\n",
            "epoch 58 | loss: 2799936853.71841|  1:19:05s\n",
            "epoch 58 | loss: 3215304585.47292|  1:19:05s\n",
            "epoch 58 | loss: 12510592242.59928|  1:19:05s\n",
            "epoch 58 | loss: 11128706307.69675|  1:19:06s\n",
            "epoch 58 | loss: 11162427752.89531|  1:19:06s\n",
            "epoch 57 | loss: 3420776780.70758|  1:19:07s\n",
            "epoch 58 | loss: 12403965616.98195|  1:19:07s\n",
            "epoch 58 | loss: 11436317058.07942|  1:19:11s\n",
            "epoch 58 | loss: 12366403440.28882|  1:19:13s\n",
            "epoch 59 | loss: 3242147782.70036|  1:34:42s\n",
            "epoch 59 | loss: 3159237120.4621|  1:34:42s\n",
            "epoch 59 | loss: 12556022071.91336|  1:34:43s\n",
            "epoch 59 | loss: 10811989291.43682|  1:34:43s\n",
            "epoch 59 | loss: 11189679343.82672|  1:34:44s\n",
            "epoch 59 | loss: 12576973111.45126|  1:34:45s\n",
            "epoch 58 | loss: 3394919187.17689|  1:34:45s\n",
            "epoch 59 | loss: 11263226514.48375|  1:34:49s\n",
            "epoch 59 | loss: 12417420991.76895|  1:34:50s\n",
            "epoch 60 | loss: 3300170503.62455|  1:34:54s\n",
            "epoch 60 | loss: 12555926925.40072|  1:34:55s\n",
            "epoch 60 | loss: 3325301193.47292|  1:34:55s\n",
            "epoch 60 | loss: 11123635602.02167|  1:34:55s\n",
            "epoch 60 | loss: 11004288043.43682|  1:34:56s\n",
            "epoch 60 | loss: 12452235102.72924|  1:34:57s\n",
            "epoch 59 | loss: 3491873550.78701|  1:34:58s\n",
            "epoch 60 | loss: 11452587612.88088|  1:35:01s\n",
            "epoch 60 | loss: 12072676044.24549|  1:35:03s\n",
            "epoch 61 | loss: 3294434304.92419|  1:35:06s\n",
            "epoch 61 | loss: 12525298581.71841|  1:35:07s\n",
            "epoch 61 | loss: 3205033013.1408|  1:35:07s\n",
            "epoch 61 | loss: 10786477891.23466|  1:35:07s\n",
            "epoch 61 | loss: 11032375772.64982|  1:35:09s\n",
            "epoch 61 | loss: 12286481798.9314|  1:35:09s\n",
            "epoch 60 | loss: 3464109191.3935|  1:35:10s\n",
            "epoch 61 | loss: 11393739158.6426|  1:35:13s\n",
            "epoch 61 | loss: 12227022187.43682|  1:35:15s\n",
            "epoch 62 | loss: 3029750098.7148|  1:35:19s\n",
            "epoch 62 | loss: 12475411261.45848|  1:35:19s\n",
            "epoch 62 | loss: 3123059258.91697|  1:35:19s\n",
            "epoch 62 | loss: 10600204081.44405|  1:35:20s\n",
            "epoch 62 | loss: 11121285680.51985|  1:35:21s\n",
            "epoch 62 | loss: 12171311383.79784|  1:35:22s\n",
            "epoch 61 | loss: 3326968591.48014|  1:35:23s\n",
            "epoch 62 | loss: 11258875995.72564|  1:35:25s\n",
            "epoch 62 | loss: 11856717145.87726|  1:35:28s\n",
            "epoch 63 | loss: 3170469809.44404|  1:35:30s\n",
            "epoch 63 | loss: 12531708251.95668|  1:35:31s\n",
            "epoch 63 | loss: 2935376070.23827|  1:35:32s\n",
            "epoch 63 | loss: 10913737750.41155|  1:35:32s\n",
            "epoch 63 | loss: 11099980240.63538|  1:35:33s\n",
            "epoch 63 | loss: 12406726056.66425|  1:35:34s\n",
            "epoch 62 | loss: 3289575535.36462|  1:35:35s\n",
            "epoch 63 | loss: 11174027255.91336|  1:35:38s\n",
            "epoch 63 | loss: 12230588176.63538|  1:35:40s\n",
            "epoch 64 | loss: 3033270769.213|  1:35:43s\n",
            "epoch 64 | loss: 12637221110.29603|  1:35:43s\n",
            "epoch 64 | loss: 10752876419.23465|  1:35:44s\n",
            "epoch 64 | loss: 3190340812.01444|  1:35:44s\n",
            "epoch 64 | loss: 11040604766.4982|  1:35:45s\n",
            "epoch 64 | loss: 11922134650.45488|  1:35:46s\n",
            "epoch 63 | loss: 3268808322.77256|  1:35:48s\n",
            "epoch 64 | loss: 11216895437.63177|  1:35:50s\n",
            "epoch 64 | loss: 12091849502.49819|  1:35:52s\n",
            "epoch 65 | loss: 2748690265.18412|  1:35:55s\n",
            "epoch 65 | loss: 12441996759.33574|  1:35:55s\n",
            "epoch 65 | loss: 10786154237.22743|  1:35:56s\n",
            "epoch 65 | loss: 2949584346.5704|  1:35:56s\n",
            "epoch 65 | loss: 10981888369.21299|  1:35:58s\n",
            "epoch 65 | loss: 12329433401.76174|  1:35:58s\n",
            "epoch 64 | loss: 3271105687.10469|  1:36:00s\n",
            "epoch 65 | loss: 11382171307.43683|  1:36:03s\n",
            "epoch 65 | loss: 12035198882.88808|  1:36:05s\n",
            "epoch 66 | loss: 3170567386.33935|  1:36:07s\n",
            "epoch 66 | loss: 12478662056.66426|  1:36:07s\n",
            "epoch 66 | loss: 10811649459.29242|  1:36:08s\n",
            "epoch 66 | loss: 3077911433.93502|  1:36:09s\n",
            "epoch 66 | loss: 10929267299.35019|  1:36:10s\n",
            "epoch 66 | loss: 12301325006.09385|  1:36:11s\n",
            "epoch 65 | loss: 3224066626.54152|  1:36:13s\n",
            "epoch 66 | loss: 11221383796.44765|  1:36:15s\n",
            "epoch 66 | loss: 11861741851.72563|  1:36:17s\n",
            "epoch 67 | loss: 2711563255.22022|  1:36:19s\n",
            "epoch 67 | loss: 13253579530.16607|  1:36:19s\n",
            "epoch 67 | loss: 10718304384.46209|  1:36:20s\n",
            "epoch 67 | loss: 2882851725.86282|  1:36:21s\n",
            "epoch 67 | loss: 10771052192.80866|  1:36:22s\n",
            "epoch 67 | loss: 12139112277.02527|  1:36:23s\n",
            "epoch 66 | loss: 3188751375.01805|  1:36:26s\n",
            "epoch 67 | loss: 11101561836.12996|  1:36:27s\n",
            "epoch 67 | loss: 11849491011.69675|  1:36:29s\n",
            "epoch 68 | loss: 2754999636.10108|  1:36:31s\n",
            "epoch 68 | loss: 12530736289.27076|  1:36:32s\n",
            "epoch 68 | loss: 10777437284.27437|  1:36:32s\n",
            "epoch 68 | loss: 3061184593.55957|  1:36:33s\n",
            "epoch 68 | loss: 11299753896.8953|  1:36:34s\n",
            "epoch 68 | loss: 12271920197.31408|  1:36:35s\n",
            "epoch 67 | loss: 3165410791.97112|  1:36:38s\n",
            "epoch 68 | loss: 11167735076.50541|  1:36:40s\n",
            "epoch 68 | loss: 12019458737.44406|  1:36:42s\n",
            "epoch 69 | loss: 2833128165.66065|  1:36:44s\n",
            "epoch 69 | loss: 10763349264.86643|  1:36:44s\n",
            "epoch 69 | loss: 12401476167.62455|  1:36:44s\n",
            "epoch 69 | loss: 2864416085.02527|  1:36:46s\n",
            "epoch 69 | loss: 11101816185.99278|  1:36:47s\n",
            "epoch 69 | loss: 12125907488.34657|  1:36:48s\n",
            "epoch 68 | loss: 3259262844.5343|  1:42:48s\n",
            "epoch 69 | loss: 11129097811.87004|  1:42:50s\n",
            "epoch 69 | loss: 11963187262.84477|  1:42:52s\n",
            "epoch 70 | loss: 2721684395.89892|  1:42:53s\n",
            "epoch 70 | loss: 10656825300.56317|  1:42:54s\n",
            "epoch 70 | loss: 12438555085.16967|  1:42:54s\n",
            "epoch 70 | loss: 2741849316.96751|  1:42:55s\n",
            "epoch 70 | loss: 11098381910.6426|  1:42:57s\n",
            "epoch 70 | loss: 12306585091.69675|  1:42:58s\n",
            "epoch 69 | loss: 3213547356.18773|  1:43:01s\n",
            "epoch 70 | loss: 11061666786.19494|  1:43:03s\n",
            "epoch 70 | loss: 11896248120.6065|  1:43:04s\n",
            "epoch 71 | loss: 2629364531.29242|  1:43:05s\n",
            "epoch 71 | loss: 10557178366.84477|  1:43:06s\n",
            "epoch 71 | loss: 12226467023.94224|  1:43:06s\n",
            "epoch 71 | loss: 2850784383.76895|  1:43:08s\n",
            "epoch 71 | loss: 11153049494.1805|  1:43:09s\n",
            "epoch 71 | loss: 12311931828.6787|  1:43:10s\n",
            "epoch 70 | loss: 3258011778.31047|  1:43:13s\n",
            "epoch 71 | loss: 11136535460.04332|  1:43:15s\n",
            "epoch 71 | loss: 12057430087.62455|  1:43:17s\n",
            "epoch 72 | loss: 2865540028.99639|  1:43:17s\n",
            "epoch 72 | loss: 10728668552.54874|  1:43:18s\n",
            "epoch 72 | loss: 12259488524.93863|  1:43:18s\n",
            "epoch 72 | loss: 2935983414.75812|  1:43:20s\n",
            "epoch 72 | loss: 10939849597.68953|  1:43:21s\n",
            "epoch 72 | loss: 11966390358.41156|  1:43:22s\n",
            "epoch 71 | loss: 3032152711.3935|  1:43:26s\n",
            "epoch 72 | loss: 11225360640.69314|  1:43:27s\n",
            "epoch 72 | loss: 11929757751.2202|  1:43:29s\n",
            "epoch 73 | loss: 2963637430.06498|  1:43:29s\n",
            "epoch 73 | loss: 10645577158.70036|  1:43:30s\n",
            "epoch 73 | loss: 12270532039.62455|  1:43:30s\n",
            "epoch 73 | loss: 3009707303.74007|  1:43:33s\n",
            "epoch 73 | loss: 10840941313.38628|  1:43:33s\n",
            "epoch 73 | loss: 12127900360.31769|  1:43:34s\n",
            "epoch 72 | loss: 3111514201.64621|  1:43:39s\n",
            "epoch 73 | loss: 10970884021.37184|  1:43:40s\n",
            "epoch 73 | loss: 12001187024.86644|  1:43:41s\n",
            "epoch 74 | loss: 2955656472.02888|  1:43:42s\n",
            "epoch 74 | loss: 10848582037.02527|  1:43:42s\n",
            "epoch 74 | loss: 12322236416.4621|  1:43:42s\n",
            "epoch 74 | loss: 3293512639.53791|  1:43:45s\n",
            "epoch 74 | loss: 10788558135.91336|  1:43:46s\n",
            "epoch 74 | loss: 12445095859.29243|  1:43:47s\n",
            "epoch 73 | loss: 3202577196.36101|  1:43:51s\n",
            "epoch 74 | loss: 11129060379.95668|  1:43:52s\n",
            "epoch 74 | loss: 11861364109.63178|  1:43:54s\n",
            "epoch 75 | loss: 2646232108.12996|  1:43:54s\n",
            "epoch 75 | loss: 12219912399.48015|  1:43:54s\n",
            "epoch 75 | loss: 10555589934.20938|  1:43:54s\n",
            "epoch 75 | loss: 2792229333.71841|  1:43:57s\n",
            "epoch 75 | loss: 10882481474.54151|  1:43:58s\n",
            "epoch 75 | loss: 12326396263.04693|  1:43:59s\n",
            "epoch 74 | loss: 3196447966.4982|  1:44:04s\n",
            "epoch 75 | loss: 11294982233.87726|  1:44:05s\n",
            "epoch 76 | loss: 12451972601.99278|  1:44:06s\n",
            "epoch 75 | loss: 11868646419.1769|  1:44:06s\n",
            "epoch 76 | loss: 3020988185.41516|  1:44:06s\n",
            "epoch 76 | loss: 10812685899.09025|  1:44:06s\n",
            "epoch 76 | loss: 2857617115.03249|  1:44:09s\n",
            "epoch 76 | loss: 10994194405.8917|  1:44:10s\n",
            "epoch 76 | loss: 12215788349.45848|  1:44:11s\n",
            "epoch 75 | loss: 3095055547.61011|  1:44:16s\n",
            "epoch 76 | loss: 11120941606.81588|  1:44:17s\n",
            "epoch 77 | loss: 12274499335.8556|  1:44:18s\n",
            "epoch 77 | loss: 2928643806.72924|  1:44:18s\n",
            "epoch 77 | loss: 10643579477.02527|  1:44:18s\n",
            "epoch 76 | loss: 12123062450.36823|  1:44:18s\n",
            "epoch 77 | loss: 2696544146.25271|  1:44:22s\n",
            "epoch 77 | loss: 10930505264.28881|  1:44:23s\n",
            "epoch 77 | loss: 11840509627.14802|  1:44:24s\n",
            "epoch 76 | loss: 3178902077.45848|  1:44:29s\n",
            "epoch 77 | loss: 10916569661.45848|  1:44:30s\n",
            "epoch 78 | loss: 12023437767.16246|  1:44:30s\n",
            "epoch 78 | loss: 10598521447.27798|  1:44:31s\n",
            "epoch 78 | loss: 2931314928.7509|  1:44:31s\n",
            "epoch 77 | loss: 11948377770.28158|  1:44:31s\n",
            "epoch 78 | loss: 3035750429.34296|  1:44:34s\n",
            "epoch 78 | loss: 10899005882.68592|  1:44:35s\n",
            "epoch 78 | loss: 11950337240.25993|  1:44:36s\n",
            "epoch 77 | loss: 3176639375.94224|  1:44:42s\n",
            "epoch 79 | loss: 12126984549.66065|  1:44:43s\n",
            "epoch 78 | loss: 10668324986.91697|  1:44:43s\n",
            "epoch 79 | loss: 10872393148.76534|  1:44:43s\n",
            "epoch 79 | loss: 2783588976.28881|  1:44:43s\n",
            "epoch 78 | loss: 11743563641.06859|  1:44:43s\n",
            "epoch 79 | loss: 2971493431.91336|  1:44:46s\n",
            "epoch 79 | loss: 10986088064.46209|  1:44:48s\n",
            "epoch 79 | loss: 12217000349.57402|  1:44:49s\n",
            "epoch 78 | loss: 3322986904.49098|  1:44:55s\n",
            "epoch 79 | loss: 11056130259.63899|  1:44:55s\n",
            "epoch 80 | loss: 12107186235.14802|  1:44:55s\n",
            "epoch 80 | loss: 10604850983.97111|  1:44:55s\n",
            "epoch 80 | loss: 2722267640.6065|  1:44:56s\n",
            "epoch 79 | loss: 11875521077.37184|  1:44:56s\n",
            "epoch 80 | loss: 2760867997.57401|  1:54:02s\n",
            "epoch 80 | loss: 10857493136.40433|  1:54:04s\n",
            "epoch 80 | loss: 11915637665.73285|  1:54:05s\n",
            "epoch 81 | loss: 10882897393.67509|  1:54:14s\n",
            "epoch 79 | loss: 3311746254.787|  1:54:14s\n",
            "epoch 81 | loss: 12216527495.3935|  1:54:14s\n",
            "epoch 80 | loss: 10846161354.62816|  1:54:14s\n",
            "epoch 81 | loss: 2664516966.81588|  1:54:14s\n",
            "epoch 80 | loss: 11802994440.31769|  1:54:16s\n",
            "epoch 81 | loss: 2758601056.11552|  1:54:19s\n",
            "epoch 81 | loss: 11128683138.54151|  1:54:21s\n",
            "epoch 81 | loss: 11752648167.74007|  1:54:23s\n",
            "epoch 82 | loss: 11794731312.05776|  1:54:30s\n",
            "epoch 82 | loss: 10665200912.17328|  1:54:30s\n",
            "epoch 81 | loss: 10708360477.80506|  1:54:30s\n",
            "epoch 80 | loss: 3199015339.66787|  1:54:31s\n",
            "epoch 82 | loss: 2845179939.81227|  1:54:31s\n",
            "epoch 81 | loss: 11604381164.12996|  1:54:32s\n",
            "epoch 82 | loss: 3144723822.90253|  1:54:36s\n",
            "epoch 82 | loss: 11103241388.12996|  1:54:38s\n",
            "epoch 82 | loss: 12007195311.59567|  1:54:39s\n",
            "epoch 83 | loss: 12214993438.0361|  1:54:47s\n",
            "epoch 83 | loss: 10476351698.25271|  1:54:47s\n",
            "epoch 82 | loss: 10778308292.15885|  1:54:47s\n",
            "epoch 81 | loss: 3180241623.10469|  1:54:48s\n",
            "epoch 83 | loss: 2710148960.34657|  1:54:48s\n",
            "epoch 82 | loss: 11814463573.02528|  1:54:49s\n",
            "epoch 83 | loss: 2757827629.2852|  1:54:52s\n",
            "epoch 83 | loss: 10787343915.89892|  1:54:54s\n",
            "epoch 83 | loss: 11938446373.42961|  1:54:55s\n",
            "epoch 84 | loss: 11960911435.3213|  1:55:01s\n",
            "epoch 84 | loss: 10722941454.09386|  1:55:01s\n",
            "epoch 83 | loss: 10600152262.9314|  1:55:02s\n",
            "epoch 84 | loss: 3121607492.38989|  1:55:02s\n",
            "epoch 82 | loss: 3280066446.55596|  1:55:02s\n",
            "epoch 83 | loss: 11694900820.79423|  1:55:03s\n",
            "epoch 84 | loss: 3467521052.88087|  1:55:07s\n",
            "epoch 84 | loss: 10778858909.11191|  1:55:08s\n",
            "epoch 84 | loss: 11976178728.43321|  1:55:10s\n",
            "epoch 85 | loss: 12007367631.94224|  1:55:16s\n",
            "epoch 85 | loss: 10901085794.88809|  1:55:16s\n",
            "epoch 84 | loss: 10808644508.18773|  1:55:17s\n",
            "epoch 85 | loss: 2767573504.92419|  1:55:17s\n",
            "epoch 83 | loss: 3662619893.37184|  1:55:17s\n",
            "epoch 84 | loss: 11692610654.49819|  1:55:18s\n",
            "epoch 85 | loss: 2999099933.57401|  1:55:21s\n",
            "epoch 85 | loss: 10752984135.62455|  1:55:22s\n",
            "epoch 85 | loss: 12024605382.70036|  1:55:24s\n",
            "epoch 86 | loss: 11699387776.92419|  1:55:29s\n",
            "epoch 86 | loss: 10849193760.34657|  1:55:30s\n",
            "epoch 85 | loss: 10745235567.13357|  1:55:30s\n",
            "epoch 86 | loss: 2570999722.51264|  1:55:30s\n",
            "epoch 85 | loss: 11812528543.65343|  1:55:31s\n",
            "epoch 84 | loss: 3685427885.74729|  1:55:31s\n",
            "epoch 86 | loss: 3070535820.01444|  1:55:34s\n",
            "epoch 86 | loss: 10694203137.38628|  1:55:35s\n",
            "epoch 86 | loss: 11726825502.0361|  1:55:37s\n",
            "epoch 87 | loss: 12060049018.45488|  1:55:42s\n",
            "epoch 87 | loss: 10229820244.10108|  1:55:42s\n",
            "epoch 87 | loss: 2814920285.80505|  1:55:43s\n",
            "epoch 86 | loss: 10692189416.20217|  1:55:43s\n",
            "epoch 86 | loss: 11610852409.76173|  1:55:44s\n",
            "epoch 85 | loss: 3678627260.99639|  1:55:44s\n",
            "epoch 87 | loss: 2743471174.93141|  1:55:47s\n",
            "epoch 87 | loss: 10699069240.6065|  1:55:49s\n",
            "epoch 87 | loss: 12060907904.4621|  1:55:51s\n",
            "epoch 88 | loss: 12440346919.74008|  1:55:55s\n",
            "epoch 88 | loss: 10239440448.92418|  1:55:56s\n",
            "epoch 88 | loss: 2523792963.69675|  1:55:56s\n",
            "epoch 87 | loss: 10107525965.16968|  1:55:56s\n",
            "epoch 87 | loss: 11490088763.61011|  1:55:58s\n",
            "epoch 86 | loss: 3743774993.55957|  1:55:58s\n",
            "epoch 88 | loss: 2645447005.57401|  1:56:00s\n",
            "epoch 88 | loss: 10551674681.06859|  1:56:01s\n",
            "epoch 88 | loss: 12154780499.40794|  1:56:03s\n",
            "epoch 89 | loss: 12046507514.91697|  1:56:07s\n",
            "epoch 89 | loss: 10591524947.87004|  1:56:08s\n",
            "epoch 89 | loss: 2538832281.64621|  1:56:09s\n",
            "epoch 88 | loss: 10571446297.87726|  1:56:09s\n",
            "epoch 88 | loss: 11098465198.67148|  1:56:11s\n",
            "epoch 87 | loss: 3669922257.32852|  1:56:12s\n",
            "epoch 89 | loss: 2811862078.61372|  1:56:14s\n",
            "epoch 89 | loss: 10596215959.33574|  1:56:15s\n",
            "epoch 89 | loss: 11553045902.32491|  1:56:17s\n",
            "epoch 90 | loss: 12083562533.8917|  1:56:21s\n",
            "epoch 90 | loss: 10287241874.94585|  1:56:21s\n",
            "epoch 90 | loss: 2529774490.1083|  1:56:22s\n",
            "epoch 89 | loss: 10441494429.34296|  1:56:23s\n",
            "epoch 89 | loss: 11480574720.23104|  1:56:24s\n",
            "epoch 88 | loss: 3660760182.29603|  1:56:25s\n",
            "epoch 90 | loss: 3031430726.23827|  1:56:28s\n",
            "epoch 90 | loss: 10920415945.93502|  1:56:29s\n",
            "epoch 90 | loss: 11728222813.57401|  1:56:31s\n",
            "epoch 91 | loss: 12421504132.15884|  1:56:35s\n",
            "epoch 91 | loss: 10594043285.94946|  1:56:35s\n",
            "epoch 91 | loss: 2775974449.90614|  1:56:37s\n",
            "epoch 90 | loss: 10724109120.23105|  1:56:38s\n",
            "epoch 90 | loss: 10893619347.40794|  1:56:39s\n",
            "epoch 89 | loss: 3621418956.24549|  1:56:41s\n",
            "epoch 91 | loss: 2785808665.87726|  1:56:42s\n",
            "epoch 91 | loss: 10703822457.29964|  1:56:44s\n",
            "epoch 91 | loss: 11431257424.86642|  1:56:47s\n",
            "epoch 92 | loss: 11399214483.40794|  1:56:50s\n",
            "epoch 92 | loss: 11258456510.15162|  1:56:51s\n",
            "epoch 92 | loss: 2642737357.40072|  1:56:52s\n",
            "epoch 91 | loss: 11080961497.64621|  1:56:53s\n",
            "epoch 91 | loss: 10743066007.33574|  1:56:55s\n",
            "epoch 90 | loss: 3642163976.31769|  1:56:57s\n",
            "epoch 92 | loss: 2755745483.09025|  1:56:59s\n",
            "epoch 92 | loss: 10494369748.10108|  1:57:01s\n",
            "epoch 92 | loss: 11448577299.40794|  1:57:04s\n",
            "epoch 93 | loss: 11795158028.93863|  1:57:08s\n",
            "epoch 93 | loss: 10994393090.77256|  1:57:08s\n",
            "epoch 93 | loss: 2484409003.89892|  1:57:10s\n",
            "epoch 92 | loss: 10630438672.17328|  1:57:11s\n",
            "epoch 92 | loss: 11071684648.66426|  1:57:13s\n",
            "epoch 91 | loss: 3665372934.93141|  1:57:15s\n",
            "epoch 93 | loss: 2643835471.01805|  1:57:15s\n",
            "epoch 93 | loss: 10651711764.33213|  1:57:17s\n",
            "epoch 93 | loss: 11578994292.90974|  1:57:21s\n",
            "epoch 94 | loss: 11120049131.66787|  1:57:24s\n",
            "epoch 94 | loss: 10547580208.51986|  1:57:24s\n",
            "epoch 94 | loss: 2807979501.2852|  1:57:26s\n",
            "epoch 93 | loss: 10473754424.83754|  1:57:27s\n",
            "epoch 93 | loss: 11640861073.79061|  1:57:30s\n",
            "epoch 92 | loss: 3712203495.50902|  1:57:32s\n",
            "epoch 94 | loss: 2754632940.8231|  1:57:32s\n",
            "epoch 94 | loss: 10634564507.26354|  1:57:34s\n",
            "epoch 94 | loss: 11823141848.72202|  1:57:38s\n",
            "epoch 95 | loss: 10990987781.77617|  1:57:40s\n",
            "epoch 95 | loss: 9762978759.3935|  1:57:41s\n",
            "epoch 95 | loss: 2822518658.07942|  1:57:43s\n",
            "epoch 94 | loss: 10436391502.32491|  1:57:43s\n",
            "epoch 94 | loss: 10572729094.93141|  1:57:46s\n",
            "epoch 93 | loss: 3727273246.96029|  1:57:48s\n",
            "epoch 95 | loss: 2644224195.00361|  1:57:49s\n",
            "epoch 95 | loss: 10598699375.59567|  1:57:50s\n",
            "epoch 95 | loss: 11367175530.51264|  1:57:54s\n",
            "epoch 96 | loss: 11934770666.74368|  1:57:55s\n",
            "epoch 96 | loss: 10444023555.69675|  1:57:55s\n",
            "epoch 96 | loss: 2670923111.74007|  1:57:57s\n",
            "epoch 95 | loss: 10539949530.80144|  1:57:57s\n",
            "epoch 95 | loss: 10570321311.19134|  1:58:00s\n",
            "epoch 96 | loss: 2828527408.28881|  1:58:02s\n",
            "epoch 94 | loss: 3771390430.72924|  1:58:02s\n",
            "epoch 96 | loss: 10454826780.18772|  1:58:03s\n",
            "epoch 96 | loss: 11488774350.09386|  1:58:07s\n",
            "epoch 97 | loss: 11516106261.25632|  1:58:08s\n",
            "epoch 97 | loss: 10294115565.28519|  1:58:08s\n",
            "epoch 97 | loss: 2696799023.82671|  1:58:11s\n",
            "epoch 96 | loss: 10592664526.55596|  1:58:11s\n",
            "epoch 96 | loss: 11898260537.53069|  1:58:14s\n",
            "epoch 97 | loss: 2560266041.06859|  1:58:16s\n",
            "epoch 95 | loss: 4104171654.93141|  1:58:16s\n",
            "epoch 97 | loss: 10577164372.33213|  1:58:17s\n",
            "epoch 97 | loss: 11942174679.56679|  1:58:21s\n",
            "epoch 98 | loss: 10593025267.52347|  1:58:21s\n",
            "epoch 98 | loss: 10976559462.58484|  1:58:21s\n",
            "epoch 98 | loss: 2671532990.61372|  1:58:23s\n",
            "epoch 97 | loss: 10465061236.6787|  1:58:24s\n",
            "epoch 97 | loss: 10731921136.7509|  1:58:27s\n",
            "epoch 98 | loss: 2656086058.28159|  1:58:28s\n",
            "epoch 96 | loss: 4560731305.58845|  1:58:29s\n",
            "epoch 98 | loss: 10471787086.787|  1:58:31s\n",
            "epoch 99 | loss: 10674942709.83394|  1:58:34s\n",
            "epoch 98 | loss: 11661174101.02528|  1:58:34s\n",
            "epoch 99 | loss: 11457770379.55235|  1:58:35s\n",
            "epoch 99 | loss: 2569352570.68592|  1:58:37s\n",
            "epoch 98 | loss: 10531949510.93141|  1:58:38s\n",
            "epoch 98 | loss: 10922953526.29603|  1:58:42s\n",
            "epoch 99 | loss: 2571327313.79061|  1:58:44s\n",
            "epoch 97 | loss: 4556729191.04693|  1:58:45s\n",
            "epoch 99 | loss: 10496622628.73646|  1:58:46s\n",
            "epoch 99 | loss: 11916358329.53069|  1:58:51s\n",
            "epoch 99 | loss: 10451295106.07942|  1:58:54s\n",
            "epoch 99 | loss: 11086560935.04693|  1:58:56s\n",
            "epoch 98 | loss: 4535707308.36101|  1:58:59s\n",
            "epoch 99 | loss: 4587024461.63177|  1:59:11s\n",
            "[CV] END .........................................gamma=1.3; total time=119.7min\n",
            "[CV] END .........................................gamma=1.3; total time=119.7min\n",
            "[CV] END .........................................gamma=1.0; total time=119.8min\n",
            "[CV] END .........................................gamma=1.3; total time=119.9min\n",
            "[CV] END .........................................gamma=1.5; total time=119.9min\n",
            "[CV] END .........................................gamma=1.5; total time=120.0min\n",
            "[CV] END .........................................gamma=1.0; total time=120.0min\n",
            "[CV] END .........................................gamma=1.0; total time=120.0min\n",
            "[CV] END .........................................gamma=1.5; total time=120.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19858774012.29878|  0:00:24s\n",
            "epoch 1  | loss: 16626380329.94698|  0:00:46s\n",
            "epoch 2  | loss: 13734856187.06506|  0:01:09s\n",
            "epoch 3  | loss: 11967469119.84578|  0:01:31s\n",
            "epoch 4  | loss: 11140862823.3253|  0:01:53s\n",
            "epoch 5  | loss: 10767987757.64819|  0:02:15s\n",
            "epoch 6  | loss: 10700816300.7229|  0:02:38s\n",
            "epoch 7  | loss: 10649708791.98072|  0:03:01s\n",
            "epoch 8  | loss: 10556293503.0747|  0:03:25s\n",
            "epoch 9  | loss: 10462526060.87711|  0:03:47s\n",
            "epoch 10 | loss: 10468601938.66024|  0:04:09s\n",
            "epoch 11 | loss: 10407115454.30362|  0:04:31s\n",
            "epoch 12 | loss: 10359140638.53494|  0:04:54s\n",
            "epoch 13 | loss: 10258373208.82891|  0:05:17s\n",
            "epoch 14 | loss: 10230304208.80964|  0:05:39s\n",
            "epoch 15 | loss: 10156730491.06505|  0:06:00s\n",
            "epoch 16 | loss: 10047060157.37831|  0:06:22s\n",
            "epoch 17 | loss: 10011075499.33494|  0:06:44s\n",
            "epoch 18 | loss: 9998148906.25542|  0:07:07s\n",
            "epoch 19 | loss: 9939550527.22891|  0:07:29s\n",
            "epoch 20 | loss: 9878296922.67951|  0:07:51s\n",
            "epoch 21 | loss: 9831174171.14216|  0:08:14s\n",
            "epoch 22 | loss: 9728636112.96384|  0:08:37s\n",
            "epoch 23 | loss: 9646079236.6265|  0:09:01s\n",
            "epoch 24 | loss: 9609068869.55182|  0:09:25s\n",
            "epoch 25 | loss: 9612012593.96627|  0:09:49s\n",
            "epoch 26 | loss: 9454804861.53254|  0:10:10s\n",
            "epoch 27 | loss: 9488280135.71084|  0:10:32s\n",
            "epoch 28 | loss: 9595254547.43131|  0:10:55s\n",
            "epoch 29 | loss: 9530399869.2241|  0:11:17s\n",
            "epoch 30 | loss: 9376267477.74458|  0:11:39s\n",
            "epoch 31 | loss: 9349826688.92529|  0:12:01s\n",
            "epoch 32 | loss: 9346972140.72289|  0:12:22s\n",
            "epoch 33 | loss: 9314730700.64579|  0:12:45s\n",
            "epoch 34 | loss: 9217288377.52289|  0:13:08s\n",
            "epoch 35 | loss: 9228536842.33253|  0:13:31s\n",
            "epoch 36 | loss: 9137056926.68916|  0:13:54s\n",
            "epoch 37 | loss: 9212321268.58794|  0:14:17s\n",
            "epoch 38 | loss: 9099756741.3976|  0:14:39s\n",
            "epoch 39 | loss: 9116269245.68674|  0:15:01s\n",
            "epoch 40 | loss: 9001096114.12048|  0:15:23s\n",
            "epoch 41 | loss: 9024959682.00482|  0:15:45s\n",
            "epoch 42 | loss: 9051203267.23856|  0:16:07s\n",
            "epoch 43 | loss: 8987301949.53252|  0:16:30s\n",
            "epoch 44 | loss: 8989354101.20482|  0:16:52s\n",
            "epoch 45 | loss: 8973023389.91809|  0:17:14s\n",
            "epoch 46 | loss: 8885329656.44337|  0:17:37s\n",
            "epoch 47 | loss: 9031082246.3229|  0:17:58s\n",
            "epoch 48 | loss: 9018028944.03855|  0:18:19s\n",
            "epoch 49 | loss: 8879290838.36144|  0:18:41s\n",
            "epoch 50 | loss: 8904371497.94699|  0:19:02s\n",
            "epoch 51 | loss: 8820324880.03855|  0:19:22s\n",
            "epoch 52 | loss: 8718334568.86747|  0:19:44s\n",
            "epoch 53 | loss: 8674960281.6|  0:20:05s\n",
            "epoch 54 | loss: 8797803775.38314|  0:20:27s\n",
            "epoch 55 | loss: 8731448648.01929|  0:20:48s\n",
            "epoch 56 | loss: 8905657666.00483|  0:21:09s\n",
            "epoch 57 | loss: 8841393736.17349|  0:21:30s\n",
            "epoch 58 | loss: 8943769936.34699|  0:21:51s\n",
            "epoch 59 | loss: 8652775464.09638|  0:22:13s\n",
            "epoch 60 | loss: 8856996982.74697|  0:22:34s\n",
            "epoch 61 | loss: 9023999928.28916|  0:22:55s\n",
            "epoch 62 | loss: 8834332734.76626|  0:23:16s\n",
            "epoch 63 | loss: 8643295743.53735|  0:23:38s\n",
            "epoch 64 | loss: 8548920545.92772|  0:23:59s\n",
            "epoch 65 | loss: 8691922504.94458|  0:24:20s\n",
            "epoch 66 | loss: 8783268737.07951|  0:24:41s\n",
            "epoch 67 | loss: 8696804006.70844|  0:25:03s\n",
            "epoch 68 | loss: 8767960289.61927|  0:25:24s\n",
            "epoch 69 | loss: 8512483270.78554|  0:25:45s\n",
            "epoch 70 | loss: 8556517985.31084|  0:26:06s\n",
            "epoch 71 | loss: 8620942319.49878|  0:26:28s\n",
            "epoch 72 | loss: 8582336503.82649|  0:26:49s\n",
            "epoch 73 | loss: 8675831191.44096|  0:27:10s\n",
            "epoch 74 | loss: 8383680599.13254|  0:27:32s\n",
            "epoch 75 | loss: 8903214758.86265|  0:27:53s\n",
            "epoch 76 | loss: 8699141478.86265|  0:28:15s\n",
            "epoch 77 | loss: 8626403602.81446|  0:28:37s\n",
            "epoch 78 | loss: 8694956571.29637|  0:28:58s\n",
            "epoch 79 | loss: 7913899591.71085|  0:29:20s\n",
            "epoch 80 | loss: 8652013766.3229|  0:29:41s\n",
            "epoch 81 | loss: 8650164923.06505|  0:30:03s\n",
            "epoch 82 | loss: 7961233001.33012|  0:30:25s\n",
            "epoch 83 | loss: 8198381054.61206|  0:30:46s\n",
            "epoch 84 | loss: 7927412601.83133|  0:31:08s\n",
            "epoch 85 | loss: 8362171361.15662|  0:31:29s\n",
            "epoch 86 | loss: 8507386988.26024|  0:31:51s\n",
            "epoch 87 | loss: 8267645529.29158|  0:32:12s\n",
            "epoch 88 | loss: 8240927170.00481|  0:32:34s\n",
            "epoch 89 | loss: 8280607322.37109|  0:32:56s\n",
            "epoch 90 | loss: 8267463957.59035|  0:33:17s\n",
            "epoch 91 | loss: 8282244620.49156|  0:33:39s\n",
            "epoch 92 | loss: 8234534937.6|  0:34:00s\n",
            "epoch 93 | loss: 7921019829.20483|  0:34:21s\n",
            "epoch 94 | loss: 8117499030.82409|  0:34:42s\n",
            "epoch 95 | loss: 8214947970.46746|  0:35:04s\n",
            "epoch 96 | loss: 7998575597.8024|  0:35:25s\n",
            "epoch 97 | loss: 8327061821.99518|  0:35:46s\n",
            "epoch 98 | loss: 7430324366.34216|  0:36:07s\n",
            "epoch 99 | loss: 8412912772.00964|  0:36:28s\n",
            "Лучшие параметры: {'gamma': 1.0}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'gamma': [1.0, 1.3, 1.5],\n",
        "}\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_d=32, n_a=16, n_steps=3, gamma=1.3, lambda_sparse=1e-3):\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.lambda_sparse = lambda_sparse\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = TabNetRegressor(\n",
        "            n_d=self.n_d,\n",
        "            n_a=self.n_a,\n",
        "            n_steps=self.n_steps,\n",
        "            gamma=self.gamma,\n",
        "            lambda_sparse=self.lambda_sparse\n",
        "        )\n",
        "        self.model.fit(X, y.reshape(-1, 1))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "model = TabNetWrapper()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Лучшие параметры: {best_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**lambda_sparse**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 22344680285.34296|  0:00:15s\n",
            "epoch 0  | loss: 24039331440.7509|  0:00:15s\n",
            "epoch 0  | loss: 24061082694.23826|  0:00:15s\n",
            "epoch 0  | loss: 22317042872.83754|  0:00:15s\n",
            "epoch 0  | loss: 14529660092.5343|  0:00:15s\n",
            "epoch 0  | loss: 14521496309.83393|  0:00:15s\n",
            "epoch 0  | loss: 14537697997.16968|  0:00:15s\n",
            "epoch 0  | loss: 14505098849.9639|  0:00:15s\n",
            "epoch 0  | loss: 22330558123.89892|  0:00:16s\n",
            "epoch 0  | loss: 24048653016.25993|  0:00:15s\n",
            "epoch 0  | loss: 24051531276.93863|  0:00:16s\n",
            "epoch 0  | loss: 22334245503.53791|  0:00:16s\n",
            "epoch 1  | loss: 12608565467.95668|  0:00:31s\n",
            "epoch 1  | loss: 20353156079.36462|  0:00:31s\n",
            "epoch 1  | loss: 12550505634.65704|  0:00:32s\n",
            "epoch 1  | loss: 21934225640.8953|  0:00:32s\n",
            "epoch 1  | loss: 22016248443.84115|  0:00:32s\n",
            "epoch 1  | loss: 12411272044.12996|  0:00:32s\n",
            "epoch 1  | loss: 12567084891.49459|  0:00:32s\n",
            "epoch 1  | loss: 21936093749.60288|  0:00:32s\n",
            "epoch 1  | loss: 21857595196.0722|  0:00:32s\n",
            "epoch 1  | loss: 20287179753.81951|  0:00:32s\n",
            "epoch 1  | loss: 20292027136.92418|  0:00:32s\n",
            "epoch 1  | loss: 20373384800.11552|  0:00:32s\n",
            "epoch 2  | loss: 10267302960.05777|  0:00:49s\n",
            "epoch 2  | loss: 17949239832.02889|  0:00:49s\n",
            "epoch 2  | loss: 10081134998.64259|  0:00:50s\n",
            "epoch 2  | loss: 10102871720.20217|  0:00:50s\n",
            "epoch 2  | loss: 19746914594.19495|  0:00:50s\n",
            "epoch 2  | loss: 10263686554.33935|  0:00:50s\n",
            "epoch 2  | loss: 19432591799.91336|  0:00:50s\n",
            "epoch 2  | loss: 17882004097.38628|  0:00:50s\n",
            "epoch 2  | loss: 18218714187.7834|  0:00:50s\n",
            "epoch 2  | loss: 19716876424.77978|  0:00:50s\n",
            "epoch 2  | loss: 19548371284.10108|  0:00:50s\n",
            "epoch 2  | loss: 18052203091.1769|  0:00:50s\n",
            "epoch 3  | loss: 8324011367.50902|  0:01:07s\n",
            "epoch 3  | loss: 8062221383.16246|  0:01:08s\n",
            "epoch 3  | loss: 15904496627.06138|  0:01:08s\n",
            "epoch 3  | loss: 8415683596.93863|  0:01:08s\n",
            "epoch 3  | loss: 8288552740.96751|  0:01:09s\n",
            "epoch 3  | loss: 17488559933.92058|  0:01:09s\n",
            "epoch 3  | loss: 17843716278.06497|  0:01:09s\n",
            "epoch 3  | loss: 16428318701.51626|  0:01:09s\n",
            "epoch 3  | loss: 16056871607.91335|  0:01:09s\n",
            "epoch 3  | loss: 17608514973.11191|  0:01:09s\n",
            "epoch 3  | loss: 17913513205.83394|  0:01:09s\n",
            "epoch 3  | loss: 16067706873.5307|  0:01:09s\n",
            "epoch 4  | loss: 6672894163.63899|  0:01:24s\n",
            "epoch 4  | loss: 7022285367.45126|  0:01:25s\n",
            "epoch 4  | loss: 14431977236.33212|  0:01:25s\n",
            "epoch 4  | loss: 7043172876.01444|  0:01:25s\n",
            "epoch 4  | loss: 16488458720.57761|  0:01:26s\n",
            "epoch 4  | loss: 16113354745.99278|  0:01:26s\n",
            "epoch 4  | loss: 15020387969.38628|  0:01:26s\n",
            "epoch 4  | loss: 6967512385.61733|  0:01:26s\n",
            "epoch 4  | loss: 16639803577.76174|  0:01:26s\n",
            "epoch 4  | loss: 16329562598.12273|  0:01:26s\n",
            "epoch 4  | loss: 14780397912.72202|  0:01:26s\n",
            "epoch 4  | loss: 14708493690.91697|  0:01:27s\n",
            "epoch 5  | loss: 6221083271.3935|  0:01:41s\n",
            "epoch 5  | loss: 5849266001.79061|  0:01:42s\n",
            "epoch 5  | loss: 13622700617.93502|  0:01:42s\n",
            "epoch 5  | loss: 6142624140.01444|  0:01:42s\n",
            "epoch 5  | loss: 15295276515.81228|  0:01:43s\n",
            "epoch 5  | loss: 15559714148.27436|  0:01:43s\n",
            "epoch 5  | loss: 14126127149.2852|  0:01:43s\n",
            "epoch 5  | loss: 6157082736.7509|  0:01:43s\n",
            "epoch 5  | loss: 15476732356.85199|  0:01:44s\n",
            "epoch 5  | loss: 15745843579.84114|  0:01:44s\n",
            "epoch 5  | loss: 13812597045.1408|  0:01:44s\n",
            "epoch 5  | loss: 13891789838.787|  0:01:44s\n",
            "epoch 6  | loss: 5698074230.29603|  0:01:59s\n",
            "epoch 6  | loss: 5405125311.76895|  0:01:59s\n",
            "epoch 6  | loss: 13150361081.53068|  0:02:00s\n",
            "epoch 6  | loss: 5573264919.56679|  0:02:01s\n",
            "epoch 6  | loss: 15028472534.87363|  0:02:01s\n",
            "epoch 6  | loss: 14906515957.37184|  0:02:01s\n",
            "epoch 6  | loss: 13496552547.81227|  0:02:02s\n",
            "epoch 6  | loss: 5581043404.24549|  0:02:02s\n",
            "epoch 6  | loss: 15060837543.74008|  0:02:02s\n",
            "epoch 6  | loss: 15201613529.64622|  0:02:02s\n",
            "epoch 6  | loss: 13182022620.41876|  0:02:02s\n",
            "epoch 6  | loss: 13324223934.84477|  0:02:03s\n",
            "epoch 7  | loss: 5363980307.87004|  0:02:17s\n",
            "epoch 7  | loss: 5159443057.213|  0:02:18s\n",
            "epoch 7  | loss: 12873369724.76535|  0:02:18s\n",
            "epoch 7  | loss: 5271630684.41877|  0:02:19s\n",
            "epoch 7  | loss: 14789381556.2166|  0:02:19s\n",
            "epoch 7  | loss: 14646025617.55955|  0:02:19s\n",
            "epoch 7  | loss: 13131651064.6065|  0:02:20s\n",
            "epoch 7  | loss: 14738282993.67507|  0:02:20s\n",
            "epoch 7  | loss: 5299619860.33213|  0:02:20s\n",
            "epoch 7  | loss: 13002983823.2491|  0:02:20s\n",
            "epoch 7  | loss: 14810712416.57762|  0:02:20s\n",
            "epoch 7  | loss: 12824724427.3213|  0:02:21s\n",
            "epoch 8  | loss: 5208373302.52707|  0:02:34s\n",
            "epoch 8  | loss: 5057812528.05776|  0:02:35s\n",
            "epoch 8  | loss: 12787650437.54512|  0:02:36s\n",
            "epoch 8  | loss: 5077959484.0722|  0:02:36s\n",
            "epoch 8  | loss: 14613883501.97834|  0:02:37s\n",
            "epoch 8  | loss: 14498971235.35018|  0:02:37s\n",
            "epoch 8  | loss: 12878515715.23464|  0:02:37s\n",
            "epoch 8  | loss: 14582668342.06496|  0:02:38s\n",
            "epoch 8  | loss: 5080634601.3574|  0:02:38s\n",
            "epoch 8  | loss: 12718324390.35379|  0:02:38s\n",
            "epoch 8  | loss: 14559148956.18773|  0:02:38s\n",
            "epoch 8  | loss: 12887138948.15883|  0:02:38s\n",
            "epoch 9  | loss: 5177742514.36823|  0:02:52s\n",
            "epoch 9  | loss: 5023673940.56318|  0:02:53s\n",
            "epoch 9  | loss: 12731258208.11554|  0:02:54s\n",
            "epoch 9  | loss: 5001630002.36823|  0:02:54s\n",
            "epoch 9  | loss: 14403389461.71841|  0:02:55s\n",
            "epoch 9  | loss: 14403971744.80868|  0:02:55s\n",
            "epoch 9  | loss: 14392133811.29243|  0:02:55s\n",
            "epoch 9  | loss: 12800264572.76533|  0:02:55s\n",
            "epoch 9  | loss: 12778028169.24186|  0:02:56s\n",
            "epoch 9  | loss: 5022260021.60289|  0:02:56s\n",
            "epoch 9  | loss: 12652065943.1047|  0:02:56s\n",
            "epoch 9  | loss: 14414905311.19133|  0:02:57s\n",
            "epoch 10 | loss: 5044869605.19856|  0:03:09s\n",
            "epoch 10 | loss: 4921962344.43321|  0:03:09s\n",
            "epoch 10 | loss: 12683759477.37184|  0:03:11s\n",
            "epoch 10 | loss: 4994329503.88448|  0:03:11s\n",
            "epoch 10 | loss: 14267141083.49458|  0:03:11s\n",
            "epoch 10 | loss: 14325121788.30325|  0:03:11s\n",
            "epoch 10 | loss: 14301734595.4657|  0:03:12s\n",
            "epoch 10 | loss: 12692718254.20938|  0:03:12s\n",
            "epoch 10 | loss: 12673770032.05776|  0:03:13s\n",
            "epoch 10 | loss: 4923755789.40072|  0:03:13s\n",
            "epoch 10 | loss: 12608371922.25271|  0:03:13s\n",
            "epoch 10 | loss: 14292680341.25632|  0:03:13s\n",
            "epoch 11 | loss: 4918140244.56318|  0:03:25s\n",
            "epoch 11 | loss: 4867906483.29242|  0:03:25s\n",
            "epoch 11 | loss: 12635908939.32131|  0:03:27s\n",
            "epoch 11 | loss: 4908218378.62816|  0:03:27s\n",
            "epoch 11 | loss: 14244310567.74008|  0:03:27s\n",
            "epoch 11 | loss: 14218480926.96028|  0:03:28s\n",
            "epoch 11 | loss: 14282892527.82672|  0:03:28s\n",
            "epoch 11 | loss: 12671676907.66787|  0:03:28s\n",
            "epoch 11 | loss: 12684023070.0361|  0:03:29s\n",
            "epoch 11 | loss: 4868048444.5343|  0:03:30s\n",
            "epoch 11 | loss: 12605723366.12274|  0:03:30s\n",
            "epoch 11 | loss: 14326458142.96028|  0:03:30s\n",
            "epoch 12 | loss: 4778755415.33574|  0:03:42s\n",
            "epoch 12 | loss: 4874749320.77978|  0:03:42s\n",
            "epoch 12 | loss: 12570611206.93142|  0:03:44s\n",
            "epoch 12 | loss: 4765475782.70036|  0:03:44s\n",
            "epoch 12 | loss: 14186339741.11192|  0:03:45s\n",
            "epoch 12 | loss: 14209716628.79424|  0:03:46s\n",
            "epoch 12 | loss: 14244483990.18051|  0:03:46s\n",
            "epoch 12 | loss: 12570294591.76896|  0:03:46s\n",
            "epoch 12 | loss: 12598961810.02165|  0:03:47s\n",
            "epoch 12 | loss: 4759286943.88448|  0:03:47s\n",
            "epoch 12 | loss: 14303599818.39711|  0:03:48s\n",
            "epoch 12 | loss: 12477890965.7184|  0:03:48s\n",
            "epoch 13 | loss: 4745084455.74007|  0:03:59s\n",
            "epoch 13 | loss: 4853676041.70397|  0:03:59s\n",
            "epoch 13 | loss: 12575502753.73285|  0:04:01s\n",
            "epoch 13 | loss: 4710574595.69675|  0:04:01s\n",
            "epoch 13 | loss: 14116780714.97473|  0:04:01s\n",
            "epoch 13 | loss: 14140075907.0036|  0:04:02s\n",
            "epoch 13 | loss: 14154199215.59567|  0:04:02s\n",
            "epoch 13 | loss: 12554643058.13718|  0:04:02s\n",
            "epoch 13 | loss: 12559460535.45126|  0:04:04s\n",
            "epoch 13 | loss: 4725507772.99639|  0:04:05s\n",
            "epoch 13 | loss: 14283779907.4657|  0:04:05s\n",
            "epoch 13 | loss: 12446507336.08664|  0:04:05s\n",
            "epoch 14 | loss: 4719055363.69675|  0:04:17s\n",
            "epoch 14 | loss: 4834307252.21661|  0:04:17s\n",
            "epoch 14 | loss: 12488253225.12636|  0:04:19s\n",
            "epoch 14 | loss: 4664900487.3935|  0:04:19s\n",
            "epoch 14 | loss: 14090393877.71842|  0:04:19s\n",
            "epoch 14 | loss: 14119542540.01443|  0:04:20s\n",
            "epoch 14 | loss: 14123360494.90252|  0:04:20s\n",
            "epoch 14 | loss: 12535222908.76534|  0:04:21s\n",
            "epoch 14 | loss: 4665860472.6065|  0:04:22s\n",
            "epoch 14 | loss: 12490822498.42598|  0:04:23s\n",
            "epoch 14 | loss: 14313788574.4982|  0:04:23s\n",
            "epoch 14 | loss: 12417126551.56678|  0:04:24s\n",
            "epoch 15 | loss: 4631848370.83032|  0:04:32s\n",
            "epoch 15 | loss: 4727264128.4621|  0:04:33s\n",
            "epoch 15 | loss: 12380217463.68231|  0:04:35s\n",
            "epoch 15 | loss: 4609750348.24549|  0:04:35s\n",
            "epoch 15 | loss: 14140235637.37185|  0:04:35s\n",
            "epoch 15 | loss: 14083777861.31407|  0:04:36s\n",
            "epoch 15 | loss: 12409332486.9314|  0:04:37s\n",
            "epoch 15 | loss: 14062189606.3538|  0:04:37s\n",
            "epoch 15 | loss: 4664282945.61732|  0:04:39s\n",
            "epoch 15 | loss: 12403057389.51624|  0:04:39s\n",
            "epoch 15 | loss: 14184116860.76535|  0:04:39s\n",
            "epoch 15 | loss: 12327436692.33214|  0:04:40s\n",
            "epoch 16 | loss: 4729677886.84477|  0:04:48s\n",
            "epoch 16 | loss: 4737753058.42599|  0:04:49s\n",
            "epoch 16 | loss: 12367960095.42238|  0:04:51s\n",
            "epoch 16 | loss: 4696452126.0361|  0:04:52s\n",
            "epoch 16 | loss: 14035930304.69314|  0:04:52s\n",
            "epoch 16 | loss: 14045259721.93502|  0:04:52s\n",
            "epoch 16 | loss: 12488861921.5018|  0:04:54s\n",
            "epoch 16 | loss: 14004417782.29604|  0:04:54s\n",
            "epoch 16 | loss: 4577189727.65342|  0:04:57s\n",
            "epoch 16 | loss: 14123179230.26716|  0:04:57s\n",
            "epoch 16 | loss: 12448210115.00362|  0:04:57s\n",
            "epoch 16 | loss: 12348246442.97473|  0:04:58s\n",
            "epoch 17 | loss: 4605597290.74368|  0:05:06s\n",
            "epoch 17 | loss: 4696368134.93141|  0:05:09s\n",
            "epoch 17 | loss: 12273509703.62454|  0:05:10s\n",
            "epoch 17 | loss: 4570273810.02166|  0:05:11s\n",
            "epoch 17 | loss: 13966432755.52346|  0:05:12s\n",
            "epoch 17 | loss: 13986298005.25632|  0:05:12s\n",
            "epoch 17 | loss: 13943772946.94585|  0:05:13s\n",
            "epoch 17 | loss: 12480420333.97834|  0:05:14s\n",
            "epoch 17 | loss: 4599848473.41516|  0:05:16s\n",
            "epoch 17 | loss: 12232796050.94584|  0:05:17s\n",
            "epoch 17 | loss: 14059770600.43322|  0:05:17s\n",
            "epoch 17 | loss: 12391474660.27437|  0:05:18s\n",
            "epoch 18 | loss: 4545936179.75451|  0:05:25s\n",
            "epoch 18 | loss: 4697251437.05415|  0:05:28s\n",
            "epoch 18 | loss: 12295778666.28159|  0:05:30s\n",
            "epoch 18 | loss: 4529964977.90614|  0:05:31s\n",
            "epoch 18 | loss: 13965441955.11913|  0:05:31s\n",
            "epoch 18 | loss: 13951316437.02528|  0:05:31s\n",
            "epoch 18 | loss: 13964859484.41878|  0:05:32s\n",
            "epoch 18 | loss: 12350125978.80144|  0:05:33s\n",
            "epoch 18 | loss: 4521924917.37184|  0:05:35s\n",
            "epoch 18 | loss: 12243216871.50902|  0:05:36s\n",
            "epoch 18 | loss: 14064935967.88448|  0:05:36s\n",
            "epoch 18 | loss: 12299281053.11191|  0:05:36s\n",
            "epoch 19 | loss: 4534640779.09025|  0:05:43s\n",
            "epoch 19 | loss: 4609363721.24188|  0:05:46s\n",
            "epoch 19 | loss: 12306076252.41877|  0:05:47s\n",
            "epoch 19 | loss: 13865851800.95308|  0:05:48s\n",
            "epoch 19 | loss: 4541829223.97112|  0:05:49s\n",
            "epoch 19 | loss: 13895973281.73285|  0:05:49s\n",
            "epoch 19 | loss: 13906468509.11191|  0:05:50s\n",
            "epoch 19 | loss: 12301149061.08303|  0:05:51s\n",
            "epoch 19 | loss: 4503479363.9278|  0:05:53s\n",
            "epoch 19 | loss: 12241932537.99278|  0:05:55s\n",
            "epoch 19 | loss: 13984706526.72923|  0:05:55s\n",
            "epoch 19 | loss: 12277632668.18773|  0:05:55s\n",
            "epoch 20 | loss: 4507997866.05054|  0:06:01s\n",
            "epoch 20 | loss: 4572474395.26354|  0:06:04s\n",
            "epoch 20 | loss: 12233994643.40794|  0:06:06s\n",
            "epoch 20 | loss: 13822866723.58123|  0:06:07s\n",
            "epoch 20 | loss: 4559284503.56678|  0:06:07s\n",
            "epoch 20 | loss: 13901263136.80866|  0:06:08s\n",
            "epoch 20 | loss: 13949133967.71119|  0:06:08s\n",
            "epoch 20 | loss: 12275902225.09747|  0:06:10s\n",
            "epoch 20 | loss: 4447889754.57039|  0:06:12s\n",
            "epoch 20 | loss: 12246828544.0|  0:06:13s\n",
            "epoch 20 | loss: 13965392727.33574|  0:06:13s\n",
            "epoch 20 | loss: 12299076343.22022|  0:06:14s\n",
            "epoch 21 | loss: 4403786376.08664|  0:06:18s\n",
            "epoch 21 | loss: 4490844073.12635|  0:06:22s\n",
            "epoch 21 | loss: 12241944590.32491|  0:06:23s\n",
            "epoch 21 | loss: 13728866249.47292|  0:06:24s\n",
            "epoch 21 | loss: 4444729846.29603|  0:06:25s\n",
            "epoch 21 | loss: 13778336780.93863|  0:06:25s\n",
            "epoch 21 | loss: 13872852089.53069|  0:06:26s\n",
            "epoch 21 | loss: 12173960807.97112|  0:06:28s\n",
            "epoch 21 | loss: 4461846040.02888|  0:06:30s\n",
            "epoch 21 | loss: 13888477524.10108|  0:06:32s\n",
            "epoch 21 | loss: 12150933324.70758|  0:06:32s\n",
            "epoch 21 | loss: 12281643535.71119|  0:06:32s\n",
            "epoch 22 | loss: 4330410241.38628|  0:06:36s\n",
            "epoch 22 | loss: 4491914694.23827|  0:06:40s\n",
            "epoch 22 | loss: 12172873941.94946|  0:06:42s\n",
            "epoch 22 | loss: 13694930758.70036|  0:06:43s\n",
            "epoch 22 | loss: 4437404964.50541|  0:06:43s\n",
            "epoch 22 | loss: 13722884539.61012|  0:06:44s\n",
            "epoch 22 | loss: 13751079650.426|  0:06:45s\n",
            "epoch 22 | loss: 12174713864.77978|  0:06:46s\n",
            "epoch 22 | loss: 4369792880.7509|  0:06:48s\n",
            "epoch 22 | loss: 12099279456.11552|  0:06:50s\n",
            "epoch 22 | loss: 13784648274.2527|  0:06:50s\n",
            "epoch 22 | loss: 12178908176.17328|  0:06:51s\n",
            "epoch 23 | loss: 4244277589.02527|  0:06:54s\n",
            "epoch 23 | loss: 4457895372.24548|  0:06:58s\n",
            "epoch 23 | loss: 12091374452.44765|  0:07:00s\n",
            "epoch 23 | loss: 13819735251.1769|  0:07:01s\n",
            "epoch 23 | loss: 4258673912.1444|  0:07:01s\n",
            "epoch 23 | loss: 13770056783.94224|  0:07:02s\n",
            "epoch 23 | loss: 13674096382.15163|  0:07:03s\n",
            "epoch 23 | loss: 12127915457.15524|  0:07:05s\n",
            "epoch 23 | loss: 4338980591.82672|  0:07:07s\n",
            "epoch 23 | loss: 11984255300.38989|  0:07:08s\n",
            "epoch 23 | loss: 13835018279.50902|  0:07:09s\n",
            "epoch 23 | loss: 12147791830.87365|  0:07:09s\n",
            "epoch 24 | loss: 4291918365.11191|  0:07:12s\n",
            "epoch 24 | loss: 4474340703.65343|  0:07:15s\n",
            "epoch 24 | loss: 12182412635.49458|  0:07:17s\n",
            "epoch 24 | loss: 13721174334.84476|  0:07:18s\n",
            "epoch 24 | loss: 4346563452.76534|  0:07:18s\n",
            "epoch 24 | loss: 13725996155.84116|  0:07:19s\n",
            "epoch 24 | loss: 13642062356.79422|  0:07:20s\n",
            "epoch 24 | loss: 12052730266.33934|  0:07:22s\n",
            "epoch 24 | loss: 4296059918.55596|  0:07:23s\n",
            "epoch 24 | loss: 12043906039.68232|  0:07:25s\n",
            "epoch 24 | loss: 13701988162.07942|  0:07:25s\n",
            "epoch 24 | loss: 12106976920.25993|  0:07:26s\n",
            "epoch 25 | loss: 4271111193.18411|  0:07:28s\n",
            "epoch 25 | loss: 4386028338.83032|  0:07:31s\n",
            "epoch 25 | loss: 12008876006.12275|  0:07:34s\n",
            "epoch 25 | loss: 13974922634.62816|  0:07:34s\n",
            "epoch 25 | loss: 4238437786.5704|  0:07:35s\n",
            "epoch 25 | loss: 13626749750.98917|  0:07:36s\n",
            "epoch 25 | loss: 13531214666.8592|  0:07:37s\n",
            "epoch 25 | loss: 12109057269.37185|  0:07:40s\n",
            "epoch 25 | loss: 4210501369.0686|  0:07:41s\n",
            "epoch 25 | loss: 11940948762.33935|  0:07:43s\n",
            "epoch 25 | loss: 13713666399.19134|  0:07:43s\n",
            "epoch 25 | loss: 12042657863.16246|  0:07:44s\n",
            "epoch 26 | loss: 4215286206.84476|  0:07:45s\n",
            "epoch 26 | loss: 4337396995.23466|  0:07:49s\n",
            "epoch 26 | loss: 12008840853.25632|  0:07:53s\n",
            "epoch 26 | loss: 13463758738.02166|  0:07:53s\n",
            "epoch 26 | loss: 4127425340.99639|  0:07:54s\n",
            "epoch 26 | loss: 13525364360.31768|  0:07:54s\n",
            "epoch 26 | loss: 13487013327.48015|  0:07:56s\n",
            "epoch 26 | loss: 12028055244.70758|  0:07:59s\n",
            "epoch 26 | loss: 4108420673.61733|  0:08:00s\n",
            "epoch 26 | loss: 11963292463.13357|  0:08:02s\n",
            "epoch 26 | loss: 13606974425.64621|  0:08:02s\n",
            "epoch 26 | loss: 12032306239.53791|  0:08:03s\n",
            "epoch 27 | loss: 4101950979.23466|  0:08:03s\n",
            "epoch 27 | loss: 4229704793.18412|  0:08:07s\n",
            "epoch 27 | loss: 11910938180.15884|  0:08:11s\n",
            "epoch 27 | loss: 13376136016.86643|  0:08:12s\n",
            "epoch 27 | loss: 13474266297.53069|  0:08:13s\n",
            "epoch 27 | loss: 4086491286.18051|  0:08:13s\n",
            "epoch 27 | loss: 13464947754.51263|  0:08:14s\n",
            "epoch 27 | loss: 12001253825.61733|  0:08:17s\n",
            "epoch 27 | loss: 4076268803.69675|  0:08:19s\n",
            "epoch 27 | loss: 11846082366.84476|  0:08:20s\n",
            "epoch 27 | loss: 13688076751.71118|  0:08:22s\n",
            "epoch 28 | loss: 4042945291.09025|  0:08:22s\n",
            "epoch 27 | loss: 12128457563.72564|  0:08:23s\n",
            "epoch 28 | loss: 4152724143.13357|  0:08:25s\n",
            "epoch 28 | loss: 11854003617.73285|  0:08:30s\n",
            "epoch 28 | loss: 13436642744.37545|  0:08:30s\n",
            "epoch 28 | loss: 4054289233.79062|  0:08:31s\n",
            "epoch 28 | loss: 13429146086.58483|  0:08:32s\n",
            "epoch 28 | loss: 13316762887.3935|  0:08:33s\n",
            "epoch 28 | loss: 11934687626.16606|  0:08:36s\n",
            "epoch 28 | loss: 4193040554.97473|  0:08:37s\n",
            "epoch 28 | loss: 11790695504.86643|  0:08:39s\n",
            "epoch 29 | loss: 4097414937.41516|  0:08:40s\n",
            "epoch 28 | loss: 13616007270.12275|  0:08:41s\n",
            "epoch 28 | loss: 12042773133.40073|  0:08:42s\n",
            "epoch 29 | loss: 4087599244.01444|  0:08:44s\n",
            "epoch 29 | loss: 11861078080.23105|  0:08:48s\n",
            "epoch 29 | loss: 13294766698.74369|  0:08:49s\n",
            "epoch 29 | loss: 4047039838.26715|  0:08:50s\n",
            "epoch 29 | loss: 13318532555.3213|  0:08:50s\n",
            "epoch 29 | loss: 13330639658.97474|  0:08:53s\n",
            "epoch 29 | loss: 11907476565.94946|  0:08:55s\n",
            "epoch 29 | loss: 4294470413.40072|  0:08:56s\n",
            "epoch 29 | loss: 11776975645.34297|  0:08:58s\n",
            "epoch 30 | loss: 4040726203.61011|  0:08:59s\n",
            "epoch 29 | loss: 12015095042.07942|  0:09:01s\n",
            "epoch 29 | loss: 13545196421.54512|  0:09:01s\n",
            "epoch 30 | loss: 4118800371.06137|  0:09:03s\n",
            "epoch 30 | loss: 11838543326.72924|  0:09:07s\n",
            "epoch 30 | loss: 13082085218.42599|  0:09:08s\n",
            "epoch 30 | loss: 4112672031.42238|  0:09:09s\n",
            "epoch 30 | loss: 13229768500.2166|  0:09:09s\n",
            "epoch 30 | loss: 13206978764.93863|  0:09:11s\n",
            "epoch 30 | loss: 11787817589.83393|  0:09:14s\n",
            "epoch 30 | loss: 4228021148.18773|  0:09:16s\n",
            "epoch 31 | loss: 3995316716.59206|  0:09:17s\n",
            "epoch 30 | loss: 11685837775.48014|  0:09:17s\n",
            "epoch 30 | loss: 11883204096.46209|  0:09:20s\n",
            "epoch 30 | loss: 13448397227.89892|  0:09:21s\n",
            "epoch 31 | loss: 4029067227.49458|  0:09:21s\n",
            "epoch 31 | loss: 11707182751.88448|  0:09:26s\n",
            "epoch 31 | loss: 13377850836.10108|  0:09:27s\n",
            "epoch 31 | loss: 13315134546.7148|  0:09:28s\n",
            "epoch 31 | loss: 3981855934.38267|  0:09:28s\n",
            "epoch 31 | loss: 13325773574.46932|  0:09:30s\n",
            "epoch 31 | loss: 11790095703.33574|  0:09:33s\n",
            "epoch 31 | loss: 4225960856.95307|  0:09:35s\n",
            "epoch 32 | loss: 4058465267.52346|  0:09:36s\n",
            "epoch 31 | loss: 11537127228.0722|  0:09:36s\n",
            "epoch 31 | loss: 13424763014.9314|  0:09:40s\n",
            "epoch 31 | loss: 11840777423.48014|  0:09:40s\n",
            "epoch 32 | loss: 4123719791.82671|  0:09:40s\n",
            "epoch 32 | loss: 11621719686.93141|  0:09:45s\n",
            "epoch 32 | loss: 13189857082.22382|  0:09:45s\n",
            "epoch 32 | loss: 13313977374.4982|  0:09:47s\n",
            "epoch 32 | loss: 3883325073.55957|  0:09:47s\n",
            "epoch 32 | loss: 13264022547.87004|  0:09:48s\n",
            "epoch 32 | loss: 11742669451.55234|  0:09:52s\n",
            "epoch 32 | loss: 4213252550.93141|  0:09:53s\n",
            "epoch 33 | loss: 3910686254.20939|  0:09:54s\n",
            "epoch 32 | loss: 11631636175.01806|  0:09:55s\n",
            "epoch 33 | loss: 3948496356.96751|  0:09:58s\n",
            "epoch 32 | loss: 11814860605.45848|  0:09:59s\n",
            "epoch 32 | loss: 13457134712.6065|  0:09:59s\n",
            "epoch 33 | loss: 11706241644.12996|  0:10:03s\n",
            "epoch 33 | loss: 13258581378.77256|  0:10:04s\n",
            "epoch 33 | loss: 13189074412.12996|  0:10:05s\n",
            "epoch 33 | loss: 3786958359.56679|  0:10:05s\n",
            "epoch 33 | loss: 13328868253.57401|  0:10:07s\n",
            "epoch 33 | loss: 11642951325.80505|  0:10:10s\n",
            "epoch 34 | loss: 3899401554.48375|  0:10:12s\n",
            "epoch 33 | loss: 4242809920.69314|  0:10:12s\n",
            "epoch 33 | loss: 11525904575.0758|  0:10:14s\n",
            "epoch 34 | loss: 3993841211.61011|  0:10:17s\n",
            "epoch 33 | loss: 11940351201.27076|  0:10:18s\n",
            "epoch 33 | loss: 13403015351.45126|  0:10:18s\n",
            "epoch 34 | loss: 11605304826.45488|  0:10:22s\n",
            "epoch 34 | loss: 13166612446.96029|  0:10:22s\n",
            "epoch 34 | loss: 13162154594.19495|  0:10:24s\n",
            "epoch 34 | loss: 3766610781.11191|  0:10:24s\n",
            "epoch 34 | loss: 13060874221.97834|  0:10:25s\n",
            "epoch 34 | loss: 11615399762.7148|  0:10:29s\n",
            "epoch 35 | loss: 3651520073.93502|  0:10:30s\n",
            "epoch 34 | loss: 4192651061.14079|  0:10:31s\n",
            "epoch 34 | loss: 11457274469.66064|  0:10:32s\n",
            "epoch 35 | loss: 3987885476.04332|  0:10:35s\n",
            "epoch 34 | loss: 13378490763.09026|  0:10:37s\n",
            "epoch 34 | loss: 11939711629.40073|  0:10:37s\n",
            "epoch 35 | loss: 11625150073.53068|  0:10:40s\n",
            "epoch 35 | loss: 13061664443.61011|  0:10:41s\n",
            "epoch 35 | loss: 13024616494.20939|  0:10:42s\n",
            "epoch 35 | loss: 3707854377.8195|  0:10:43s\n",
            "epoch 35 | loss: 12944110339.69675|  0:10:43s\n",
            "epoch 35 | loss: 11616529446.3538|  0:10:48s\n",
            "epoch 36 | loss: 3703706403.81227|  0:10:48s\n",
            "epoch 35 | loss: 4127372989.22744|  0:10:50s\n",
            "epoch 35 | loss: 11434263260.41878|  0:10:51s\n",
            "epoch 36 | loss: 4196856681.3574|  0:10:53s\n",
            "epoch 35 | loss: 13528094314.28158|  0:10:55s\n",
            "epoch 35 | loss: 11941376779.3213|  0:10:56s\n",
            "epoch 36 | loss: 12085369507.11914|  0:10:58s\n",
            "epoch 36 | loss: 12966170088.43321|  0:10:59s\n",
            "epoch 36 | loss: 12991674571.32129|  0:11:00s\n",
            "epoch 36 | loss: 3745477781.71841|  0:11:01s\n",
            "epoch 36 | loss: 13023581543.04694|  0:11:01s\n",
            "epoch 37 | loss: 3621881003.43682|  0:11:05s\n",
            "epoch 36 | loss: 11525741250.54152|  0:11:05s\n",
            "epoch 36 | loss: 4157238747.26354|  0:11:07s\n",
            "epoch 36 | loss: 11458399981.2852|  0:11:08s\n",
            "epoch 37 | loss: 3892639485.45848|  0:11:10s\n",
            "epoch 36 | loss: 13487468508.41877|  0:11:13s\n",
            "epoch 36 | loss: 11942120125.45848|  0:11:13s\n",
            "epoch 37 | loss: 12035830413.40072|  0:11:15s\n",
            "epoch 37 | loss: 13025243251.52346|  0:11:16s\n",
            "epoch 37 | loss: 12949791375.71119|  0:11:17s\n",
            "epoch 37 | loss: 3609207164.30325|  0:11:18s\n",
            "epoch 37 | loss: 12777918368.80866|  0:11:18s\n",
            "epoch 38 | loss: 3489054516.21661|  0:11:23s\n",
            "epoch 37 | loss: 11449862866.7148|  0:11:24s\n",
            "epoch 37 | loss: 4125184027.03249|  0:11:25s\n",
            "epoch 37 | loss: 11330722338.65704|  0:11:26s\n",
            "epoch 38 | loss: 3976853377.84838|  0:11:28s\n",
            "epoch 37 | loss: 13414659490.65704|  0:11:32s\n",
            "epoch 37 | loss: 11886182566.81588|  0:11:33s\n",
            "epoch 38 | loss: 11853349146.80144|  0:11:34s\n",
            "epoch 38 | loss: 13319655683.4657|  0:11:35s\n",
            "epoch 38 | loss: 12734660028.07221|  0:11:36s\n",
            "epoch 38 | loss: 3639369155.4657|  0:11:37s\n",
            "epoch 38 | loss: 12694529507.81228|  0:11:38s\n",
            "epoch 39 | loss: 3534100644.96751|  0:11:41s\n",
            "epoch 38 | loss: 11539042853.8917|  0:11:42s\n",
            "epoch 38 | loss: 4082329013.14079|  0:11:44s\n",
            "epoch 38 | loss: 11330652496.86643|  0:11:44s\n",
            "epoch 39 | loss: 3922519119.2491|  0:11:46s\n",
            "epoch 38 | loss: 13288321266.13718|  0:11:50s\n",
            "epoch 38 | loss: 11871659214.55596|  0:11:51s\n",
            "epoch 39 | loss: 11577096814.67148|  0:11:52s\n",
            "epoch 39 | loss: 12874938155.8989|  0:11:52s\n",
            "epoch 39 | loss: 13043066040.37545|  0:11:52s\n",
            "epoch 39 | loss: 3893126727.16246|  0:11:54s\n",
            "epoch 39 | loss: 13100908781.05414|  0:11:55s\n",
            "epoch 40 | loss: 3622781299.52347|  0:11:58s\n",
            "epoch 39 | loss: 11401803522.31047|  0:12:00s\n",
            "epoch 39 | loss: 4074278966.52708|  0:12:02s\n",
            "epoch 39 | loss: 11235888043.20578|  0:12:02s\n",
            "epoch 40 | loss: 3732927863.91336|  0:12:03s\n",
            "epoch 39 | loss: 13351337229.63178|  0:12:08s\n",
            "epoch 40 | loss: 11618562620.5343|  0:12:09s\n",
            "epoch 39 | loss: 11902785784.6065|  0:12:09s\n",
            "epoch 40 | loss: 13067819296.34657|  0:12:10s\n",
            "epoch 40 | loss: 12920188648.89531|  0:12:10s\n",
            "epoch 40 | loss: 3830119182.32491|  0:12:12s\n",
            "epoch 40 | loss: 13227285652.33214|  0:12:13s\n",
            "epoch 41 | loss: 3381424418.65704|  0:12:16s\n",
            "epoch 40 | loss: 11576104582.70036|  0:12:19s\n",
            "epoch 40 | loss: 3993777428.56318|  0:12:20s\n",
            "epoch 40 | loss: 11274918555.72563|  0:12:21s\n",
            "epoch 41 | loss: 3670053109.37184|  0:12:21s\n",
            "epoch 40 | loss: 13274616538.5704|  0:12:27s\n",
            "epoch 41 | loss: 11516265881.41516|  0:12:28s\n",
            "epoch 40 | loss: 11716125287.04693|  0:12:28s\n",
            "epoch 41 | loss: 12618746002.02166|  0:12:28s\n",
            "epoch 41 | loss: 12861983177.93502|  0:12:28s\n",
            "epoch 41 | loss: 3764449054.96029|  0:12:30s\n",
            "epoch 41 | loss: 12949274563.92779|  0:12:31s\n",
            "epoch 42 | loss: 3238078226.94585|  0:12:34s\n",
            "epoch 41 | loss: 11602981444.38988|  0:12:38s\n",
            "epoch 41 | loss: 3970095433.24188|  0:12:38s\n",
            "epoch 41 | loss: 11117280693.6029|  0:12:39s\n",
            "epoch 42 | loss: 3735348817.79061|  0:12:39s\n",
            "epoch 41 | loss: 13211207173.08303|  0:12:46s\n",
            "epoch 42 | loss: 11559946932.2166|  0:12:46s\n",
            "epoch 42 | loss: 12747026768.86643|  0:12:46s\n",
            "epoch 42 | loss: 13008806115.35018|  0:12:47s\n",
            "epoch 41 | loss: 11630742514.59928|  0:12:47s\n",
            "epoch 42 | loss: 3749654192.51986|  0:12:48s\n",
            "epoch 42 | loss: 12729016358.81588|  0:12:49s\n",
            "epoch 43 | loss: 3357010583.33574|  0:12:52s\n",
            "epoch 42 | loss: 11625145782.98918|  0:12:56s\n",
            "epoch 43 | loss: 3815040634.91697|  0:12:57s\n",
            "epoch 42 | loss: 3962814940.18773|  0:12:57s\n",
            "epoch 42 | loss: 11229354891.55235|  0:12:57s\n",
            "epoch 43 | loss: 11589619199.07581|  0:13:04s\n",
            "epoch 42 | loss: 12980567576.95307|  0:13:04s\n",
            "epoch 43 | loss: 12597212846.20939|  0:13:04s\n",
            "epoch 43 | loss: 12306459951.82671|  0:13:05s\n",
            "epoch 42 | loss: 11575135742.61372|  0:13:05s\n",
            "epoch 43 | loss: 3675394726.81588|  0:13:06s\n",
            "epoch 43 | loss: 12688736268.47653|  0:13:08s\n",
            "epoch 44 | loss: 3242743274.74368|  0:13:10s\n",
            "epoch 44 | loss: 3656494070.98917|  0:13:15s\n",
            "epoch 43 | loss: 11532687529.58845|  0:13:15s\n",
            "epoch 43 | loss: 11182020170.8592|  0:13:16s\n",
            "epoch 43 | loss: 3868602712.25993|  0:13:16s\n",
            "epoch 44 | loss: 11328747610.1083|  0:13:22s\n",
            "epoch 44 | loss: 12542798550.41155|  0:13:23s\n",
            "epoch 43 | loss: 12832519285.37186|  0:13:23s\n",
            "epoch 44 | loss: 12389446947.11913|  0:13:23s\n",
            "epoch 44 | loss: 3558784725.94946|  0:13:25s\n",
            "epoch 43 | loss: 11564823131.49458|  0:13:25s\n",
            "epoch 44 | loss: 12782023186.94585|  0:13:26s\n",
            "epoch 45 | loss: 3458078579.29242|  0:13:28s\n",
            "epoch 45 | loss: 3688144438.29603|  0:13:33s\n",
            "epoch 44 | loss: 11595859830.98916|  0:13:34s\n",
            "epoch 44 | loss: 11013242969.41516|  0:13:34s\n",
            "epoch 44 | loss: 3811423751.8556|  0:13:35s\n",
            "epoch 45 | loss: 11309319719.74007|  0:13:41s\n",
            "epoch 45 | loss: 12501521434.1083|  0:13:41s\n",
            "epoch 44 | loss: 12831205754.91697|  0:13:41s\n",
            "epoch 45 | loss: 12315151683.23466|  0:13:42s\n",
            "epoch 45 | loss: 3862433227.55235|  0:13:43s\n",
            "epoch 44 | loss: 11516550468.15884|  0:13:43s\n",
            "epoch 45 | loss: 12542102055.74008|  0:13:45s\n",
            "epoch 46 | loss: 3638052352.46209|  0:13:46s\n",
            "epoch 46 | loss: 3652726324.6787|  0:13:51s\n",
            "epoch 45 | loss: 11614530530.19495|  0:13:53s\n",
            "epoch 45 | loss: 11032044448.80867|  0:13:54s\n",
            "epoch 45 | loss: 3925691478.87365|  0:13:54s\n",
            "epoch 46 | loss: 11278500112.40433|  0:13:59s\n",
            "epoch 46 | loss: 12608848352.57762|  0:14:00s\n",
            "epoch 46 | loss: 12413584489.35741|  0:14:01s\n",
            "epoch 45 | loss: 12876144921.41516|  0:14:00s\n",
            "epoch 46 | loss: 4073406960.28881|  0:14:01s\n",
            "epoch 45 | loss: 11665059741.80505|  0:14:02s\n",
            "epoch 46 | loss: 12413636255.19132|  0:14:04s\n",
            "epoch 47 | loss: 3346769258.97473|  0:14:04s\n",
            "epoch 47 | loss: 3594806752.34657|  0:14:09s\n",
            "epoch 46 | loss: 11694370017.9639|  0:14:12s\n",
            "epoch 46 | loss: 11108619637.1408|  0:14:12s\n",
            "epoch 46 | loss: 3778021652.56318|  0:14:12s\n",
            "epoch 47 | loss: 12618768705.61733|  0:14:18s\n",
            "epoch 47 | loss: 11366248105.12635|  0:14:18s\n",
            "epoch 47 | loss: 12740572366.55596|  0:14:19s\n",
            "epoch 46 | loss: 12656789147.0325|  0:14:20s\n",
            "epoch 47 | loss: 3990654592.0|  0:14:20s\n",
            "epoch 46 | loss: 11615182225.09748|  0:14:21s\n",
            "epoch 47 | loss: 12366940607.30686|  0:14:22s\n",
            "epoch 48 | loss: 3217989961.01083|  0:14:23s\n",
            "epoch 48 | loss: 3627423291.14802|  0:14:27s\n",
            "epoch 47 | loss: 11090675871.42238|  0:14:31s\n",
            "epoch 47 | loss: 11677700458.05056|  0:14:31s\n",
            "epoch 47 | loss: 3768047135.42238|  0:14:31s\n",
            "epoch 48 | loss: 11189309051.37906|  0:14:36s\n",
            "epoch 48 | loss: 12602773372.30325|  0:14:36s\n",
            "epoch 48 | loss: 12175704157.11192|  0:14:38s\n",
            "epoch 47 | loss: 12622662856.31768|  0:14:39s\n",
            "epoch 48 | loss: 3966734395.14802|  0:14:39s\n",
            "epoch 47 | loss: 11519536814.67149|  0:14:41s\n",
            "epoch 48 | loss: 12420560634.45488|  0:14:41s\n",
            "epoch 49 | loss: 3462822707.29242|  0:14:41s\n",
            "epoch 49 | loss: 3521071338.28159|  0:14:46s\n",
            "epoch 48 | loss: 11100025818.33936|  0:14:50s\n",
            "epoch 48 | loss: 11730736183.91336|  0:14:50s\n",
            "epoch 48 | loss: 3838080702.61372|  0:14:51s\n",
            "epoch 49 | loss: 11189263248.63538|  0:14:55s\n",
            "epoch 49 | loss: 12319762001.32851|  0:14:55s\n",
            "epoch 49 | loss: 12025160855.56679|  0:14:56s\n",
            "epoch 48 | loss: 12575470158.32491|  0:14:57s\n",
            "epoch 49 | loss: 3910790661.77617|  0:14:57s\n",
            "epoch 48 | loss: 11499150212.62094|  0:14:59s\n",
            "epoch 50 | loss: 3020597419.89892|  0:14:59s\n",
            "epoch 49 | loss: 12236382506.97472|  0:14:59s\n",
            "epoch 50 | loss: 3504803162.5704|  0:15:04s\n",
            "epoch 49 | loss: 11011789503.76896|  0:15:08s\n",
            "epoch 49 | loss: 11648646239.19134|  0:15:09s\n",
            "epoch 49 | loss: 3751110600.08664|  0:15:09s\n",
            "epoch 50 | loss: 11192515689.3574|  0:15:13s\n",
            "epoch 50 | loss: 12318443826.83033|  0:15:13s\n",
            "epoch 50 | loss: 12444541443.69676|  0:15:15s\n",
            "epoch 50 | loss: 3830766381.97834|  0:15:16s\n",
            "epoch 49 | loss: 12490002535.97112|  0:15:16s\n",
            "epoch 51 | loss: 3306432071.3935|  0:15:18s\n",
            "epoch 50 | loss: 12343949050.45488|  0:15:18s\n",
            "epoch 49 | loss: 11551170899.17689|  0:15:18s\n",
            "epoch 51 | loss: 3466129966.67148|  0:15:22s\n",
            "epoch 50 | loss: 10974588945.55957|  0:15:27s\n",
            "epoch 50 | loss: 3750965334.41155|  0:15:27s\n",
            "epoch 50 | loss: 11641439079.04693|  0:15:28s\n",
            "epoch 51 | loss: 11220591610.91696|  0:15:30s\n",
            "epoch 51 | loss: 12323560759.45127|  0:15:31s\n",
            "epoch 51 | loss: 12648092659.52347|  0:15:33s\n",
            "epoch 51 | loss: 3522793877.48736|  0:15:35s\n",
            "epoch 50 | loss: 12627956504.02888|  0:15:35s\n",
            "epoch 52 | loss: 3151497914.68592|  0:15:35s\n",
            "epoch 51 | loss: 12240203251.52346|  0:15:36s\n",
            "epoch 50 | loss: 11487003230.26715|  0:15:36s\n",
            "epoch 52 | loss: 3466629250.31047|  0:15:40s\n",
            "epoch 51 | loss: 10944098757.08303|  0:15:46s\n",
            "epoch 51 | loss: 3668242251.09025|  0:15:47s\n",
            "epoch 51 | loss: 11626814408.54874|  0:15:48s\n",
            "epoch 52 | loss: 11324919596.36101|  0:15:50s\n",
            "epoch 52 | loss: 12264992865.03971|  0:15:50s\n",
            "epoch 52 | loss: 11804758398.38266|  0:15:52s\n",
            "epoch 52 | loss: 3558327175.85559|  0:15:54s\n",
            "epoch 53 | loss: 2994189059.69675|  0:15:55s\n",
            "epoch 51 | loss: 12518287213.2852|  0:15:55s\n",
            "epoch 52 | loss: 12308596400.7509|  0:15:55s\n",
            "epoch 51 | loss: 11528750725.31408|  0:15:57s\n",
            "epoch 53 | loss: 3424458164.90975|  0:15:58s\n",
            "epoch 52 | loss: 10852915437.2852|  0:16:05s\n",
            "epoch 52 | loss: 3723440987.26354|  0:16:06s\n",
            "epoch 52 | loss: 11620841321.12635|  0:16:08s\n",
            "epoch 53 | loss: 11561747444.90974|  0:16:08s\n",
            "epoch 53 | loss: 12395900129.73285|  0:16:09s\n",
            "epoch 53 | loss: 11754790921.24188|  0:16:11s\n",
            "epoch 53 | loss: 3207348976.98195|  0:16:13s\n",
            "epoch 54 | loss: 3045723753.3574|  0:16:13s\n",
            "epoch 52 | loss: 12376927545.76174|  0:16:14s\n",
            "epoch 53 | loss: 11909161056.57762|  0:16:14s\n",
            "epoch 52 | loss: 11390788510.0361|  0:16:16s\n",
            "epoch 54 | loss: 3344958792.54874|  0:16:17s\n",
            "epoch 53 | loss: 10754522837.71842|  0:16:24s\n",
            "epoch 53 | loss: 3677291702.98917|  0:16:25s\n",
            "epoch 54 | loss: 11395497244.41877|  0:16:27s\n",
            "epoch 54 | loss: 12124016843.3213|  0:16:27s\n",
            "epoch 53 | loss: 11508281803.3213|  0:16:28s\n",
            "epoch 54 | loss: 12446303270.81589|  0:16:30s\n",
            "epoch 55 | loss: 3232589647.2491|  0:16:32s\n",
            "epoch 54 | loss: 3228192796.18772|  0:16:32s\n",
            "epoch 54 | loss: 11722148530.83032|  0:16:33s\n",
            "epoch 53 | loss: 12241970265.64621|  0:16:33s\n",
            "epoch 53 | loss: 11492397714.48375|  0:16:35s\n",
            "epoch 55 | loss: 3382447716.50542|  0:16:35s\n",
            "epoch 54 | loss: 10782099620.04332|  0:16:42s\n",
            "epoch 54 | loss: 3726670171.72563|  0:16:43s\n",
            "epoch 55 | loss: 12310323821.51624|  0:16:44s\n",
            "epoch 55 | loss: 11359132834.65704|  0:16:45s\n",
            "epoch 54 | loss: 11413705557.94946|  0:16:45s\n",
            "epoch 55 | loss: 11724632126.38267|  0:16:47s\n",
            "epoch 56 | loss: 3104189965.40072|  0:16:49s\n",
            "epoch 55 | loss: 3199316714.74368|  0:16:49s\n",
            "epoch 55 | loss: 11812660344.37546|  0:16:50s\n",
            "epoch 54 | loss: 12182615632.40434|  0:16:51s\n",
            "epoch 56 | loss: 3237736374.75812|  0:16:52s\n",
            "epoch 54 | loss: 11401491768.37545|  0:16:52s\n",
            "epoch 55 | loss: 10779324365.63177|  0:16:59s\n",
            "epoch 55 | loss: 3738395376.98195|  0:17:01s\n",
            "epoch 56 | loss: 10926094137.29964|  0:17:02s\n",
            "epoch 56 | loss: 11939445577.47292|  0:17:02s\n",
            "epoch 55 | loss: 11407356025.53068|  0:17:03s\n",
            "epoch 56 | loss: 12434538824.08664|  0:17:05s\n",
            "epoch 57 | loss: 3310830251.20578|  0:17:06s\n",
            "epoch 56 | loss: 3115391418.22383|  0:17:07s\n",
            "epoch 56 | loss: 11266647693.86282|  0:17:08s\n",
            "epoch 55 | loss: 12662746712.49098|  0:17:09s\n",
            "epoch 57 | loss: 3098018645.02527|  0:17:09s\n",
            "epoch 55 | loss: 11472059860.33213|  0:17:10s\n",
            "epoch 56 | loss: 10867576366.20939|  0:17:17s\n",
            "epoch 57 | loss: 10815006296.25993|  0:17:18s\n",
            "epoch 56 | loss: 3663173761.84838|  0:17:19s\n",
            "epoch 57 | loss: 12318983029.37184|  0:17:19s\n",
            "epoch 56 | loss: 11338266327.10469|  0:17:20s\n",
            "epoch 57 | loss: 11743316455.04694|  0:17:22s\n",
            "epoch 58 | loss: 2799936853.71841|  0:17:23s\n",
            "epoch 57 | loss: 3137335414.29603|  0:17:24s\n",
            "epoch 57 | loss: 11845230787.23466|  0:17:25s\n",
            "epoch 58 | loss: 3298617625.64621|  0:17:25s\n",
            "epoch 56 | loss: 12240465781.37184|  0:17:26s\n",
            "epoch 56 | loss: 11334623005.57401|  0:17:28s\n",
            "epoch 57 | loss: 10734130750.84476|  0:17:34s\n",
            "epoch 58 | loss: 10949902649.29964|  0:17:35s\n",
            "epoch 58 | loss: 12274587258.68592|  0:17:35s\n",
            "epoch 57 | loss: 3666067091.87004|  0:17:36s\n",
            "epoch 57 | loss: 11316687853.51624|  0:17:38s\n",
            "epoch 58 | loss: 12286281441.27075|  0:17:39s\n",
            "epoch 59 | loss: 3242147782.70036|  0:17:39s\n",
            "epoch 58 | loss: 3127082116.15884|  0:17:41s\n",
            "epoch 58 | loss: 11302472273.09748|  0:17:42s\n",
            "epoch 59 | loss: 3164229183.30686|  0:17:42s\n",
            "epoch 57 | loss: 12164144662.87364|  0:17:43s\n",
            "epoch 57 | loss: 11335282811.84115|  0:17:45s\n",
            "epoch 58 | loss: 10778291221.71841|  0:17:52s\n",
            "epoch 59 | loss: 11116598625.50181|  0:17:52s\n",
            "epoch 59 | loss: 11910596703.88448|  0:17:53s\n",
            "epoch 58 | loss: 3624702646.98917|  0:17:53s\n",
            "epoch 58 | loss: 11297068942.787|  0:17:56s\n",
            "epoch 60 | loss: 3300170503.62455|  0:17:56s\n",
            "epoch 59 | loss: 11662160601.18412|  0:17:57s\n",
            "epoch 59 | loss: 3008243842.31047|  0:17:59s\n",
            "epoch 59 | loss: 11488408625.44404|  0:18:00s\n",
            "epoch 60 | loss: 3308180243.87004|  0:18:00s\n",
            "epoch 58 | loss: 12366403440.28882|  0:18:01s\n",
            "epoch 58 | loss: 11436317058.07942|  0:18:03s\n",
            "epoch 59 | loss: 10768334080.46209|  0:18:09s\n",
            "epoch 60 | loss: 10941896320.23105|  0:18:09s\n",
            "epoch 60 | loss: 12096148728.1444|  0:18:11s\n",
            "epoch 59 | loss: 3688216178.59928|  0:18:11s\n",
            "epoch 61 | loss: 3294434304.92419|  0:18:14s\n",
            "epoch 59 | loss: 11261289456.28881|  0:18:14s\n",
            "epoch 60 | loss: 11597049277.92058|  0:18:15s\n",
            "epoch 60 | loss: 2925112117.60289|  0:18:17s\n",
            "epoch 61 | loss: 3002781246.38267|  0:18:17s\n",
            "epoch 60 | loss: 12139939288.49097|  0:18:18s\n",
            "epoch 59 | loss: 12417420991.76895|  0:18:20s\n",
            "epoch 59 | loss: 11263226514.48375|  0:18:21s\n",
            "epoch 61 | loss: 11071390617.87726|  0:18:26s\n",
            "epoch 60 | loss: 10809247530.74368|  0:18:27s\n",
            "epoch 61 | loss: 12107783297.15524|  0:18:28s\n",
            "epoch 60 | loss: 3638599560.08664|  0:18:28s\n",
            "epoch 62 | loss: 3029750098.7148|  0:18:31s\n",
            "epoch 60 | loss: 11182591247.01805|  0:18:32s\n",
            "epoch 61 | loss: 12415121797.54512|  0:18:32s\n",
            "epoch 62 | loss: 3258523678.49819|  0:18:34s\n",
            "epoch 61 | loss: 2924516528.05776|  0:18:35s\n",
            "epoch 61 | loss: 11208615485.68953|  0:18:35s\n",
            "epoch 60 | loss: 12072676044.24549|  0:18:38s\n",
            "epoch 60 | loss: 11452587612.88088|  0:18:40s\n",
            "epoch 62 | loss: 10787361486.55595|  0:18:44s\n",
            "epoch 61 | loss: 10639583911.27798|  0:18:45s\n",
            "epoch 62 | loss: 12130933499.14802|  0:18:46s\n",
            "epoch 61 | loss: 3564916958.26715|  0:18:46s\n",
            "epoch 63 | loss: 3170469809.44404|  0:18:48s\n",
            "epoch 62 | loss: 11325977245.57401|  0:18:51s\n",
            "epoch 61 | loss: 11251289296.86643|  0:18:51s\n",
            "epoch 63 | loss: 3228755567.36462|  0:18:52s\n",
            "epoch 62 | loss: 3347140342.98917|  0:18:53s\n",
            "epoch 62 | loss: 12438312778.62816|  0:18:53s\n",
            "epoch 61 | loss: 12227022187.43682|  0:18:57s\n",
            "epoch 61 | loss: 11393739158.6426|  0:18:58s\n",
            "epoch 63 | loss: 10841281991.8556|  0:19:02s\n",
            "epoch 62 | loss: 10759054558.72924|  0:19:03s\n",
            "epoch 63 | loss: 11683848318.61372|  0:19:04s\n",
            "epoch 62 | loss: 3692239737.76173|  0:19:05s\n",
            "epoch 64 | loss: 3033270769.213|  0:19:06s\n",
            "epoch 63 | loss: 11406867797.71842|  0:19:09s\n",
            "epoch 64 | loss: 3345065499.26354|  0:19:09s\n",
            "epoch 62 | loss: 11259905732.85198|  0:19:09s\n",
            "epoch 63 | loss: 11232177319.50902|  0:19:11s\n",
            "epoch 63 | loss: 3076603797.48737|  0:19:11s\n",
            "epoch 62 | loss: 11856717145.87726|  0:19:15s\n",
            "epoch 62 | loss: 11258875995.72564|  0:19:17s\n",
            "epoch 64 | loss: 10836929024.23105|  0:19:19s\n",
            "epoch 63 | loss: 10666298410.74368|  0:19:20s\n",
            "epoch 64 | loss: 11934964187.03249|  0:19:21s\n",
            "epoch 63 | loss: 3732762756.85199|  0:19:22s\n",
            "epoch 65 | loss: 2748690265.18412|  0:19:23s\n",
            "epoch 65 | loss: 3081324738.54152|  0:19:25s\n",
            "epoch 64 | loss: 12489643999.65343|  0:19:26s\n",
            "epoch 63 | loss: 11143180662.29603|  0:19:26s\n",
            "epoch 64 | loss: 12010863488.0|  0:19:28s\n",
            "epoch 64 | loss: 2972794362.45487|  0:19:28s\n",
            "epoch 63 | loss: 12230588176.63538|  0:19:31s\n",
            "epoch 63 | loss: 11174027255.91336|  0:19:33s\n",
            "epoch 65 | loss: 10866851998.96029|  0:19:35s\n",
            "epoch 64 | loss: 10670717047.91336|  0:19:36s\n",
            "epoch 65 | loss: 11851789380.85198|  0:19:37s\n",
            "epoch 64 | loss: 3569334348.93863|  0:19:38s\n",
            "epoch 66 | loss: 3170567386.33935|  0:19:39s\n",
            "epoch 66 | loss: 3003486438.58484|  0:19:41s\n",
            "epoch 65 | loss: 11497753340.99639|  0:19:41s\n",
            "epoch 64 | loss: 11066563481.64621|  0:19:42s\n",
            "epoch 65 | loss: 3228859516.30325|  0:19:44s\n",
            "epoch 65 | loss: 11756804500.33213|  0:19:44s\n",
            "epoch 64 | loss: 12091849502.49819|  0:19:48s\n",
            "epoch 64 | loss: 11216895437.63177|  0:19:49s\n",
            "epoch 66 | loss: 10708699803.4946|  0:19:50s\n",
            "epoch 65 | loss: 10668324783.13357|  0:19:52s\n",
            "epoch 66 | loss: 11683376719.01806|  0:19:52s\n",
            "epoch 65 | loss: 3543283205.77617|  0:19:54s\n",
            "epoch 67 | loss: 2711563255.22022|  0:19:55s\n",
            "epoch 67 | loss: 3178667756.59206|  0:19:56s\n",
            "epoch 66 | loss: 11270952951.68232|  0:19:57s\n",
            "epoch 65 | loss: 11154030763.89892|  0:19:59s\n",
            "epoch 66 | loss: 2799461395.40794|  0:20:00s\n",
            "epoch 66 | loss: 11083241825.5018|  0:20:00s\n",
            "epoch 65 | loss: 12035198882.88808|  0:20:04s\n",
            "epoch 65 | loss: 11382171307.43683|  0:20:05s\n",
            "epoch 67 | loss: 10719896697.99278|  0:20:06s\n",
            "epoch 67 | loss: 11936109559.68231|  0:20:08s\n",
            "epoch 66 | loss: 10626983765.48736|  0:20:08s\n",
            "epoch 68 | loss: 2754999636.10108|  0:20:10s\n",
            "epoch 66 | loss: 3588837909.94946|  0:20:10s\n",
            "epoch 68 | loss: 3414720910.55596|  0:20:11s\n",
            "epoch 67 | loss: 11085558040.25993|  0:20:13s\n",
            "epoch 66 | loss: 11035910757.8917|  0:20:14s\n",
            "epoch 67 | loss: 11335736583.8556|  0:20:15s\n",
            "epoch 67 | loss: 2845823483.14801|  0:20:16s\n",
            "epoch 66 | loss: 11861741851.72563|  0:20:20s\n",
            "epoch 66 | loss: 11221383796.44765|  0:20:21s\n",
            "epoch 68 | loss: 10742641668.62094|  0:20:22s\n",
            "epoch 68 | loss: 11991269594.10831|  0:20:23s\n",
            "epoch 67 | loss: 10621398301.11191|  0:20:24s\n",
            "epoch 69 | loss: 2833128165.66065|  0:20:25s\n",
            "epoch 67 | loss: 3442098603.43682|  0:20:26s\n",
            "epoch 69 | loss: 3210583610.91697|  0:20:27s\n",
            "epoch 68 | loss: 11251384921.87725|  0:20:29s\n",
            "epoch 67 | loss: 10961256095.65342|  0:20:31s\n",
            "epoch 68 | loss: 12192665578.97472|  0:20:31s\n",
            "epoch 68 | loss: 2825787765.37184|  0:20:32s\n",
            "epoch 67 | loss: 11849491011.69675|  0:20:36s\n",
            "epoch 69 | loss: 10744996972.8231|  0:20:38s\n",
            "epoch 67 | loss: 11101561836.12996|  0:20:38s\n",
            "epoch 69 | loss: 11809723273.93502|  0:20:39s\n",
            "epoch 68 | loss: 10749197376.23105|  0:21:34s\n",
            "epoch 70 | loss: 2721684395.89892|  0:21:35s\n",
            "epoch 70 | loss: 3132828398.67148|  0:21:37s\n",
            "epoch 68 | loss: 3432355053.05415|  0:21:37s\n",
            "epoch 69 | loss: 11153492568.72202|  0:21:40s\n",
            "epoch 68 | loss: 10991071568.86643|  0:21:43s\n",
            "epoch 69 | loss: 11946235673.64621|  0:21:43s\n",
            "epoch 69 | loss: 2924850455.79783|  0:21:44s\n",
            "epoch 68 | loss: 12019458737.44406|  0:21:49s\n",
            "epoch 70 | loss: 10781048216.02888|  0:21:50s\n",
            "epoch 68 | loss: 11167735076.50541|  0:21:51s\n",
            "epoch 70 | loss: 11623972451.35018|  0:21:52s\n",
            "epoch 71 | loss: 2629364531.29242|  0:21:53s\n",
            "epoch 69 | loss: 10734965042.13719|  0:21:54s\n",
            "epoch 71 | loss: 3208586022.12274|  0:21:55s\n",
            "epoch 69 | loss: 3458628642.19494|  0:21:56s\n",
            "epoch 70 | loss: 11160000857.41516|  0:21:58s\n",
            "epoch 69 | loss: 10919007675.61011|  0:22:01s\n",
            "epoch 70 | loss: 11265681857.84838|  0:22:02s\n",
            "epoch 70 | loss: 2838260117.25632|  0:22:02s\n",
            "epoch 69 | loss: 11963187262.84477|  0:22:07s\n",
            "epoch 71 | loss: 10621378950.00722|  0:22:08s\n",
            "epoch 69 | loss: 11129097811.87004|  0:22:09s\n",
            "epoch 71 | loss: 11932974643.06138|  0:22:10s\n",
            "epoch 72 | loss: 2865540028.99639|  0:22:11s\n",
            "epoch 70 | loss: 10478013517.40072|  0:22:12s\n",
            "epoch 72 | loss: 3166660629.94946|  0:22:13s\n",
            "epoch 70 | loss: 3316191872.0|  0:22:14s\n",
            "epoch 71 | loss: 11063836688.63538|  0:22:17s\n",
            "epoch 70 | loss: 10939951546.91697|  0:22:20s\n",
            "epoch 71 | loss: 11044180902.35379|  0:22:20s\n",
            "epoch 71 | loss: 3138797125.31408|  0:22:20s\n",
            "epoch 70 | loss: 11896248120.6065|  0:22:25s\n",
            "epoch 72 | loss: 10741387283.87004|  0:22:25s\n",
            "epoch 72 | loss: 11797785420.70758|  0:22:27s\n",
            "epoch 70 | loss: 11061666786.19494|  0:22:28s\n",
            "epoch 73 | loss: 2963637430.06498|  0:22:29s\n",
            "epoch 73 | loss: 3738521469.92058|  0:22:29s\n",
            "epoch 71 | loss: 10558679808.23104|  0:22:30s\n",
            "epoch 71 | loss: 3185079728.05776|  0:22:32s\n",
            "epoch 72 | loss: 11164237350.12274|  0:22:34s\n",
            "epoch 72 | loss: 10928082810.91696|  0:22:37s\n",
            "epoch 72 | loss: 3306377159.8556|  0:22:38s\n",
            "epoch 71 | loss: 10908772940.70758|  0:22:38s\n",
            "epoch 73 | loss: 10652198630.81589|  0:22:43s\n",
            "epoch 71 | loss: 12057430087.62455|  0:22:43s\n",
            "epoch 73 | loss: 12057534810.33936|  0:22:45s\n",
            "epoch 71 | loss: 11136535460.04332|  0:22:46s\n",
            "epoch 74 | loss: 3092215507.1769|  0:22:47s\n",
            "epoch 74 | loss: 2955656472.02888|  0:22:47s\n",
            "epoch 72 | loss: 10613800822.06498|  0:22:48s\n",
            "epoch 72 | loss: 3320132080.51986|  0:22:49s\n",
            "epoch 73 | loss: 11208007837.34297|  0:22:52s\n",
            "epoch 73 | loss: 12043769432.25993|  0:22:55s\n",
            "epoch 73 | loss: 2771101183.53791|  0:22:55s\n",
            "epoch 72 | loss: 10900214433.27076|  0:22:56s\n",
            "epoch 74 | loss: 10596552804.50542|  0:23:00s\n",
            "epoch 72 | loss: 11929757751.2202|  0:23:01s\n",
            "epoch 74 | loss: 11716334665.70398|  0:23:02s\n",
            "epoch 72 | loss: 11225360640.69314|  0:23:04s\n",
            "epoch 75 | loss: 2775976120.6065|  0:23:04s\n",
            "epoch 75 | loss: 2646232108.12996|  0:23:04s\n",
            "epoch 73 | loss: 10472790933.71841|  0:23:05s\n",
            "epoch 73 | loss: 3271342190.44043|  0:23:07s\n",
            "epoch 74 | loss: 11137740779.43682|  0:23:10s\n",
            "epoch 74 | loss: 10749161938.25271|  0:23:12s\n",
            "epoch 74 | loss: 2823855689.93502|  0:23:12s\n",
            "epoch 73 | loss: 10840441714.59928|  0:23:14s\n",
            "epoch 75 | loss: 10629997565.22743|  0:23:17s\n",
            "epoch 73 | loss: 12001187024.86644|  0:23:19s\n",
            "epoch 75 | loss: 11809243950.44043|  0:23:20s\n",
            "epoch 76 | loss: 3020988185.41516|  0:23:21s\n",
            "epoch 76 | loss: 3514340948.10108|  0:23:21s\n",
            "epoch 73 | loss: 10970884021.37184|  0:23:22s\n",
            "epoch 74 | loss: 10487795645.68954|  0:23:24s\n",
            "epoch 74 | loss: 3111909941.37184|  0:23:25s\n",
            "epoch 75 | loss: 11775236846.90252|  0:23:28s\n",
            "epoch 75 | loss: 10795634322.7148|  0:23:31s\n",
            "epoch 75 | loss: 2771314314.62816|  0:23:31s\n",
            "epoch 74 | loss: 10931787129.76173|  0:23:32s\n",
            "epoch 76 | loss: 10591115397.31408|  0:23:35s\n",
            "epoch 74 | loss: 11861364109.63178|  0:23:38s\n",
            "epoch 76 | loss: 11537857588.44765|  0:23:38s\n",
            "epoch 77 | loss: 3718469221.4296|  0:23:39s\n",
            "epoch 77 | loss: 2928643806.72924|  0:23:40s\n",
            "epoch 74 | loss: 11129060379.95668|  0:23:41s\n",
            "epoch 75 | loss: 10524518664.31769|  0:23:43s\n",
            "epoch 75 | loss: 3034540809.47292|  0:23:44s\n",
            "epoch 76 | loss: 11234175295.30686|  0:23:47s\n",
            "epoch 76 | loss: 11350728300.12996|  0:23:49s\n",
            "epoch 76 | loss: 2970836864.92419|  0:23:50s\n",
            "epoch 75 | loss: 10868534380.12996|  0:23:51s\n",
            "epoch 77 | loss: 10569195049.81949|  0:23:53s\n",
            "epoch 77 | loss: 11682703706.33935|  0:23:55s\n",
            "epoch 75 | loss: 11868646419.1769|  0:23:56s\n",
            "epoch 78 | loss: 3170819808.80866|  0:23:56s\n",
            "epoch 78 | loss: 2931314928.7509|  0:23:57s\n",
            "epoch 75 | loss: 11294982233.87726|  0:23:59s\n",
            "epoch 76 | loss: 10640428897.5018|  0:24:00s\n",
            "epoch 76 | loss: 3272810100.90975|  0:24:01s\n",
            "epoch 77 | loss: 11042226591.42239|  0:24:04s\n",
            "epoch 77 | loss: 11127131980.24548|  0:24:05s\n",
            "epoch 77 | loss: 2808474977.9639|  0:24:07s\n",
            "epoch 76 | loss: 10746914630.00722|  0:24:08s\n",
            "epoch 78 | loss: 10477051458.31046|  0:24:10s\n",
            "epoch 78 | loss: 11551458353.67509|  0:24:12s\n",
            "epoch 79 | loss: 3151578072.49098|  0:24:13s\n",
            "epoch 79 | loss: 2783588976.28881|  0:24:13s\n",
            "epoch 76 | loss: 12123062450.36823|  0:24:13s\n",
            "epoch 76 | loss: 11120941606.81588|  0:24:16s\n",
            "epoch 77 | loss: 10335633443.35018|  0:24:17s\n",
            "epoch 77 | loss: 3101212264.20216|  0:24:18s\n",
            "epoch 78 | loss: 10989436578.426|  0:24:20s\n",
            "epoch 78 | loss: 10758796032.92418|  0:24:22s\n",
            "epoch 78 | loss: 2805257763.11913|  0:24:23s\n",
            "epoch 77 | loss: 10681751534.67148|  0:24:25s\n",
            "epoch 79 | loss: 10648539268.15884|  0:24:26s\n",
            "epoch 79 | loss: 11694393274.68592|  0:24:28s\n",
            "epoch 80 | loss: 3030436401.67509|  0:24:29s\n",
            "epoch 80 | loss: 2722267640.6065|  0:24:30s\n",
            "epoch 77 | loss: 11948377770.28158|  0:24:30s\n",
            "epoch 77 | loss: 10916569661.45848|  0:24:33s\n",
            "epoch 78 | loss: 10506944435.52347|  0:24:34s\n",
            "epoch 78 | loss: 3095984399.94224|  0:24:35s\n",
            "epoch 79 | loss: 10963405190.00722|  0:24:38s\n",
            "epoch 79 | loss: 10944213070.55596|  0:24:40s\n",
            "epoch 79 | loss: 3023464057.99278|  0:24:41s\n",
            "epoch 78 | loss: 10725585179.26353|  0:24:43s\n",
            "epoch 80 | loss: 10506619738.57039|  0:24:43s\n",
            "epoch 80 | loss: 11894419738.5704|  0:24:45s\n",
            "epoch 81 | loss: 2657060124.18773|  0:24:46s\n",
            "epoch 81 | loss: 2664516966.81588|  0:24:47s\n",
            "epoch 78 | loss: 11743563641.06859|  0:24:48s\n",
            "epoch 78 | loss: 10668324986.91697|  0:24:50s\n",
            "epoch 79 | loss: 10612397807.59567|  0:24:51s\n",
            "epoch 79 | loss: 3080197594.5704|  0:24:52s\n",
            "epoch 80 | loss: 10905650560.0|  0:24:55s\n",
            "epoch 80 | loss: 10767170836.56318|  0:24:57s\n",
            "epoch 80 | loss: 2771834192.17328|  0:24:58s\n",
            "epoch 81 | loss: 10561587030.6426|  0:25:01s\n",
            "epoch 79 | loss: 10751828825.87726|  0:25:01s\n",
            "epoch 81 | loss: 11626966609.09748|  0:25:03s\n",
            "epoch 82 | loss: 2891925082.33935|  0:25:03s\n",
            "epoch 82 | loss: 2845179939.81227|  0:25:04s\n",
            "epoch 79 | loss: 11875521077.37184|  0:25:06s\n",
            "epoch 79 | loss: 11056130259.63899|  0:25:08s\n",
            "epoch 80 | loss: 10407084281.99278|  0:25:09s\n",
            "epoch 80 | loss: 2878387103.42238|  0:25:10s\n",
            "epoch 81 | loss: 10819896302.90253|  0:25:12s\n",
            "epoch 81 | loss: 10665525728.80867|  0:25:14s\n",
            "epoch 81 | loss: 2779602835.40794|  0:25:15s\n",
            "epoch 82 | loss: 10570705993.01083|  0:25:18s\n",
            "epoch 80 | loss: 10674678908.99639|  0:25:19s\n",
            "epoch 82 | loss: 11859618775.56679|  0:25:20s\n",
            "epoch 83 | loss: 2950099498.74368|  0:25:20s\n",
            "epoch 83 | loss: 2710148960.34657|  0:25:21s\n",
            "epoch 80 | loss: 11802994440.31769|  0:25:23s\n",
            "epoch 80 | loss: 10846161354.62816|  0:25:27s\n",
            "epoch 81 | loss: 10388103005.34297|  0:25:27s\n",
            "epoch 81 | loss: 2867813741.51625|  0:25:28s\n",
            "epoch 82 | loss: 10714844454.81588|  0:25:31s\n",
            "epoch 82 | loss: 10713153560.95307|  0:25:33s\n",
            "epoch 82 | loss: 2742955708.5343|  0:25:33s\n",
            "epoch 83 | loss: 10600862755.35018|  0:25:36s\n",
            "epoch 81 | loss: 10942625258.51264|  0:25:38s\n",
            "epoch 84 | loss: 2782554556.30325|  0:25:38s\n",
            "epoch 83 | loss: 11932842836.10109|  0:25:38s\n",
            "epoch 84 | loss: 3121607492.38989|  0:25:40s\n",
            "epoch 81 | loss: 11604381164.12996|  0:25:42s\n",
            "epoch 81 | loss: 10708360477.80506|  0:25:45s\n",
            "epoch 82 | loss: 10440951321.64621|  0:25:46s\n",
            "epoch 82 | loss: 2976791182.787|  0:25:46s\n",
            "epoch 83 | loss: 11166011808.11552|  0:25:48s\n",
            "epoch 83 | loss: 2754793103.71119|  0:25:50s\n",
            "epoch 83 | loss: 10808203095.79784|  0:25:50s\n",
            "epoch 84 | loss: 10504250152.89531|  0:25:53s\n",
            "epoch 85 | loss: 2839354768.17329|  0:25:55s\n",
            "epoch 82 | loss: 10858773839.94224|  0:25:55s\n",
            "epoch 84 | loss: 11466335190.6426|  0:25:55s\n",
            "epoch 85 | loss: 2767573504.92419|  0:25:56s\n",
            "epoch 82 | loss: 11814463573.02528|  0:25:59s\n",
            "epoch 83 | loss: 10660545839.36463|  0:26:02s\n",
            "epoch 82 | loss: 10778308292.15885|  0:26:03s\n",
            "epoch 83 | loss: 3027027168.34657|  0:26:03s\n",
            "epoch 84 | loss: 11001900236.47653|  0:26:06s\n",
            "epoch 84 | loss: 2900142094.09386|  0:26:06s\n",
            "epoch 84 | loss: 10604525456.17328|  0:26:07s\n",
            "epoch 85 | loss: 10562051638.29603|  0:26:10s\n",
            "epoch 86 | loss: 2796075690.51263|  0:26:11s\n",
            "epoch 85 | loss: 11898798063.36462|  0:26:12s\n",
            "epoch 86 | loss: 2570999722.51264|  0:26:12s\n",
            "epoch 83 | loss: 10859005269.71841|  0:26:13s\n",
            "epoch 83 | loss: 11694900820.79423|  0:26:17s\n",
            "epoch 84 | loss: 10366016650.16607|  0:26:20s\n",
            "epoch 83 | loss: 10600152262.9314|  0:26:21s\n",
            "epoch 84 | loss: 2936324205.51625|  0:26:21s\n",
            "epoch 85 | loss: 12044322622.15162|  0:26:23s\n",
            "epoch 85 | loss: 2743681031.62455|  0:26:24s\n",
            "epoch 85 | loss: 10887423264.11552|  0:26:25s\n",
            "epoch 86 | loss: 10531699730.7148|  0:26:26s\n",
            "epoch 87 | loss: 3283449657.06859|  0:26:28s\n",
            "epoch 86 | loss: 11380306966.41155|  0:26:29s\n",
            "epoch 87 | loss: 2814920285.80505|  0:26:30s\n",
            "epoch 84 | loss: 10776915416.95307|  0:26:30s\n",
            "epoch 84 | loss: 11692610654.49819|  0:26:35s\n",
            "epoch 85 | loss: 10349954145.03971|  0:26:38s\n",
            "epoch 84 | loss: 10808644508.18773|  0:26:38s\n",
            "epoch 85 | loss: 2867281278.15162|  0:26:39s\n",
            "epoch 86 | loss: 10876942231.33574|  0:26:40s\n",
            "epoch 86 | loss: 2701791959.79783|  0:26:41s\n",
            "epoch 86 | loss: 10889010797.74729|  0:26:42s\n",
            "epoch 87 | loss: 10333134036.33213|  0:26:44s\n",
            "epoch 88 | loss: 3102131250.83032|  0:26:45s\n",
            "epoch 88 | loss: 2523792963.69675|  0:26:47s\n",
            "epoch 87 | loss: 10833144710.23827|  0:26:47s\n",
            "epoch 85 | loss: 10669180754.2527|  0:26:48s\n",
            "epoch 85 | loss: 11812528543.65343|  0:26:52s\n",
            "epoch 86 | loss: 10412048755.52347|  0:26:55s\n",
            "epoch 85 | loss: 10745235567.13357|  0:26:55s\n",
            "epoch 86 | loss: 3027568447.30686|  0:26:56s\n",
            "epoch 87 | loss: 10976995050.05054|  0:26:57s\n",
            "epoch 87 | loss: 2802573441.38628|  0:26:58s\n",
            "epoch 87 | loss: 10883789246.38267|  0:26:59s\n",
            "epoch 88 | loss: 10308050511.71119|  0:27:00s\n",
            "epoch 89 | loss: 2748887855.82672|  0:27:01s\n",
            "epoch 89 | loss: 2538832281.64621|  0:27:03s\n",
            "epoch 88 | loss: 11583281333.1408|  0:27:04s\n",
            "epoch 86 | loss: 10738963814.35379|  0:27:05s\n",
            "epoch 86 | loss: 11610852409.76173|  0:27:10s\n",
            "epoch 87 | loss: 10546101035.20578|  0:27:13s\n",
            "epoch 86 | loss: 10692189416.20217|  0:27:13s\n",
            "epoch 87 | loss: 2986647031.68231|  0:27:13s\n",
            "epoch 88 | loss: 11092577112.95307|  0:27:15s\n",
            "epoch 88 | loss: 2680134684.88087|  0:27:16s\n",
            "epoch 88 | loss: 11508878296.25992|  0:27:17s\n",
            "epoch 89 | loss: 10552774709.83394|  0:27:18s\n",
            "epoch 90 | loss: 2712026704.17329|  0:27:19s\n",
            "epoch 90 | loss: 2529774490.1083|  0:27:20s\n",
            "epoch 89 | loss: 11938618367.76895|  0:27:21s\n",
            "epoch 87 | loss: 10677506581.25631|  0:27:24s\n",
            "epoch 87 | loss: 11490088763.61011|  0:27:28s\n",
            "epoch 88 | loss: 10317947267.69675|  0:27:30s\n",
            "epoch 87 | loss: 10107525965.16968|  0:27:31s\n",
            "epoch 88 | loss: 2855505436.18773|  0:27:32s\n",
            "epoch 89 | loss: 10783705740.24549|  0:27:33s\n",
            "epoch 89 | loss: 2658622232.25993|  0:27:34s\n",
            "epoch 89 | loss: 11132882608.05776|  0:27:34s\n",
            "epoch 90 | loss: 10476604436.56318|  0:27:35s\n",
            "epoch 91 | loss: 2778069296.98195|  0:27:36s\n",
            "epoch 91 | loss: 2775974449.90614|  0:27:37s\n",
            "epoch 90 | loss: 10886415798.06498|  0:27:39s\n",
            "epoch 88 | loss: 10612012332.12997|  0:27:42s\n",
            "epoch 88 | loss: 11098465198.67148|  0:27:46s\n",
            "epoch 89 | loss: 10543817338.22383|  0:27:48s\n",
            "epoch 88 | loss: 10571446297.87726|  0:27:49s\n",
            "epoch 89 | loss: 2836461144.02888|  0:27:50s\n",
            "epoch 90 | loss: 10975374267.84115|  0:27:51s\n",
            "epoch 90 | loss: 2627651943.04693|  0:27:52s\n",
            "epoch 90 | loss: 10797057342.61371|  0:27:52s\n",
            "epoch 91 | loss: 10371250493.45848|  0:27:53s\n",
            "epoch 92 | loss: 2841993902.20939|  0:27:53s\n",
            "epoch 92 | loss: 2642737357.40072|  0:27:55s\n",
            "epoch 91 | loss: 11431463714.65704|  0:27:56s\n",
            "epoch 89 | loss: 10678306639.48014|  0:28:00s\n",
            "epoch 89 | loss: 11480574720.23104|  0:28:03s\n",
            "epoch 90 | loss: 10383670387.06137|  0:28:06s\n",
            "epoch 89 | loss: 10441494429.34296|  0:28:07s\n",
            "epoch 90 | loss: 2867830406.00722|  0:28:07s\n",
            "epoch 91 | loss: 10974097452.59206|  0:28:09s\n",
            "epoch 91 | loss: 2591159394.19495|  0:28:09s\n",
            "epoch 92 | loss: 10418445030.81588|  0:28:09s\n",
            "epoch 91 | loss: 10844077781.02527|  0:28:10s\n",
            "epoch 93 | loss: 2980350022.70036|  0:28:10s\n",
            "epoch 93 | loss: 2484409003.89892|  0:28:12s\n",
            "epoch 92 | loss: 10980871993.76173|  0:28:13s\n",
            "epoch 90 | loss: 10662472023.10469|  0:28:18s\n",
            "epoch 90 | loss: 10893619347.40794|  0:28:21s\n",
            "epoch 91 | loss: 10246866189.86282|  0:28:23s\n",
            "epoch 90 | loss: 10724109120.23105|  0:28:24s\n",
            "epoch 91 | loss: 2937898360.83754|  0:28:25s\n",
            "epoch 92 | loss: 10700431658.74368|  0:28:25s\n",
            "epoch 92 | loss: 2565277248.23105|  0:28:26s\n",
            "epoch 93 | loss: 10349603007.76895|  0:28:27s\n",
            "epoch 94 | loss: 3030403969.61733|  0:28:27s\n",
            "epoch 92 | loss: 10740801609.01084|  0:28:27s\n",
            "epoch 94 | loss: 2807979501.2852|  0:28:28s\n",
            "epoch 93 | loss: 10880276955.26354|  0:28:31s\n",
            "epoch 91 | loss: 10676440730.5704|  0:28:36s\n",
            "epoch 91 | loss: 10743066007.33574|  0:28:40s\n",
            "epoch 92 | loss: 10263659029.48736|  0:28:41s\n",
            "epoch 91 | loss: 11080961497.64621|  0:28:43s\n",
            "epoch 93 | loss: 10755302007.91336|  0:28:44s\n",
            "epoch 92 | loss: 2865975176.31769|  0:28:44s\n",
            "epoch 94 | loss: 10313814746.80144|  0:28:45s\n",
            "epoch 95 | loss: 2997107146.62816|  0:28:45s\n",
            "epoch 93 | loss: 2751671267.81227|  0:28:45s\n",
            "epoch 93 | loss: 10673885043.29242|  0:28:46s\n",
            "epoch 95 | loss: 2822518658.07942|  0:28:47s\n",
            "epoch 94 | loss: 10941849133.51624|  0:28:48s\n",
            "epoch 92 | loss: 10759741511.3935|  0:28:55s\n",
            "epoch 92 | loss: 11071684648.66426|  0:28:58s\n",
            "epoch 93 | loss: 10380153834.28159|  0:29:00s\n",
            "epoch 92 | loss: 10630438672.17328|  0:29:02s\n",
            "epoch 94 | loss: 11149838449.67509|  0:29:02s\n",
            "epoch 95 | loss: 10556401899.66787|  0:29:02s\n",
            "epoch 96 | loss: 2861321877.25632|  0:29:02s\n",
            "epoch 93 | loss: 2861739800.25993|  0:29:02s\n",
            "epoch 94 | loss: 2622858748.0722|  0:29:03s\n",
            "epoch 94 | loss: 10561964348.5343|  0:29:03s\n",
            "epoch 96 | loss: 2670923111.74007|  0:29:05s\n",
            "epoch 95 | loss: 10991492565.48736|  0:29:06s\n",
            "epoch 93 | loss: 10723105222.23827|  0:29:14s\n",
            "epoch 93 | loss: 11640861073.79061|  0:29:18s\n",
            "epoch 94 | loss: 10356737453.05415|  0:29:19s\n",
            "epoch 97 | loss: 2718143064.25993|  0:29:21s\n",
            "epoch 96 | loss: 10609524037.54512|  0:29:21s\n",
            "epoch 94 | loss: 3047502334.15162|  0:29:21s\n",
            "epoch 95 | loss: 10684329512.66426|  0:29:21s\n",
            "epoch 93 | loss: 10473754424.83754|  0:29:22s\n",
            "epoch 95 | loss: 2598985161.70397|  0:29:22s\n",
            "epoch 95 | loss: 10937044355.00361|  0:29:22s\n",
            "epoch 97 | loss: 2696799023.82671|  0:29:23s\n",
            "epoch 96 | loss: 11923622519.91336|  0:29:25s\n",
            "epoch 94 | loss: 10572588264.20216|  0:29:33s\n",
            "epoch 94 | loss: 10572729094.93141|  0:29:36s\n",
            "epoch 95 | loss: 10319380588.36101|  0:29:38s\n",
            "epoch 98 | loss: 2639976720.17328|  0:29:38s\n",
            "epoch 97 | loss: 10480075636.90975|  0:29:39s\n",
            "epoch 96 | loss: 10715891527.8556|  0:29:40s\n",
            "epoch 95 | loss: 2754434772.56318|  0:29:40s\n",
            "epoch 94 | loss: 10436391502.32491|  0:29:41s\n",
            "epoch 96 | loss: 10703155434.05054|  0:29:41s\n",
            "epoch 96 | loss: 2632987628.59206|  0:29:41s\n",
            "epoch 98 | loss: 2671532990.61372|  0:29:42s\n",
            "epoch 97 | loss: 10815904814.67148|  0:29:44s\n",
            "epoch 95 | loss: 10489693332.33213|  0:29:52s\n",
            "epoch 95 | loss: 10570321311.19134|  0:29:55s\n",
            "epoch 96 | loss: 10156099318.29603|  0:29:56s\n",
            "epoch 98 | loss: 10620171821.2852|  0:29:56s\n",
            "epoch 99 | loss: 2667557155.11913|  0:29:56s\n",
            "epoch 97 | loss: 10718496418.42599|  0:29:58s\n",
            "epoch 96 | loss: 2895743082.97473|  0:29:58s\n",
            "epoch 97 | loss: 11994991892.10108|  0:29:59s\n",
            "epoch 97 | loss: 2606964391.97112|  0:29:59s\n",
            "epoch 95 | loss: 10539949530.80144|  0:29:59s\n",
            "epoch 99 | loss: 2569352570.68592|  0:29:59s\n",
            "epoch 98 | loss: 11486567960.02888|  0:30:02s\n",
            "epoch 96 | loss: 10532726860.24549|  0:30:12s\n",
            "epoch 96 | loss: 11898260537.53069|  0:30:15s\n",
            "epoch 99 | loss: 10371980217.53068|  0:30:16s\n",
            "epoch 97 | loss: 10303489352.31769|  0:30:16s\n",
            "epoch 98 | loss: 10806678878.96028|  0:30:18s\n",
            "epoch 97 | loss: 2895311342.67148|  0:30:19s\n",
            "epoch 98 | loss: 2762433558.87365|  0:30:19s\n",
            "epoch 98 | loss: 12085625525.83394|  0:30:19s\n",
            "epoch 96 | loss: 10592664526.55596|  0:30:21s\n",
            "epoch 99 | loss: 11996591289.99277|  0:30:23s\n",
            "epoch 97 | loss: 10505778747.84115|  0:30:33s\n",
            "epoch 97 | loss: 10731921136.7509|  0:30:36s\n",
            "epoch 98 | loss: 10303662939.03249|  0:30:37s\n",
            "epoch 99 | loss: 10624008740.04332|  0:30:39s\n",
            "epoch 98 | loss: 2685657659.61011|  0:30:40s\n",
            "epoch 99 | loss: 2615037113.29964|  0:30:40s\n",
            "epoch 99 | loss: 11346600640.69314|  0:30:41s\n",
            "epoch 97 | loss: 10465061236.6787|  0:30:41s\n",
            "epoch 98 | loss: 10670500383.42238|  0:30:51s\n",
            "[CV] END ....................................lambda_sparse=0; total time=30.9min\n",
            "epoch 98 | loss: 10922953526.29603|  0:30:53s\n",
            "epoch 99 | loss: 10484855964.18772|  0:30:54s\n",
            "epoch 99 | loss: 2809400359.50902|  0:30:56s\n",
            "epoch 98 | loss: 10531949510.93141|  0:30:57s\n",
            "[CV] END ................................lambda_sparse=0.001; total time=31.0min\n",
            "epoch 99 | loss: 10579724037.31408|  0:31:05s\n",
            "epoch 99 | loss: 11086560935.04693|  0:31:07s\n",
            "epoch 99 | loss: 10451295106.07942|  0:31:10s\n",
            "[CV] END .................................lambda_sparse=0.01; total time=31.5min\n",
            "[CV] END ...............................lambda_sparse=0.0001; total time=31.7min\n",
            "[CV] END ....................................lambda_sparse=0; total time=31.9min\n",
            "[CV] END .................................lambda_sparse=0.01; total time=32.0min\n",
            "[CV] END ...............................lambda_sparse=0.0001; total time=32.0min\n",
            "[CV] END ...............................lambda_sparse=0.0001; total time=32.1min\n",
            "[CV] END .................................lambda_sparse=0.01; total time=32.1min\n",
            "[CV] END ....................................lambda_sparse=0; total time=32.1min\n",
            "[CV] END ................................lambda_sparse=0.001; total time=32.1min\n",
            "[CV] END ................................lambda_sparse=0.001; total time=32.1min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19851063456.38556|  0:00:20s\n",
            "epoch 1  | loss: 16694416971.25784|  0:00:41s\n",
            "epoch 2  | loss: 13972356959.61445|  0:01:02s\n",
            "epoch 3  | loss: 12090253807.96144|  0:01:23s\n",
            "epoch 4  | loss: 11174662577.04096|  0:01:45s\n",
            "epoch 5  | loss: 10869676251.91326|  0:02:06s\n",
            "epoch 6  | loss: 10714546408.86746|  0:02:26s\n",
            "epoch 7  | loss: 10668124206.26506|  0:02:48s\n",
            "epoch 8  | loss: 10581056220.22169|  0:03:09s\n",
            "epoch 9  | loss: 10505884036.93493|  0:03:30s\n",
            "epoch 10 | loss: 10494014905.98554|  0:03:50s\n",
            "epoch 11 | loss: 10415766627.0072|  0:04:11s\n",
            "epoch 12 | loss: 10375458902.36144|  0:04:33s\n",
            "epoch 13 | loss: 10345457373.3012|  0:04:54s\n",
            "epoch 14 | loss: 10240338012.2217|  0:05:15s\n",
            "epoch 15 | loss: 10217753312.53977|  0:05:36s\n",
            "epoch 16 | loss: 10176488550.09156|  0:05:57s\n",
            "epoch 17 | loss: 10206419699.66264|  0:06:18s\n",
            "epoch 18 | loss: 10349568345.44578|  0:06:39s\n",
            "epoch 19 | loss: 10217385968.26989|  0:06:59s\n",
            "epoch 20 | loss: 10024965479.3253|  0:07:20s\n",
            "epoch 21 | loss: 9989253723.29637|  0:07:41s\n",
            "epoch 22 | loss: 9925112838.47711|  0:08:03s\n",
            "epoch 23 | loss: 10142175415.82652|  0:08:24s\n",
            "epoch 24 | loss: 9964211240.25059|  0:08:45s\n",
            "epoch 25 | loss: 9923195256.90602|  0:09:06s\n",
            "epoch 26 | loss: 9838176508.14457|  0:09:27s\n",
            "epoch 27 | loss: 9887960425.79278|  0:09:48s\n",
            "epoch 28 | loss: 9770591561.0988|  0:10:10s\n",
            "epoch 29 | loss: 9591579239.3253|  0:10:31s\n",
            "epoch 30 | loss: 9620731586.46746|  0:10:51s\n",
            "epoch 31 | loss: 9658427461.39758|  0:11:13s\n",
            "epoch 32 | loss: 9472400708.31807|  0:11:34s\n",
            "epoch 33 | loss: 9750938668.72289|  0:11:56s\n",
            "epoch 34 | loss: 9592070398.1494|  0:12:16s\n",
            "epoch 35 | loss: 9553227682.54457|  0:12:38s\n",
            "epoch 36 | loss: 9481111839.15181|  0:12:59s\n",
            "epoch 37 | loss: 9395421687.82651|  0:13:21s\n",
            "epoch 38 | loss: 9424198854.01446|  0:13:43s\n",
            "epoch 39 | loss: 9412507274.9494|  0:14:06s\n",
            "epoch 40 | loss: 9387944957.84097|  0:14:27s\n",
            "epoch 41 | loss: 9253577949.91807|  0:14:48s\n",
            "epoch 42 | loss: 9329684898.39036|  0:15:09s\n",
            "epoch 43 | loss: 9277759256.21205|  0:15:30s\n",
            "epoch 44 | loss: 9236672132.31808|  0:15:52s\n",
            "epoch 45 | loss: 9011282719.76867|  0:16:13s\n",
            "epoch 46 | loss: 8812090953.0988|  0:16:54s\n",
            "epoch 47 | loss: 9129854904.75181|  0:17:52s\n",
            "epoch 48 | loss: 9009190494.84338|  0:18:23s\n",
            "epoch 49 | loss: 8811590959.80723|  0:18:45s\n",
            "epoch 50 | loss: 8879652670.30361|  0:19:06s\n",
            "epoch 51 | loss: 8705264066.46746|  0:19:27s\n",
            "epoch 52 | loss: 8773130541.8024|  0:19:48s\n",
            "epoch 53 | loss: 8813382475.72048|  0:20:10s\n",
            "epoch 54 | loss: 8818110710.747|  0:20:31s\n",
            "epoch 55 | loss: 8827455747.08434|  0:20:52s\n",
            "epoch 56 | loss: 8703179138.7759|  0:21:13s\n",
            "epoch 57 | loss: 8778923074.7759|  0:21:34s\n",
            "epoch 58 | loss: 8615704450.46747|  0:21:55s\n",
            "epoch 59 | loss: 8692871363.85541|  0:22:16s\n",
            "epoch 60 | loss: 8702664043.48917|  0:22:37s\n",
            "epoch 61 | loss: 8585159151.96145|  0:22:58s\n",
            "epoch 62 | loss: 8661800905.86987|  0:23:19s\n",
            "epoch 63 | loss: 8678641967.19036|  0:23:40s\n",
            "epoch 64 | loss: 8744747732.20241|  0:24:00s\n",
            "epoch 65 | loss: 8640255496.63614|  0:26:39s\n",
            "epoch 66 | loss: 8722604953.6|  0:27:01s\n",
            "epoch 67 | loss: 8496930200.21205|  0:27:22s\n",
            "epoch 68 | loss: 8602734236.99277|  0:27:44s\n",
            "epoch 69 | loss: 8644977289.253|  0:28:05s\n",
            "epoch 70 | loss: 8642834132.81928|  0:28:27s\n",
            "epoch 71 | loss: 8651590370.08194|  0:28:49s\n",
            "epoch 72 | loss: 8681728596.81928|  0:29:10s\n",
            "epoch 73 | loss: 8418483731.58554|  0:29:31s\n",
            "epoch 74 | loss: 8379091078.16867|  0:29:52s\n",
            "epoch 75 | loss: 8438365180.14458|  0:30:12s\n",
            "epoch 76 | loss: 8357747144.01928|  0:30:33s\n",
            "epoch 77 | loss: 8536077097.02169|  0:30:54s\n",
            "epoch 78 | loss: 8479077179.21928|  0:31:15s\n",
            "epoch 79 | loss: 7789818935.36385|  0:31:36s\n",
            "epoch 80 | loss: 8405238311.01686|  0:31:57s\n",
            "epoch 81 | loss: 8411370902.66988|  0:32:18s\n",
            "epoch 82 | loss: 8238682884.78073|  0:32:39s\n",
            "epoch 83 | loss: 8376308781.95662|  0:33:00s\n",
            "epoch 84 | loss: 8495942988.02891|  0:33:21s\n",
            "epoch 85 | loss: 8566701364.27952|  0:33:42s\n",
            "epoch 86 | loss: 8369872261.86024|  0:34:03s\n",
            "epoch 87 | loss: 8306762129.58072|  0:34:24s\n",
            "epoch 88 | loss: 8330622575.34458|  0:34:45s\n",
            "epoch 89 | loss: 8267501727.92289|  0:35:06s\n",
            "epoch 90 | loss: 8466472222.22652|  0:35:27s\n",
            "epoch 91 | loss: 8267056992.84819|  0:35:48s\n",
            "epoch 92 | loss: 8538894819.31566|  0:36:09s\n",
            "epoch 93 | loss: 8238130386.81446|  0:36:30s\n",
            "epoch 94 | loss: 8699463995.99036|  0:36:52s\n",
            "epoch 95 | loss: 8546546258.3518|  0:37:13s\n",
            "epoch 96 | loss: 8226133560.59759|  0:37:35s\n",
            "epoch 97 | loss: 8264283183.65301|  0:37:57s\n",
            "epoch 98 | loss: 8062623806.1494|  0:38:19s\n",
            "epoch 99 | loss: 8429435101.147|  0:38:41s\n",
            "Лучшие параметры: {'lambda_sparse': 0.01}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'lambda_sparse': [0, 1e-4, 1e-3, 1e-2],\n",
        "}\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class TabNetWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, n_d=32, n_a=16, n_steps=3, gamma=1.0, lambda_sparse=1e-3):\n",
        "        self.n_d = n_d\n",
        "        self.n_a = n_a\n",
        "        self.n_steps = n_steps\n",
        "        self.gamma = gamma\n",
        "        self.lambda_sparse = lambda_sparse\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = TabNetRegressor(\n",
        "            n_d=self.n_d,\n",
        "            n_a=self.n_a,\n",
        "            n_steps=self.n_steps,\n",
        "            gamma=self.gamma,\n",
        "            lambda_sparse=self.lambda_sparse\n",
        "        )\n",
        "        self.model.fit(X, y.reshape(-1, 1))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X).flatten()\n",
        "\n",
        "model = TabNetWrapper()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=param_grid,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Лучшие параметры: {best_params}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19790739692.96751| train_rmse: 134188.25805| train_r2: -0.41325| train_smape: 149.04689| val_rmse: 106700.17219| val_r2: -0.85555| val_smape: 149.19094|  0:00:37s\n"
          ]
        }
      ],
      "source": [
        "class R2Score(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"r2\"\n",
        "        self._maximize = True  # R² нужно максимизировать\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        return r2_score(y_true, y_pred)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tabnet_params = {\n",
        "    \"n_d\": 32,\n",
        "    \"n_a\": 16,\n",
        "    \"n_steps\": 3,\n",
        "    \"gamma\": 1.0,\n",
        "    \"lambda_sparse\": 1e-3,\n",
        "    \"optimizer_fn\": torch.optim.Adam,\n",
        "    \"optimizer_params\": dict(lr=2e-2),\n",
        "    \"mask_type\": \"sparsemax\",\n",
        "    \"scheduler_params\": dict(\n",
        "        mode=\"min\",\n",
        "        patience=5,\n",
        "        min_lr=1e-5,\n",
        "        factor=0.9,\n",
        "    ),\n",
        "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    \"seed\": 42,\n",
        "    \"verbose\": 10\n",
        "}\n",
        "\n",
        "model = TabNetRegressor(**tabnet_params, device_name=device)\n",
        "\n",
        "model.fit(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['rmse', R2Score, SMAPE],\n",
        "    max_epochs=50,\n",
        "    patience=20,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    loss_fn=torch.nn.functional.mse_loss,\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfRQ2JVVw2H3"
      },
      "source": [
        "### Подготовка данных без эмбедингов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcDOoUiXXLlT",
        "outputId": "cd40b880-d669-4390-99b1-73d6b911f8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размеры выборок: Обучающая (425714, 69), Валидационная (141905, 69), Тестовая (141905, 69)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "num_df = pd.DataFrame(scaler.fit_transform(df[num_columns]), columns=num_columns)\n",
        "\n",
        "label_columns = []\n",
        "ohe_columns = []\n",
        "\n",
        "for column in cat_columns:\n",
        "    if df[column].nunique() > 10:\n",
        "        label_columns.append(column)\n",
        "    else:\n",
        "        ohe_columns.append(column)\n",
        "\n",
        "to_bool = list(df[cat_columns].select_dtypes(include=['bool']).columns)\n",
        "df[['salary_gross', 'employer_accredited_it_employer']] = df[['salary_gross', 'employer_accredited_it_employer']].astype(bool).astype(int)\n",
        "df[to_bool] = df[to_bool].astype(int)\n",
        "\n",
        "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
        "ohe_encoded = ohe.fit_transform(df[ohe_columns])\n",
        "ohe_feature_names = ohe.get_feature_names_out(ohe_columns).tolist()\n",
        "encoded_ohe_data = pd.DataFrame(ohe_encoded, columns=ohe_feature_names)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in label_columns:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "X = pd.concat([df[label_columns], encoded_ohe_data, num_df], axis=1)\n",
        "y = df['salary']\n",
        "\n",
        "X_2_train, X_2_test_val, y_2_train, y_2_test_val, = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
        "X_2_test, X_2_val, y_2_test, y_2_val = train_test_split(X_2_test_val, y_2_test_val, test_size=0.5, random_state=12345)\n",
        "\n",
        "print(f'Размеры выборок: Обучающая {X_2_train.shape}, Валидационная {X_2_test.shape}, Тестовая {X_2_val.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2YRZ_2uw2H3"
      },
      "source": [
        "### Полносвязная нейронная сеть без эмбедингов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRb3QBeyXMh7",
        "outputId": "62e911dd-2f1b-4284-a92c-67a8ce331e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training small architecture: [64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
            "Training time: 702.78s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 71249.22691526295\n",
            "R² Score: 0.029691776178032314\n",
            "Средняя абсолютная ошибка (MAE): 41372.06422014223\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 45.38%\n",
            "Медианная абсолютная ошибка (MedAE): 33547.609375\n",
            "\n",
            "Training medium architecture: [128, 64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
            "Training time: 1053.81s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 70796.97617631152\n",
            "R² Score: 0.041970643708062916\n",
            "Средняя абсолютная ошибка (MAE): 38817.90827763207\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 42.65%\n",
            "Медианная абсолютная ошибка (MedAE): 28399.53125\n",
            "\n",
            "Training large architecture: [256, 128, 64, 32]\n",
            "\u001b[1m4435/4435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step\n",
            "Training time: 1138.94s\n",
            "Корень из среднеквадратичной ошибки (RMSE): 75041.47628239205\n",
            "R² Score: -0.0763465867913884\n",
            "Средняя абсолютная ошибка (MAE): 43487.600362960016\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 47.14%\n",
            "Медианная абсолютная ошибка (MedAE): 36524.149999999994\n",
            "\n",
            "Training wide architecture: [512, 256]\n"
          ]
        }
      ],
      "source": [
        "results_2 = {}\n",
        "\n",
        "architectures = {\n",
        "    'small': [64, 32],\n",
        "    'medium': [128, 64, 32],\n",
        "    'large': [256, 128, 64, 32],\n",
        "    'wide': [512, 256],\n",
        "    'deep': [64, 64, 64, 64, 64]\n",
        "}\n",
        "\n",
        "for name, arch in architectures.items():\n",
        "    print(f\"\\nTraining {name} architecture: {arch}\")\n",
        "    model, history, y_pred, train_time, metrics = build_and_train_model(\n",
        "        arch, X_2_train, y_2_train, X_2_test, y_2_test\n",
        "    )\n",
        "\n",
        "    results_2[name] = {\n",
        "        'architecture': arch,\n",
        "        'train_time': train_time,\n",
        "        'metrics': metrics,\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    culc_metrics(y_2_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0SEhJqpw2H4"
      },
      "source": [
        "### TabNet без эмбедингов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VHCPtqbw2H4",
        "outputId": "3f3c871a-daf7-448f-a457-5f110af263ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0  | loss: 19872069664.19348| train_rmse: 136917.37655| train_mae: 79243.44531| train_smape: 154.26673| val_rmse: 110076.88833| val_mae: 79087.0 | val_smape: 154.32972|  0:00:58s\n",
            "epoch 10 | loss: 11264595244.16502| train_rmse: 106016.77754| train_mae: 29198.63867| train_smape: 32.39938| val_rmse: 68291.12645| val_mae: 29137.13281| val_smape: 32.44966|  0:10:57s\n",
            "epoch 20 | loss: 11220968340.13476| train_rmse: 112126.81278| train_mae: 33202.75781| train_smape: 36.70336| val_rmse: 78464.1925| val_mae: 33103.00391| val_smape: 36.7279 |  0:20:47s\n",
            "epoch 30 | loss: 11206899306.1923| train_rmse: 114423.6865| train_mae: 38514.47266| train_smape: 41.57988| val_rmse: 80557.57692| val_mae: 38373.82812| val_smape: 41.61062|  0:30:39s\n",
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_smape = 32.44966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mandal437/hh_regression/.venv/lib/python3.10/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Корень из среднеквадратичной ошибки (RMSE): 61374.38162621274\n",
            "R² Score: 0.28001469373703003\n",
            "Средняя абсолютная ошибка (MAE): 29087.1015625\n",
            "Средняя абсолютная процентная ошибка (SMAPE): 32.53%\n",
            "Медианная абсолютная ошибка (MedAE): 19507.56640625\n"
          ]
        }
      ],
      "source": [
        "X_train = X_2_train.to_numpy()\n",
        "X_val = X_2_val.to_numpy()\n",
        "X_test = X_2_test.to_numpy()\n",
        "\n",
        "y_train = y_2_train.to_numpy().reshape(-1, 1)\n",
        "y_val = y_2_val.to_numpy().reshape(-1, 1)\n",
        "y_test = y_2_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "class SMAPE(Metric):\n",
        "    def __init__(self):\n",
        "        self._name = \"smape\"\n",
        "        self._maximize = False\n",
        "\n",
        "    def __call__(self, y_true, y_pred):\n",
        "        return 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tabnet_params = {\n",
        "    \"n_d\": 8,\n",
        "    \"n_a\": 8,\n",
        "    \"n_steps\": 3,\n",
        "    \"gamma\": 1.3,\n",
        "    \"lambda_sparse\": 1e-3,\n",
        "    \"optimizer_fn\": torch.optim.Adam,\n",
        "    \"optimizer_params\": dict(lr=2e-2),\n",
        "    \"mask_type\": \"sparsemax\",\n",
        "    \"scheduler_params\": dict(\n",
        "        mode=\"min\",\n",
        "        patience=5,\n",
        "        min_lr=1e-5,\n",
        "        factor=0.9,\n",
        "    ),\n",
        "    \"scheduler_fn\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "    \"seed\": 42,\n",
        "    \"verbose\": 10,\n",
        "    \"device_name\": device\n",
        "}\n",
        "\n",
        "model = TabNetRegressor(**tabnet_params)\n",
        "\n",
        "model.fit(\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['rmse', 'mae', SMAPE],\n",
        "    max_epochs=50,\n",
        "    patience=20,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False,\n",
        "    loss_fn=torch.nn.functional.mse_loss,\n",
        "    pin_memory=False\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "culc_metrics(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfN5t9DVdGL5"
      },
      "source": [
        "## Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vL8OLWCILeP"
      },
      "source": [
        "Лучший результат дает RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiHfUp56Armw"
      },
      "source": [
        "| Model                               |    RMSE |      R2 |     MAE |   SMAPE (%) |   MedAE |\n",
        "|:------------------------------------|--------:|--------:|--------:|------------:|--------:|\n",
        "| RF                                  | 44484.3 |  0.6218 | 21484.4 |       24.32 | 12514.5 |\n",
        "| DT (с эмбеддингами)                 | 48970.3 |  0.5416 | 25268.4 |       28.27 | 14970.8 |\n",
        "| TabNet + Embeddings                 | 49171.3 |  0.5379 | 26366.7 |       29.62 | 17047.4 |\n",
        "| DNN [64,32] + Embeddings            | 50941.3 |  0.504  | 29103.1 |       32.33 | 20343.1 |\n",
        "| DNN [64,32] + BN + Adam             | 51853.1 |  0.4861 | 28105   |       31.24 | 18523.9 |\n",
        "| DNN [64,32] + BN + SGD              | 56739.9 |  0.3846 | 27046.5 |       29.85 | 17030.6 |\n",
        "| DNN [64,32] + BN + Adam + Glorot    | 57458.3 |  0.369  | 28906.6 |       32.1  | 19763   |\n",
        "| DNN [64,32] + LN + Adam + He        | 57648.2 |  0.3648 | 26941.2 |       30.1  | 17837.7 |\n",
        "| DNN [64,32] + BN + Adam + He        | 57850.2 |  0.3603 | 28789   |       31.83 | 19358.6 |\n",
        "| DNN [64,32] + LN + Adam + Glorot    | 57900.8 |  0.3592 | 27254.7 |       30.34 | 17967.6 |\n",
        "| DNN [64,32] + LN + Adam             | 57955.4 |  0.358  | 27787.1 |       30.88 | 18780.5 |\n",
        "| DNN [64x5]                          | 58303.6 |  0.3503 | 28460.1 |       31.2  | 18813.3 |\n",
        "| DNN [512,256]                       | 58451.3 |  0.347  | 29016.8 |       31.54 | 19087.2 |\n",
        "| DNN [64,32] + LN + SGD + He         | 58823.4 |  0.3386 | 27388.2 |       30.6  | 18350.5 |\n",
        "| TabNet без эмбеддингов              | 61374.4 |  0.28   | 29087.1 |       32.53 | 19507.6 |\n",
        "| DNN [128,64,32]                     | 63997.7 |  0.2172 | 29133   |       31.22 | 18446.5 |\n",
        "| DNN [128, 64, 32] без эмбеддингов   | 70797   |  0.042  | 38817.9 |       42.65 | 28399.5 |\n",
        "| DNN [64, 32] без эмбеддингов        | 71249.2 |  0.0297 | 41372.1 |       45.38 | 33547.6 |\n",
        "| DNN Large [256,...] без эмбеддингов | 75041.5 | -0.0763 | 43487.6 |       47.14 | 36524.2 |\n",
        "| DNN [256,128,64,32]                 | 99553.4 | -0.8944 | 62541.9 |      107.8  | 48945.9 |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
